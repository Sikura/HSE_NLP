<!DOCTYPE html>
<html lang="en" data-reactroot="" data-reactid="1" data-react-checksum="395334878"><head data-reactid="2">
    <title>Quanta Magazine</title>
    <link href="/fonts.css" rel="stylesheet"/>
    <link href="/main.css?ver=2.7.6" rel="stylesheet"/>
    <link rel="icon" href="/favicon.png" type="image/png">
    
<!-- All in One SEO Pack 2.3.11.4 by Michael Torbert of Semper Fi Web Designob_start_detected [-1,-1] -->
<meta name="description"  content="A tool known as BERT can now beat humans on advanced reading-comprehension tests. But it's also revealed how far AI has to go." />

<meta name="keywords"  content="computer science,artificial intelligence,neural networks,machine learning,natural language processing,bert,nlp" />

<link rel="canonical" href="https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" />
<meta property="og:title" content="Machines Beat Humans on a Reading Test. But Do They Understand? | Quanta Magazine" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" />
<meta property="og:image" content="https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_1200_Social.jpg" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />
<meta property="og:site_name" content="Quanta Magazine" />
<meta property="fb:app_id" content="533309373681765" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:site" content="@QuantaMagazine" />
<meta name="twitter:domain" content="quantamagazine.org" />
<meta name="twitter:title" content="Machines Beat Humans on a Reading Test. But Do They Understand? | Quanta Magazine" />
<meta name="twitter:image" content="https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_1200_Social.jpg" />
<meta itemprop="image" content="https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_1200_Social.jpg" />
			<script>
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-8526335-13', 'auto');
			ga('require', 'displayfeatures');
			ga('send', 'pageview');
			</script>
<!-- /all in one seo pack -->
<meta name="twitter:description" content="A tool known as BERT can now beat humans on advanced reading-comprehension tests. But it&#039;s also revealed how far AI has to go." />
    <script type="text/javascript">
      if ('group' in window.console) {
        console.groupCollapsed('Development by https://barrelny.com - @barrelny')
        console.info('Built with React, React Router v3, Apollo GraphQL libraries, the Wordpress REST API, and coffee ☕️')
        console.groupEnd()
      } else {
        console.info('Development by https://barrelny.com - @barrelny')
      }
    </script>
    <style type="text/css">._hover_div-c-1a1a1a:hover div{color:#1a1a1a}._hover_div-opacity-1:hover div{opacity:1}._hover_svg-c-1a1a1a:hover svg{color:#1a1a1a}.c-ff8600{color:#ff8600}.c-1a1a1a{color:#1a1a1a}._hover-c-ff8600:hover{color:#ff8600}.c-999999{color:#999999}._16jm4kw:hover #logo__mark{color:#ff8600}._e16twb:hover #logo__mark__icon{color:#ff8600}.bc-efefef{background-color:#efefef}._hover-c-white:hover{color:white}._hover-bc-ff8600:hover{background-color:#ff8600}._hover_div-c-ff8600:hover div{color:#ff8600}._hover_svg-c-ff8600:hover svg{color:#ff8600}.lh-0{line-height:0}.w-100P{width:100%}.m-0_auto{margin:0 auto}.d-flex{display:flex}.align-items-center{align-items:center}.justify-content-center{justify-content:center}.flex-direction-column{flex-direction:column}.max-width-1420{max-width:1420px}._p_last-of-type-mb-0 p:last-of-type{margin-bottom:0px}.p-0{padding:0px}.w-auto{width:auto}.max-width-100P{max-width:100%}.max-height-100P{max-height:100%}.mr-0p5em{margin-right:0.5em}._last-of-type-m-0:last-of-type{margin:0px}.w-initial{width:initial}.mb-1p5em{margin-bottom:1.5em}.border-none{border:none}.d-block{display:block}.p-0_3em{padding:0 3em}.max-width-560px{max-width:560px}._1re1wwt .attribution{text-align:left}._pattribution-w-auto .attribution{width:auto}._46bwqc .attribution:before{content:}._pujp80 .attribution:before{display:block}._pcaption-w-auto .caption{width:auto}._1dxfdx3{justify-content:flex-end}@media (min-width: 34em){._m32ct8{color:#1a1a1a}}@media screen and (min-width: 1056px){._19nesb1{padding:0px}}@media screen and (min-width: 1056px){._jrggmc{flex-direction:column}}@media screen and (min-width: 1056px){._552kiq{margin:0 auto 5em}}@media screen and (max-width: 544px){._rna4ro{padding:0px}}@media screen and (min-width: 1056px){._149bqoo{max-width:1300px}}@media screen and (min-width: 545px) and (max-width: 1055px){._1syob6o{max-width:unset}}@media screen and (max-width: 544px){._aylhnx{flex-direction:column}}@media screen and (max-width: 544px){._1ovb59i{margin:auto}}@media screen and (max-width: 544px){._1oyl2xe{width:100%}}@media screen and (max-width: 544px){._1mmfes9{margin:0px}}@media screen and (max-width: 544px){._duy6tz{display:flex}}@media screen and (max-width: 544px){._rv3kk2{margin-bottom:1em}}@media screen and (max-width: 544px){._112lb0a .caption{margin-bottom:0}}@media screen and (min-width: 1056px){._192y3bk{margin:0px}}@media screen and (min-width: 1056px){._dc69mj{width:100%}}@media screen and (min-width: 545px) and (max-width: 1055px){._191d351{padding:0 4em}}@media screen and (min-width: 1056px){._1e0lyfy{display:flex}}@media screen and (min-width: 1056px){._k6y9ug{flex-direction:row}}@media screen and (min-width: 1056px){._1ij7gf7 .attribution{width:calc(50% - 280px)}}@media screen and (min-width: 1056px){._1xqp4r2 .attribution{text-align:right}}@media screen and (min-width: 1056px){._19one4x .attribution{padding-left:6em}}@media screen and (min-width: 1056px){._eugonq .attribution:before{content:none}}@media screen and (min-width: 1056px){._l378w0 .caption{width:560px}}@media screen and (max-width: 544px){._owlpzp{padding:0 1.25em}}</style>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <noscript>
      <style type="text/css">
        #transitionRoot {
          transform: translateY(0) !important;
          -webkit-transform: translateY(0) !important;
          opacity: 1 !important;
        }
        noscript img {
          display: block;
        }
      </style>
    </noscript>
    <script type="text/javascript">
      /**
       * Array.assign polyfill via MDN
       */
      if (typeof Object.assign != 'function') { Object.assign = function(target, varArgs) { 'use strict'; if (target == null) { throw new TypeError('Cannot convert undefined or null to object'); } var to = Object(target); for (var index = 1; index < arguments.length; index++) { var nextSource = arguments[index]; if (nextSource != null) { for (var nextKey in nextSource) { if (Object.prototype.hasOwnProperty.call(nextSource, nextKey)) { to[nextKey] = nextSource[nextKey]; } } } } return to; }; }
      /**
       * Array.findIndex polyfill via MDN
       */
      if (!Array.prototype.findIndex) { Object.defineProperty(Array.prototype, 'findIndex', { value: function(predicate) { if (this == null) { throw new TypeError('"this" is null or not defined'); } var o = Object(this); var len = o.length >>> 0; if (typeof predicate !== 'function') { throw new TypeError('predicate must be a function'); } var thisArg = arguments[1]; var k = 0; while (k < len) { var kValue = o[k]; if (predicate.call(thisArg, kValue, k, o)) { return k; } k++; } return -1; } }); }
    </script>
  </head><body data-reactid="3"><div id="trackingScripts" data-reactid="4"><!-- Facebook Pixel Code -->
<script>
!function(f,b,e,v,n,t,s)
{if(f.fbq)return;n=f.fbq=function()
{n.callMethod? n.callMethod.apply(n,arguments):n.queue.push(arguments)}
;
if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];
s.parentNode.insertBefore(t,s)}(window,document,'script',
'https://connect.facebook.net/en_US/fbevents.js');
fbq('init', '190747804793608'); 
fbq('track', 'PageView');
</script>
<noscript>
<img height="1" width="1" 
src="https://www.facebook.com/tr?id=190747804793608&ev=PageView
&noscript=1"/>
</noscript>
<!-- End Facebook Pixel Code -->

<!-- Chartbeat --><script type="text/javascript">var _sf_async_config = { uid: 65564, domain: 'quantamagazine.org', useCanonical: true };(function() {function loadChartbeat(){ window._sf_endpt = (new Date()).getTime(); var e = document.createElement('script'); e.setAttribute('language', 'javascript'); e.setAttribute('type', 'text/javascript'); e.setAttribute('src','//static.chartbeat.com/js/chartbeat.js'); document.body.appendChild(e); };var oldonload = window.onload;window.onload = (typeof window.onload != 'function') ?loadChartbeat : function(){ oldonload(); loadChartbeat(); };})();</script><!-- End Chartbeat -->

<!--Parsely--><script id="parsely-cfg" src="//cdn.parsely.com/keys/quantamagazine.org/p.js"></script></div><div id="root" data-reactid="5"><div id="app" data-reactroot="" data-reactid="1" data-react-checksum="177171673"><header class="nav fixed fit-t fit-l fit-r z9" data-reactid="2"><!-- react-empty: 3 --><div data-reactid="4"><div class="nav__container z1 fill-v mha absolute fit-x" data-reactid="5"><div class="nav__inner fill-v relative z1" data-reactid="6"><section class="outer header__inner flex fill-v relative z1" data-reactid="7"><div class="header__group flex relative z1" data-reactid="8"><a class="header__logo flex flex-items-center mr1 absolute fit-t fit-b _1s98oc1 is-active" href="/" data-reactid="9"><svg x="0px" y="0px" viewBox="0 0 353.5 49.5" enable-background="new 0 0 353.5 49.5" xml:space="preserve" data-reactid="10"><g id="logo" data-reactid="11"><path id="logo__mark" class="_riw402" fill="currentColor" d="M28.4,5.9c1,0,1.9-0.8,1.9-1.9c0-1-0.8-1.9-1.9-1.9c-1,0-1.9,0.8-1.9,1.9C26.5,5.1,27.3,5.9,28.4,5.9z M28.4,43.6c-1,0-1.9,0.8-1.9,1.9c0,1,0.8,1.9,1.9,1.9c1,0,1.9-0.8,1.9-1.9C30.3,44.5,29.4,43.6,28.4,43.6z M10.9,33.3 c-0.5-0.1-1-0.1-1.4,0.2c-0.4,0.3-0.7,0.7-0.9,1.1c-0.1,0.5-0.1,1,0.2,1.4c0.4,0.6,1,0.9,1.6,0.9c0.3,0,0.6-0.1,0.9-0.3 c0.4-0.3,0.8-0.7,0.9-1.1c0.1-0.5,0.1-1-0.2-1.4C11.8,33.7,11.4,33.4,10.9,33.3z M46.8,12.6c-0.5-0.1-1-0.1-1.4,0.2 c-0.9,0.5-1.2,1.7-0.7,2.6c0.3,0.4,0.7,0.7,1.1,0.9c0.2,0,0.3,0.1,0.5,0.1c0.3,0,0.6-0.1,0.9-0.3c0.4-0.3,0.8-0.7,0.9-1.1 c0.1-0.5,0.1-1-0.2-1.4C47.7,13,47.3,12.7,46.8,12.6z M47.3,33.5c-0.4-0.3-0.9-0.3-1.4-0.2c-0.3,0.1-0.6,0.3-0.8,0.5l-3.4-2 c0.2-0.5,0.2-1,0.1-1.5c-0.2-0.7-0.6-1.2-1.2-1.6c-1.3-0.7-2.9-0.3-3.6,1c-0.4,0.6-0.4,1.3-0.3,2c0,0.1,0,0.1,0.1,0.2l-6.3,3.6 c-0.5-0.6-1.2-0.9-2-0.9c-0.8,0-1.5,0.4-2,0.9l-6.3-3.6c0-0.1,0-0.1,0.1-0.2c0.2-0.7,0.1-1.4-0.3-2c-0.4-0.6-0.9-1-1.6-1.2 c-0.1,0-0.1,0-0.2,0v-7.3c0.1,0,0.1,0,0.2,0c0.7-0.2,1.2-0.6,1.6-1.2c0.4-0.6,0.4-1.3,0.3-2c0-0.1,0-0.1-0.1-0.2l6.3-3.6 c0.5,0.6,1.2,0.9,2,0.9c1.5,0,2.6-1.2,2.6-2.6s-1.2-2.6-2.6-2.6s-2.6,1.2-2.6,2.6c0,0.3,0.1,0.6,0.2,0.9l-6.3,3.6 c-0.2-0.2-0.4-0.4-0.7-0.6c-0.6-0.4-1.3-0.4-2-0.3c-0.7,0.2-1.2,0.6-1.6,1.2c-0.7,1.3-0.3,2.9,1,3.6l0,0c0.3,0.1,0.5,0.2,0.8,0.3 v7.3c-0.3,0.1-0.6,0.1-0.8,0.3c-0.6,0.4-1,0.9-1.2,1.6c-0.2,0.7-0.1,1.4,0.3,2c0.4,0.6,0.9,1,1.6,1.2c0.2,0.1,0.5,0.1,0.7,0.1 c0.5,0,0.9-0.1,1.3-0.4c0.3-0.1,0.5-0.3,0.7-0.6l6.3,3.6c-0.1,0.3-0.2,0.6-0.2,0.9c0,1.5,1.2,2.6,2.6,2.6s2.6-1.2,2.6-2.6 c0-0.3-0.1-0.6-0.2-0.9l6.3-3.6c0.2,0.2,0.4,0.4,0.7,0.6l0,0c0.4,0.2,0.9,0.4,1.3,0.4c0.7,0,1.5-0.3,2-0.9l3.4,2 c-0.1,0.3-0.1,0.6,0,1c0.1,0.5,0.4,0.9,0.9,1.1c0.3,0.2,0.6,0.3,0.9,0.3c0.2,0,0.3,0,0.5-0.1c0.5-0.1,0.9-0.4,1.1-0.9 c0.3-0.4,0.3-0.9,0.2-1.4C48,34.2,47.7,33.7,47.3,33.5z M9.5,16c0.3,0.2,0.6,0.3,0.9,0.3c0.2,0,0.3,0,0.5-0.1 c0.5-0.1,0.9-0.4,1.1-0.9c0.5-0.9,0.2-2.1-0.7-2.6c-0.9-0.5-2.1-0.2-2.6,0.7c-0.3,0.4-0.3,0.9-0.2,1.4C8.7,15.4,9,15.8,9.5,16z M15.7,2.8c0.7-0.4,0.9-1.3,0.5-2c-0.4-0.7-1.3-0.9-2-0.5c-0.7,0.4-0.9,1.3-0.5,2C14.1,2.9,15,3.2,15.7,2.8z M41.1,46.8 c-0.7,0.4-0.9,1.3-0.5,2c0.4,0.7,1.3,0.9,2,0.5c0.7-0.4,0.9-1.3,0.5-2C42.7,46.6,41.8,46.4,41.1,46.8z M15.7,46.8 c-0.7-0.4-1.6-0.2-2,0.5c-0.4,0.7-0.2,1.6,0.5,2c0.7,0.4,1.6,0.2,2-0.5C16.6,48.1,16.4,47.2,15.7,46.8z M41.1,2.8 c0.7,0.4,1.6,0.2,2-0.5c0.4-0.7,0.2-1.6-0.5-2c-0.7-0.4-1.6-0.2-2,0.5C40.1,1.4,40.4,2.3,41.1,2.8z M55.3,23.3 c-0.8,0-1.5,0.7-1.5,1.5c0,0.8,0.7,1.5,1.5,1.5c0.8,0,1.5-0.7,1.5-1.5C56.7,24,56.1,23.3,55.3,23.3z M1.5,23.3C0.7,23.3,0,24,0,24.8 c0,0.8,0.7,1.5,1.5,1.5s1.5-0.7,1.5-1.5C2.9,24,2.3,23.3,1.5,23.3z M39.1,21.2c0.4,0,0.9-0.1,1.3-0.4c1.3-0.7,1.7-2.3,1-3.6 c-0.7-1.3-2.3-1.7-3.6-1l0,0c-0.6,0.4-1,0.9-1.2,1.6c-0.2,0.7-0.1,1.4,0.3,2C37.3,20.7,38.2,21.2,39.1,21.2z" data-reactid="12"></path><path id="logo__quanta" class="_riw402" fill="currentColor" d="M309.9,14c0,1.1-0.9,1.8-2,1.8c-0.9,0-1.8-0.7-1.8-1.8c0-1.2,0.8-2,1.9-2C309.2,12,309.9,12.8,309.9,14z M85.5,28.7c0.6-1.3,0.8-2.6,0.8-4.2c0-2.9-1-5.2-2.9-7.1c-1.9-1.9-4.2-2.8-7-2.8s-5.1,0.9-7,2.8c-1.9,1.9-2.9,4.2-2.9,7.1 c0,2.9,1,5.2,2.9,7.1c1.9,1.9,4.2,2.8,7,2.8c2.7,0,4.9-0.9,6.8-2.6l2.6,1.7l2.2-3.3L85.5,28.7z M82.1,26.5L79.8,25l-2.2,3.3l2.3,1.5 c-1,0.7-2.1,1.1-3.5,1.1c-1.8,0-3.2-0.6-4.3-1.7c-1.1-1.2-1.6-2.7-1.6-4.6c0-1.9,0.5-3.4,1.6-4.6c1.1-1.2,2.5-1.7,4.3-1.7 c1.8,0,3.2,0.6,4.3,1.7c1.1,1.1,1.6,2.7,1.6,4.6C82.3,25.2,82.2,25.9,82.1,26.5z M103.2,27.3c0,1.2-0.3,2.1-0.9,2.8 c-0.6,0.6-1.5,1-2.5,1s-1.9-0.3-2.5-1c-0.6-0.6-0.9-1.6-0.9-2.8v-8.5h-3.9v9c0,2,0.6,3.7,1.7,4.8c1.1,1.2,2.5,1.7,4.3,1.7 c2.2,0,3.6-0.4,4.8-1.7v1.5h3.9V18.9h-3.9V27.3z M144.3,18.9c-2.2,0-3.6,0.4-4.8,1.7v-1.5h-3.9v15.4h3.9V26c0-1.2,0.3-2.1,0.9-2.8 c0.6-0.6,1.5-1,2.5-1c1.1,0,1.9,0.3,2.5,1c0.6,0.6,0.9,1.6,0.9,2.8v8.5h3.9v-9c0-2-0.6-3.7-1.7-4.8C147.4,19.5,146,18.9,144.3,18.9z M124.8,18.9v1.5c-0.8-0.8-2.7-1.7-4.8-1.7c-2.1,0-3.8,0.7-5.2,2.2c-1.4,1.5-2.1,3.4-2.1,5.7c0,2.3,0.7,4.2,2.1,5.7 c1.4,1.5,3.1,2.2,5.2,2.2c1.3,0,3-0.2,4.8-1.6v1.4h3.9V18.9H124.8z M123.6,29.9c-0.8,0.8-1.8,1.2-2.8,1.2c-1.1,0-2-0.4-2.8-1.2 c-0.8-0.8-1.2-1.9-1.2-3.3c0-1.4,0.4-2.5,1.2-3.3c0.8-0.8,1.8-1.2,2.8-1.2c1.1,0,2,0.4,2.9,1.2c0.8,0.8,1.2,1.9,1.2,3.3 C124.8,28,124.4,29.1,123.6,29.9z M180.1,18.9v1.5c-0.8-0.8-2.7-1.7-4.8-1.7c-2.1,0-3.8,0.7-5.2,2.2c-1.4,1.5-2.1,3.4-2.1,5.7 c0,2.3,0.7,4.2,2.1,5.7c1.4,1.5,3.1,2.2,5.2,2.2c1.3,0,3-0.2,4.8-1.6v1.4h3.9V18.9H180.1z M178.9,29.9c-0.8,0.8-1.8,1.2-2.8,1.2 c-1.1,0-2-0.4-2.8-1.2c-0.8-0.8-1.2-1.9-1.2-3.3c0-1.4,0.4-2.5,1.2-3.3C174,22.4,175,22,176,22c1.1,0,2,0.4,2.9,1.2 c0.8,0.8,1.2,1.9,1.2,3.3C180.1,28,179.7,29.1,178.9,29.9z M161.4,31c-1.1,0-1.9-0.7-1.9-2.1v-6.4h4.1v-3.2h-4.1v-4h-3.7v4v3.2v6.4 c0,3.7,2.1,5.5,5.3,5.4c1.1,0,2-0.2,3-0.6l-1-3.1C162.6,30.9,161.9,31,161.4,31z" data-reactid="13"></path><path id="logo__magazine" class="_b4g2te" fill="currentColor" d="M218.3,33.5l-0.1,1c-1.1,0-2.4-0.1-3.9-0.1c-1.5,0-2.7,0.1-3.6,0.1v-1c1.6-0.1,2-0.3,2-0.9 c0.1-0.8,0.1-2.4,0.1-5.1c0-4.4,0-4.9-0.3-5.4c-0.4-0.9-1.2-1.4-2.4-1.4c-1.6,0-3,1-3.7,2.3c-0.2,0.5-0.4,0.9-0.4,1.5v4.7 c0,1.3,0,2.6,0.1,3.4c0,0.7,0.4,0.9,2.2,0.9l-0.1,1c-0.9,0-2.5-0.1-3.9-0.1c-1.4,0-2.6,0.1-3.5,0.1v-1c1.6-0.1,2-0.2,2-1 c0.1-1.1,0.1-2.2,0.1-4.4v-2.8c0-2.4,0-2.8-0.2-3.3c-0.4-0.9-1.1-1.3-2.3-1.3c-1.5,0-3,0.9-3.8,2.4c-0.3,0.6-0.4,0.9-0.4,1.7v4.6 c0,1.4,0,2.5,0.1,3.3c0.1,0.7,0.4,0.8,2.1,0.9l-0.1,0.9c-0.8,0-2.5-0.1-3.8-0.1c-1.3,0-2.6,0.1-3.7,0.1v-1c1.8,0,2.1-0.2,2.1-1 c0-0.9,0.1-2.3,0.1-4.2v-2.9c0-1.9,0-3.4-0.1-4.3c0-0.5-0.3-0.6-2.2-0.6l0.1-0.9c1.7,0,3.6-0.2,5.2-0.5c0.1,0.6,0.2,2.2,0.2,2.7 c1.3-1.3,3.2-2.9,5.7-2.9c2,0,2.9,0.8,3.4,1.5c0.3,0.4,0.5,0.9,0.6,1.3c1.2-1.2,3-2.8,5.7-2.8c2.1,0,3.3,1.1,3.8,2 c0.4,0.7,0.5,1.5,0.5,2.3v9.4C216,33.3,216.2,33.4,218.3,33.5z M238.4,31l0.9,0.4c-0.5,2.5-1.9,3.4-3.5,3.4c-1.8,0-2.5-1.1-2.7-2.6 c-1.5,1.7-3.4,2.6-5,2.6c-2.7,0-4.3-1.9-4.3-4.3c0-1.4,0.6-2.6,2-3.2c2.4-1,6-2.1,7.4-3.1v-1.4c0-1.5-0.7-3-2.7-3 c-2.1,0-3,1.1-3,2.5c0,0.4,0.1,0.8,0.1,1.1c0.1,0.3-0.1,0.6-0.3,0.7c-0.3,0.2-0.7,0.4-1.2,0.4c-0.8,0-1.5-0.4-1.5-1.6 c0-1.8,2.6-4.1,6.4-4.1c3,0,4.3,1.3,4.7,2c0.3,0.5,0.5,1.2,0.5,1.8v8.9c0,1.3,0.4,1.5,0.8,1.5C237.5,33.1,238,32.4,238.4,31z M233,25.3c-1,0.5-2.8,1.3-4.1,2c-1.1,0.6-1.8,1.1-1.8,2.7c0,1.7,0.9,3,2.5,3c1.7,0,2.7-1,3.3-2.3c0.1-0.4,0.2-1,0.2-1.5V25.3z M255.8,27.1c-1.3,0-2.8-0.1-3.7-0.1l0,0.9l1.5,0.1c1.2,0.1,1.4,0.3,1.4,1.3c0,1,0,2.4-0.1,3.2c-0.1,0.8-1.1,1.3-2.5,1.3 c-1.5,0-2.8-0.5-3.8-1.8c-0.9-1.1-1.3-3.1-1.3-5.1c0-2.2,0.5-3.9,1.4-5.1c0.8-1.2,2-1.8,3.5-1.8c2.6,0,4.1,1.7,4.4,5l0.9,0 c-0.1-2.1,0.2-4.8,0.4-5.7l-0.8-0.3l-0.5,1.3c-0.5-0.5-1.8-1.4-4.3-1.4c-1.6,0-3,0.3-4.2,1c-2.4,1.3-3.8,3.9-3.8,7 c0,2.4,0.6,4.2,1.7,5.5c1.2,1.5,3.2,2.3,6.1,2.3c1.2,0,2.5-0.3,3.6-0.6c1-0.3,1.8-0.6,2.4-0.7c-0.1-0.5-0.2-1.3-0.2-2.5 c0-0.7,0-1.7,0.1-2.3c0-0.5,0.3-0.6,1.5-0.8l0-0.9C258.4,27.1,257.1,27.1,255.8,27.1z M279.4,31l0.9,0.4c-0.5,2.5-1.9,3.4-3.5,3.4 c-1.8,0-2.5-1.1-2.7-2.6c-1.5,1.7-3.4,2.6-5,2.6c-2.7,0-4.3-1.9-4.3-4.3c0-1.4,0.6-2.6,2-3.2c2.4-1,6-2.1,7.4-3.1v-1.4 c0-1.5-0.7-3-2.7-3c-2.1,0-3,1.1-3,2.5c0,0.4,0.1,0.8,0.1,1.1c0.1,0.3-0.1,0.6-0.3,0.7c-0.3,0.2-0.7,0.4-1.2,0.4 c-0.8,0-1.5-0.4-1.5-1.6c0-1.8,2.6-4.1,6.4-4.1c3,0,4.3,1.3,4.7,2c0.3,0.5,0.5,1.2,0.5,1.8v8.9c0,1.3,0.4,1.5,0.8,1.5 C278.5,33.1,279,32.4,279.4,31z M274,25.3c-1,0.5-2.8,1.3-4.1,2c-1.1,0.6-1.8,1.1-1.8,2.7c0,1.7,0.9,3,2.5,3c1.7,0,2.7-1,3.3-2.3 c0.1-0.4,0.2-1,0.2-1.5V25.3z M295.1,33c-1,0.2-2.8,0.3-5.6,0.3c1.8-2.8,7.1-10.8,7.9-12c0.4-0.7,0.8-1.4,0.9-2.1 c-1.4,0-2.6,0.1-5.3,0.1h-3c-2,0-3.2-0.1-3.8-0.4c0,2.1-0.2,4.4-0.4,5.8l0.9-0.2c0.2-0.8,0.4-1.7,0.7-2.6c0.4-1.1,0.9-1.4,2.4-1.5 c1.4-0.1,2.9-0.1,4.4-0.1c-0.9,1.8-5.2,8.8-9,13.4l0.4,0.7c0.6,0,1.7-0.1,3.7-0.1c3.8,0,7.8,0.1,9.1,0.2c0.1-1.6,0.4-4.3,0.6-5.8 l-0.9-0.2C297.3,32,296.5,32.9,295.1,33z M309.9,32.5c0-0.7-0.1-1.9-0.1-4.1v-4.1c0-2.6,0.1-4.6,0.1-5.4c-1.6,0.4-3.9,0.5-5.6,0.6 l0,0.9c1.9-0.1,2.2,0,2.2,0.5c0,0.5,0.1,1.7,0.1,3.6v3.9c0,2-0.1,3.5-0.1,4.1c0,0.6-0.3,0.9-2.4,1l0,1c1.1,0,2.1-0.1,3.8-0.1 c1.7,0,3,0.1,4,0.1l0-1C310.3,33.4,309.9,33.3,309.9,32.5z M332.9,32.5v-9.3c0-0.8-0.1-1.6-0.5-2.2c-0.5-1.1-1.7-2.1-4-2.1 c-2.5,0-4.2,1.5-5.5,2.7c0-0.5-0.1-1.9-0.2-2.6c-1.6,0.3-3.4,0.5-5.1,0.5l-0.1,0.9c1.8,0,2.1,0.1,2.1,0.6c0.1,0.9,0.1,2.4,0.1,4.3 v3.1c0,1.7-0.1,3-0.1,4c0,0.8-0.3,0.9-2.1,1v1c1,0,2.2-0.1,3.7-0.1c1.3,0,3,0.1,3.9,0.1l0.1-1c-1.8-0.1-2.1-0.2-2.1-0.9 c-0.1-0.8-0.1-2.2-0.1-3.7v-4.1c0-0.8,0.1-1.3,0.4-1.8c0.8-1.4,2.1-2.2,3.8-2.2c1.2,0,1.9,0.5,2.4,1.3c0.3,0.6,0.4,1,0.4,5.4 c0,2.8-0.1,4.4-0.1,5.1c-0.1,0.7-0.4,0.8-2,0.9l0,1c0.8,0,2-0.1,3.6-0.1c1.5,0,2.8,0.1,3.9,0.1l0.1-1 C333.1,33.4,332.9,33.3,332.9,32.5z M352.5,29.8l0.9,0.5c-1.1,3.2-3.3,4.5-6.3,4.5c-2.7,0-4.4-0.8-5.6-2.4c-0.9-1.2-1.5-3.2-1.5-5.3 c0-4.4,2.5-8.3,7.4-8.3c5.1,0,6,4,6,6.1c0,0.7-0.2,1.2-0.7,1.4c-0.6,0.2-2.3,0.4-4.6,0.5c-1.2,0-3.1,0-4.6,0 c-0.1,1.9,0.4,3.6,1.1,4.6c0.8,1.2,1.9,1.8,3.5,1.8C350.3,33.2,351.6,32.2,352.5,29.8z M343.6,25.7h2.9c1.7,0,2.6-0.1,3.1-0.2 c0.5-0.1,0.7-0.5,0.7-1.2c0-1.9-0.8-4.4-3.1-4.4C344.8,19.9,343.7,22.8,343.6,25.7z" data-reactid="14"></path></g></svg></a></div><div class="header__divider flex mh1 relative _b4g2te" data-reactid="15"></div><nav class="header__main header__group flex relative" data-reactid="16"><ul class="flex fill-v" data-reactid="17"><li class="flex flex-items-center fill-v" data-reactid="18"><a class="header__link flex flex-items-center relative mh05 ph025 transition--color _100werz" href="/physics/" data-reactid="19"><h4 class="mv0" data-reactid="20">Physics</h4><span class="_480t39 __underline" data-reactid="21"></span></a></li><li class="flex flex-items-center fill-v" data-reactid="22"><a class="header__link flex flex-items-center relative mh05 ph025 transition--color _100werz" href="/mathematics/" data-reactid="23"><h4 class="mv0" data-reactid="24">Mathematics</h4><span class="_480t39 __underline" data-reactid="25"></span></a></li><li class="flex flex-items-center fill-v" data-reactid="26"><a class="header__link flex flex-items-center relative mh05 ph025 transition--color _100werz" href="/biology/" data-reactid="27"><h4 class="mv0" data-reactid="28">Biology</h4><span class="_480t39 __underline" data-reactid="29"></span></a></li><li class="flex flex-items-center fill-v" data-reactid="30"><a class="header__link flex flex-items-center relative mh05 ph025 transition--color _100werz" href="/computer-science/" data-reactid="31"><h4 class="mv0" data-reactid="32">Computer Science</h4><span class="_480t39 __underline" data-reactid="33"></span></a></li><li class="flex flex-items-center fill-v" data-reactid="34"><a class="header__link flex flex-items-center relative mh05 ph025 transition--color _100werz" href="/archive/" data-reactid="35"><h4 class="mv0" data-reactid="36">All Articles</h4><span class="_480t39 __underline" data-reactid="37"></span></a></li></ul></nav><div class="header__group flex flex-auto relative" data-reactid="38"><ul class="header__icons flex flex-auto" data-reactid="39"><li class="header__bookmarks header__icon flex flex-items-center mh05 z1 _100werz" data-reactid="40"><button class="relative" data-reactid="41"><svg viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="42"><path fill="currentColor" d="M37.1,5.6v34.7l-8.9-5.1l-2.7-1.6l-2.8,1.5l-9.8,5.4V5.6H37.1 M42.7,0H7.3v50l18.1-9.9L42.7,50V0L42.7,0z" data-reactid="43"></path></svg></button></li><li class="header__account header__icon flex flex-items-center mh05 z1 _100werz" data-reactid="44"><button class="relative" data-reactid="45"><svg viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="46"><path fill="currentColor" d="M35.2 29.9c3.9-3.1 6.4-7.8 6.4-13.2C41.7 7.5 34.2 0 25 0S8.3 7.5 8.3 16.7c0 5.4 2.5 10.1 6.4 13.2C6.1 33.4 0 41.1 0 50h5.6c0-9.1 8.7-16.5 19.4-16.5S44.4 40.9 44.4 50H50c0-8.9-6.1-16.6-14.8-20.1zM25 5.6c6.1 0 11.1 5 11.1 11.2S31.1 28 25 28s-11.1-5-11.1-11.2S18.9 5.6 25 5.6z" data-reactid="47"></path></svg></button></li><li class="header__search header__icon relative flex flex-items-center flex-auto flex-justify-end mh05 z1 _100werz" data-reactid="48"><button class="relative" data-reactid="49"><svg viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="50"><path fill="currentColor" d="M48.8 46.2l-9.2-9.4c3.5-3.9 5.7-9.1 5.7-14.7C45.3 9.9 35.4 0 23.2 0s-22 9.9-22 22.1 9.9 22.1 22 22.1c4.4 0 8.5-1.3 12-3.6l9.5 9.5 4.1-3.9zM7.1 22.1c0-8.9 7.2-16.2 16.2-16.2 8.9 0 16.2 7.3 16.2 16.2s-7.3 16.2-16.2 16.2c-9-.1-16.2-7.3-16.2-16.2z" data-reactid="51"></path></svg></button></li><li class="header__hamburger-outer flex flex-items-center mh05 relative" data-reactid="52"><div class="header__hamburger" data-reactid="53"><button class="hamburger block z10 relative theme__header-primary mha _b4g2te" data-reactid="54"><span class="hamburger__bar absolute fit-x mxa" data-reactid="55"></span><span class="hamburger__bar absolute fit-x mxa" data-reactid="56"></span><span class="hamburger__bar absolute fit-x mxa" data-reactid="57"></span></button></div></li></ul></div></section></div></div></div><!-- react-empty: 58 --></header><style id="Theme" type="text/css" data-reactid="59">
      .theme__text {
        color: #1a1a1a;
      }
      .theme__text-background,
      .flickity-page-dots .dot {
        background-color: #1a1a1a;
      }
      .theme__text-hover:hover {
        color: #1a1a1a;
      }
      .theme__background {
        color: white;
      }
      .theme__background-background {
        background-color: white;
      }
      .putz__inner,
      .theme__accent {
        color: #ff8600;
      }
      .theme__accent-background,
      .flickity-page-dots .dot.is-selected {
        background-color: #ff8600;
      }
      .theme__accent-hover:hover, .download-button {
        color: #ff8600;
      }

      .theme__anchors--underline a {
        box-shadow: inset 0 0 0 rgba(0, 0, 0, 0), 0 1px 0 #1a1a1a;
      }
      .theme__anchors--underline a:hover {
        box-shadow: inset 0 0 0 rgba(0, 0, 0, 0), 0 1px 0 #ff8600;
      }
      .theme__anchors--solid a {
        color: #ff8600;
      }
      .theme__anchors--solid a:hover {
        color: #1a1a1a;
      }

      .theme__anchors--underline h2.large a {
        color: #1a1a1a;
        box-shadow: none;
      }

      .theme__anchors--underline h2.large a:hover {
        color: #ff8600;
      }

      .sshare__inner {
        background-color: #1a1a1a;
        color: #1a1a1a;
      }
      .sshare__inner a {
        color: white;
      }
      .sshare__inner a:hover, .sshare__inner a:focus {
        color: #ff8600;
      }

      /* For javascript hovers on cards, needs to be themable */
      .is-hover .card__title {
        color: #ff8600;
      }

      ::selection {
        background: rgba(255, 134, 0, 0.4);
      }
      ::-moz-selection {
        background: rgba(255, 134, 0, 0.4);
      }
  </style><div data-reactid="60"><!-- react-empty: 61 --></div><div data-reactid="62"><!-- react-empty: 63 --></div><div data-reactid="64"><!-- react-empty: 65 --></div><div data-reactid="66"><!-- react-empty: 67 --></div><div data-reactid="68"><!-- react-empty: 69 --></div><div id="transitionRoot" class="is-visible" data-reactid="70"><div data-reactid="71"><!-- react-empty: 72 --><div id="postContent" class="post" data-reactid="73"><div class="fixed fit-t fit-l fit-r z10" data-reactid="74"><div class="nav__local fill-v z1 absolute fit-x is-hidden" data-reactid="75"><section class="outer header__inner flex fill-v relative" data-reactid="76"><div class="header__group flex relative z1" data-reactid="77"><a class="header__logo header__logo--local flex flex-items-center absolute fit-t fit-b _16jm4kw _e16twb is-active" href="/" data-reactid="78"><svg x="0px" y="0px" viewBox="0 0 56.7 49.5" enable-background="new 0 0 56.7 49.5" data-reactid="79"><path id="logo__mark__icon" class="c-1a1a1a _m32ct8" fill="currentColor" d="M28.4,5.9c1,0,1.9-0.8,1.9-1.9c0-1-0.8-1.9-1.9-1.9c-1,0-1.9,0.8-1.9,1.9C26.5,5.1,27.3,5.9,28.4,5.9z M28.4,43.6c-1,0-1.9,0.8-1.9,1.9c0,1,0.8,1.9,1.9,1.9c1,0,1.9-0.8,1.9-1.9C30.3,44.5,29.4,43.6,28.4,43.6z M10.9,33.3 c-0.5-0.1-1-0.1-1.4,0.2c-0.4,0.3-0.7,0.7-0.9,1.1c-0.1,0.5-0.1,1,0.2,1.4c0.4,0.6,1,0.9,1.6,0.9c0.3,0,0.6-0.1,0.9-0.3 c0.4-0.3,0.8-0.7,0.9-1.1c0.1-0.5,0.1-1-0.2-1.4C11.8,33.7,11.4,33.4,10.9,33.3z M46.8,12.6c-0.5-0.1-1-0.1-1.4,0.2 c-0.9,0.5-1.2,1.7-0.7,2.6c0.3,0.4,0.7,0.7,1.1,0.9c0.2,0,0.3,0.1,0.5,0.1c0.3,0,0.6-0.1,0.9-0.3c0.4-0.3,0.8-0.7,0.9-1.1 c0.1-0.5,0.1-1-0.2-1.4C47.7,13,47.3,12.7,46.8,12.6z M47.3,33.5c-0.4-0.3-0.9-0.3-1.4-0.2c-0.3,0.1-0.6,0.3-0.8,0.5l-3.4-2 c0.2-0.5,0.2-1,0.1-1.5c-0.2-0.7-0.6-1.2-1.2-1.6c-1.3-0.7-2.9-0.3-3.6,1c-0.4,0.6-0.4,1.3-0.3,2c0,0.1,0,0.1,0.1,0.2l-6.3,3.6 c-0.5-0.6-1.2-0.9-2-0.9c-0.8,0-1.5,0.4-2,0.9l-6.3-3.6c0-0.1,0-0.1,0.1-0.2c0.2-0.7,0.1-1.4-0.3-2c-0.4-0.6-0.9-1-1.6-1.2 c-0.1,0-0.1,0-0.2,0v-7.3c0.1,0,0.1,0,0.2,0c0.7-0.2,1.2-0.6,1.6-1.2c0.4-0.6,0.4-1.3,0.3-2c0-0.1,0-0.1-0.1-0.2l6.3-3.6 c0.5,0.6,1.2,0.9,2,0.9c1.5,0,2.6-1.2,2.6-2.6s-1.2-2.6-2.6-2.6s-2.6,1.2-2.6,2.6c0,0.3,0.1,0.6,0.2,0.9l-6.3,3.6 c-0.2-0.2-0.4-0.4-0.7-0.6c-0.6-0.4-1.3-0.4-2-0.3c-0.7,0.2-1.2,0.6-1.6,1.2c-0.7,1.3-0.3,2.9,1,3.6l0,0c0.3,0.1,0.5,0.2,0.8,0.3 v7.3c-0.3,0.1-0.6,0.1-0.8,0.3c-0.6,0.4-1,0.9-1.2,1.6c-0.2,0.7-0.1,1.4,0.3,2c0.4,0.6,0.9,1,1.6,1.2c0.2,0.1,0.5,0.1,0.7,0.1 c0.5,0,0.9-0.1,1.3-0.4c0.3-0.1,0.5-0.3,0.7-0.6l6.3,3.6c-0.1,0.3-0.2,0.6-0.2,0.9c0,1.5,1.2,2.6,2.6,2.6s2.6-1.2,2.6-2.6 c0-0.3-0.1-0.6-0.2-0.9l6.3-3.6c0.2,0.2,0.4,0.4,0.7,0.6l0,0c0.4,0.2,0.9,0.4,1.3,0.4c0.7,0,1.5-0.3,2-0.9l3.4,2 c-0.1,0.3-0.1,0.6,0,1c0.1,0.5,0.4,0.9,0.9,1.1c0.3,0.2,0.6,0.3,0.9,0.3c0.2,0,0.3,0,0.5-0.1c0.5-0.1,0.9-0.4,1.1-0.9 c0.3-0.4,0.3-0.9,0.2-1.4C48,34.2,47.7,33.7,47.3,33.5z M9.5,16c0.3,0.2,0.6,0.3,0.9,0.3c0.2,0,0.3,0,0.5-0.1 c0.5-0.1,0.9-0.4,1.1-0.9c0.5-0.9,0.2-2.1-0.7-2.6c-0.9-0.5-2.1-0.2-2.6,0.7c-0.3,0.4-0.3,0.9-0.2,1.4C8.7,15.4,9,15.8,9.5,16z M15.7,2.8c0.7-0.4,0.9-1.3,0.5-2c-0.4-0.7-1.3-0.9-2-0.5c-0.7,0.4-0.9,1.3-0.5,2C14.1,2.9,15,3.2,15.7,2.8z M41.1,46.8 c-0.7,0.4-0.9,1.3-0.5,2c0.4,0.7,1.3,0.9,2,0.5c0.7-0.4,0.9-1.3,0.5-2C42.7,46.6,41.8,46.4,41.1,46.8z M15.7,46.8 c-0.7-0.4-1.6-0.2-2,0.5c-0.4,0.7-0.2,1.6,0.5,2c0.7,0.4,1.6,0.2,2-0.5C16.6,48.1,16.4,47.2,15.7,46.8z M41.1,2.8 c0.7,0.4,1.6,0.2,2-0.5c0.4-0.7,0.2-1.6-0.5-2c-0.7-0.4-1.6-0.2-2,0.5C40.1,1.4,40.4,2.3,41.1,2.8z M55.3,23.3 c-0.8,0-1.5,0.7-1.5,1.5c0,0.8,0.7,1.5,1.5,1.5c0.8,0,1.5-0.7,1.5-1.5C56.7,24,56.1,23.3,55.3,23.3z M1.5,23.3C0.7,23.3,0,24,0,24.8 c0,0.8,0.7,1.5,1.5,1.5s1.5-0.7,1.5-1.5C2.9,24,2.3,23.3,1.5,23.3z M39.1,21.2c0.4,0,0.9-0.1,1.3-0.4c1.3-0.7,1.7-2.3,1-3.6 c-0.7-1.3-2.3-1.7-3.6-1l0,0c-0.6,0.4-1,0.9-1.2,1.6c-0.2,0.7-0.1,1.4,0.3,2C37.3,20.7,38.2,21.2,39.1,21.2z" data-reactid="80"></path></svg></a></div><div class="header__divider flex mh075 relative c-999999" data-reactid="81"></div><div class="nav__local__left header__group flex relative flex-items-center" data-reactid="82"><h1 class="ml025 h3 noe mv0" data-reactid="83">Machines Beat Humans on a Reading Test. But Do They Understand?</h1></div><div class="nav__local__right header__group flex relative flex-items-center flex-auto flex-justify-end h5" data-reactid="84"><div class="comments-button mr05 flex flex-items-center h5 theme__accent-hover" data-reactid="85"><a href="#comments" class="flex flex-items-center pangram" data-reactid="86"><svg class="o2" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="87"><path fill="currentColor" d="M9.4 4.2h31.2c8.6 0 9.4 7 9.4 15.6s-.7 15.6-9.4 15.6h-2.2l-.9 9.4-18.8-9.4H9.4c-8.6 0-9.4-7-9.4-15.6S.7 4.2 9.4 4.2z" data-reactid="88"></path></svg><div data-reactid="89"><span class="comments-button__count ml075 small mbold disqus-comment-count" data-disqus-identifier="77108 https://www.quantamagazine.org/?p=77108"></span></div></a></div><span class="o-divider mh1 relative" data-reactid="90"></span><div class="relative" data-reactid="91"><button class="bookmark-button mh05 flex flex-items-center black theme__accent-hover o8" aria-expanded="false" data-reactid="92"><svg class="icon" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="93"><path fill="currentColor" d="M2.1 0h45.8v50L25.5 37.5 2.1 50V0z" data-reactid="94"></path></svg></button><div class="q-tooltip hidden force-mobile-placement" style="width:130px;top:55px;" data-reactid="95"><div class="q-tooltip-content" data-reactid="96"><div class="q-tooltip-arrow" data-reactid="97"></div><div class="q-tooltip-inner" role="tooltip" data-reactid="98"><h6 class="relative z1 uppercase kern--w mx025" data-reactid="99"><span class="small no-wrap" data-reactid="100">Read Later</span></h6></div></div></div></div><span class="o-divider mh1 relative" data-reactid="101"></span><div class="nav__local__share mr1 ph05 pv2 flex flex-items-center transition--color pointer relative c-1a1a1a _hover-c-ff8600" data-reactid="102"><span class="__label flex flex-items-center absolute fit-t fit-b fit-r mr05" data-reactid="103"><svg class="icon-l o2" x="0px" y="0px" viewBox="0 0 50 50" enable-background="new 0 0 50 50" xml:space="preserve" data-reactid="104"><path fill="currentColor" d="M41.9,34.2c-2.2,0-4.1,0.9-5.5,2.3L15.7,26.2c0.1-0.4,0.1-0.8,0.1-1.2c0-0.4,0-0.8-0.1-1.2l20.7-10.3 c1.4,1.4,3.4,2.3,5.5,2.3c4.2,0,7.7-3.4,7.7-7.7s-3.4-7.7-7.7-7.7c-4.2,0-7.7,3.4-7.7,7.7c0,0.4,0,0.8,0.1,1.2L13.6,19.7 c-1.4-1.4-3.4-2.3-5.5-2.3c-4.2,0-7.7,3.4-7.7,7.7c0,4.2,3.4,7.7,7.7,7.7c2.2,0,4.1-0.9,5.5-2.3l20.7,10.3c-0.1,0.4-0.1,0.8-0.1,1.2 c0,4.2,3.4,7.7,7.7,7.7c4.2,0,7.7-3.4,7.7-7.7C49.6,37.7,46.1,34.2,41.9,34.2L41.9,34.2z M41.9,34.2" data-reactid="105"></path></svg><h6 class="uppercase kern mv0 ml1" data-reactid="106">Share</h6></span><span class="__links flex flex-items-center absolute fit-x mxa" data-reactid="107"><div data-reactid="108"><div class="social-links social-links--share flex flex-justify-between" data-reactid="109"><a href="http://www.facebook.com/sharer.php?u=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="_blank" class="social-links__link flex flex-items-center relative facebook" data-reactid="110"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="111"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="112"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="113"><path fill="currentColor" d="M13 16.5h5.1v-5c-.2-2.7.3-5.4 1.7-7.7 1.8-2.5 4.9-4 8-3.8 3.1-.1 6.2.2 9.2 1l-1.3 7.7C34.4 8.3 33 8 31.6 8c-2 0-3.8.7-3.8 2.7v5.9H36l-.6 7.5h-7.6V50h-9.6V23.9H13v-7.4z" data-reactid="114"></path></svg></div></a><a href="https://twitter.com/share?url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/&amp;text=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?&amp;via=QuantaMagazine" target="_blank" class="social-links__link flex flex-items-center relative twitter" data-reactid="115"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="116"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="117"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="118"><path fill="currentColor" d="M50 9.9c-1.9.8-3.8 1.3-5.9 1.6 2.1-1.3 3.7-3.2 4.5-5.6-2 1.2-4.2 2-6.5 2.5-3.8-4.1-10.3-4.5-14.5-.8-2.8 2.5-4 6.3-3.1 10-8.2-.5-15.8-4.3-21-10.6-2.7 4.6-1.3 10.5 3.2 13.5C5 20.4 3.4 20 2 19.2c0 4.8 3.4 8.9 8.2 9.9-.9.2-1.8.4-2.7.3-.6 0-1.3-.1-1.9-.2 1.3 4.1 5.2 6.9 9.5 7C10.8 39.5 5.4 41 0 40.4c13.5 8.5 31.5 4.6 40.2-8.7 3-4.6 4.6-10 4.6-15.5v-1.3c2-1.3 3.7-3.1 5.2-5" data-reactid="119"></path></svg></div></a><a href="#0" target="" class="social-links__link flex flex-items-center relative link" data-reactid="120"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="121"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="122"></div><svg class="absolute fit-x mxa c-1a1a1a" x="0px" y="0px" viewBox="0 0 50 50" enable-background="new 0 0 50 50" xml:space="preserve" data-reactid="123"><g data-reactid="124"><!-- react-text: 125 --> <!-- /react-text --><path fill="currentColor" d="M20.6,38.5c-0.8,0-1.6,0.3-2.2,0.8L16,41.9c-1.1,1-2.4,1.6-3.9,1.6c-1.5,0-2.8-0.5-3.9-1.6c-0.5-0.5-0.9-1.1-1.2-1.8 c-0.3-0.7-0.4-1.4-0.4-2.1c0-0.7,0.1-1.4,0.4-2.1c0.3-0.7,0.7-1.2,1.2-1.8l9.1-9c1-0.9,2.2-1.8,3.8-2.7s3-0.7,4.3,0.7 c0.6,0.6,1.3,0.8,2.2,0.8s1.5-0.3,2.1-0.9c0.6-0.6,0.9-1.3,0.9-2.2s-0.3-1.6-0.9-2.2c-2.2-2.2-4.8-3.1-7.8-2.7 c-3,0.4-5.9,2-8.8,4.8l-9.2,9c-1.1,1.1-1.9,2.4-2.5,3.8C0.7,35,0.4,36.5,0.4,38c0,1.6,0.3,3,0.9,4.4c0.6,1.4,1.4,2.7,2.5,3.8 c1.1,1.1,2.4,2,3.8,2.5c1.4,0.6,2.9,0.8,4.4,0.8s2.9-0.3,4.3-0.8c1.4-0.6,2.7-1.4,3.8-2.5l2.5-2.5c0.6-0.6,0.9-1.3,0.9-2.1 s-0.3-1.6-0.9-2.2C22.1,38.8,21.4,38.5,20.6,38.5z" data-reactid="126"></path><!-- react-text: 127 --> <!-- /react-text --><path fill="currentColor" d="M48.7,7.9c-0.6-1.4-1.4-2.7-2.5-3.8c-2.4-2.4-5.1-3.6-8-3.7c-3-0.1-5.5,0.9-7.7,3.1l-3.1,3.1c-0.6,0.6-0.9,1.3-0.9,2.1 s0.3,1.6,0.9,2.2s1.3,0.9,2.2,0.9s1.6-0.3,2.2-0.8l3.1-3.1c1.2-1.1,2.4-1.5,3.7-1.3c1.3,0.3,2.5,0.9,3.4,1.9 c0.5,0.5,0.9,1.1,1.2,1.8c0.3,0.7,0.4,1.4,0.4,2.1c0,0.7-0.1,1.4-0.4,2.1c-0.3,0.7-0.7,1.2-1.2,1.8l-9.7,9.6 c-2.2,2.2-3.9,3.1-5.1,2.7s-2-0.8-2.4-1.3c-0.6-0.6-1.3-0.8-2.2-0.8s-1.5,0.3-2.1,0.9c-0.6,0.6-0.9,1.3-0.9,2.2s0.3,1.5,0.9,2.1 c1,1,2.1,1.8,3.2,2.3s2.4,0.7,3.6,0.7c1.5,0,3-0.4,4.6-1.1c1.6-0.7,3.1-1.9,4.6-3.4l9.8-9.6c1.1-1.1,1.9-2.4,2.5-3.8 c0.6-1.4,0.9-2.9,0.9-4.4C49.6,10.8,49.3,9.3,48.7,7.9z" data-reactid="128"></path><!-- react-text: 129 --> <!-- /react-text --></g></svg></div></a><div class="q-tooltip hidden force-mobile-placement" style="width:unsetpx;top:140px;" data-reactid="130"><div class="q-tooltip-content" data-reactid="131"><div class="q-tooltip-arrow" data-reactid="132"></div><div class="q-tooltip-inner" role="tooltip" data-reactid="133"><h6 class="relative z1 uppercase kern mv0" data-reactid="134">Copied!</h6></div></div></div><a href="mailto:?subject=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?&amp;body=A%20tool%20known%20as%20BERT%20can%20now%20beat%20humans%20on%20advanced%20reading-comprehension%20tests.%20But%20it&#x27;s%20also%20revealed%20how%20far%20AI%20has%20to%20go.%0A%0Ahttps://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="" class="social-links__link flex flex-items-center relative email" data-reactid="135"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="136"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="137"></div><svg class="absolute fit-x mxa c-1a1a1a" x="0px" y="0px" viewBox="0 0 50 50" enable-background="new 0 0 50 50" xml:space="preserve" data-reactid="138"><path fill="currentColor" d="M25,29.5l-5.2-4.3L1.8,43.8h46L30.1,25.2L25,29.5z M32.6,23.2l17.2,17.9c0-0.2,0.1-0.3,0.1-0.5c0-0.2,0-0.4,0-0.6V9.1 L32.6,23.2z M0,9.1v31c0,0.2,0,0.4,0,0.6s0.1,0.3,0.1,0.5l17.3-17.8L0,9.1z M48.4,6.2H1.6L25,25L48.4,6.2z" data-reactid="139"></path></svg></div></a></div><div class="social-hide closed" data-reactid="140"><div class="social-links social-links--share flex flex-justify-between" data-reactid="141"><a href="https://getpocket.com/save?url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/&amp;title=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?" target="_blank" class="social-links__link flex flex-items-center relative pocket" data-reactid="142"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="143"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="144"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="145"><path fill="currentColor" d="M2.6,1.7C1.3,1.6,0.1,2.7,0,4.1c0,0.1,0,0.3,0,0.4v9.9c0,8.1,8,14.4,15,14.4c8-0.1,14.6-6.4,15-14.4v-10 c0.1-1.4-0.9-2.6-2.3-2.8c-0.2,0-0.4,0-0.5,0L2.6,1.7z M9,9.8l6,5.7l6-5.7c2.8-1.1,3.9,2,2.8,2.8L16,20.1c-0.6,0.3-1.3,0.3-1.9,0 l-7.9-7.5C5.2,11.5,6.5,8.4,9,9.8L9,9.8z" data-reactid="146"></path></svg></div></a><a href="https://www.reddit.com/submit?url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="_blank" class="social-links__link flex flex-items-center relative reddit" data-reactid="147"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="148"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="149"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="4 0 33 33" enable-background="new 0 0 30 30" data-reactid="150"><path fill="currentColor" d="M39.58,19.65A4.72,4.72,0,0,0,31.91,16a22.4,22.4,0,0,0-10.42-3.09l2-6.38,5.6,1.31a3.91,3.91,0,1,0,.43-2.08L23.05,4.27A1.08,1.08,0,0,0,21.79,5L19.26,12.9A22.6,22.6,0,0,0,8,16a4.68,4.68,0,1,0-5.56,7.51,8.32,8.32,0,0,0-.08,1.12c0,3.21,1.89,6.2,5.31,8.41a22.69,22.69,0,0,0,12.23,3.3A22.67,22.67,0,0,0,32.15,33c3.43-2.21,5.31-5.2,5.31-8.41a8.77,8.77,0,0,0-.06-1,4.65,4.65,0,0,0,2.18-3.93M33.05,5.8a1.78,1.78,0,1,1-1.8,1.78,1.79,1.79,0,0,1,1.8-1.78M11.52,22.53a2.71,2.71,0,0,1,2.69-2.66,2.65,2.65,0,1,1-2.69,2.66m14.93,7.73c-1.37,1.35-3.47,2-6.43,2h0c-3,0-5.06-.65-6.43-2a1.05,1.05,0,0,1,0-1.5,1.09,1.09,0,0,1,1.52,0c.94.93,2.54,1.38,4.91,1.38h0c2.37,0,4-.45,4.91-1.38a1.08,1.08,0,0,1,1.52,0,1.07,1.07,0,0,1,0,1.5m-.63-5.1a2.65,2.65,0,1,1,2.66-2.63,2.65,2.65,0,0,1-2.66,2.63" transform="translate(-0.42 -3.68)" data-reactid="151"></path></svg></div></a><a href="https://news.ycombinator.com/submitlink?u=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/&amp;t=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?" target="_blank" class="social-links__link flex flex-items-center relative hackernews" data-reactid="152"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="153"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="154"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="155"><path fill="currentColor" d="M12.9,18L3.2-0.1h4.4l5.7,11.5l0.3,0.6c0.1,0.2,0.2,0.4,0.3,0.7c0,0.1,0,0.2,0,0.2v0.2l0.4,0.9l0.5,0.7 l0.8-1.6l0.9-1.8l5.8-11.5h4.1l-9.8,18.3v11.7h-3.7V18z" data-reactid="156"></path></svg></div></a><a href="https://share.flipboard.com/bookmarklet/popout?v=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?&amp;url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="_blank" class="social-links__link flex flex-items-center relative flipboard" data-reactid="157"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="158"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="159"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="160"><path fill="currentColor" d="M30,0 0,0 0,30 10,30 10,20 20,20 20,10 30,10 z" data-reactid="161"></path></svg></div></a></div></div><div class="flex flex-justify-center social-more" data-reactid="162"><svg class="ml05 icon icon-offset closed" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="163"><path fill="currentColor" d="M15,20.7c-0.1,0-0.3,0-0.4-0.1L0.3,10.7l0.9-1.2L15,19l13.8-9.5l0.9,1.2l-14.3,9.8C15.3,20.6,15.1,20.7,15,20.7 z" data-reactid="164"></path></svg></div></div></span></div></div><div class="nav__local__mobile flex-auto flex-justify-end fill-v" data-reactid="165"><div class="nav__local__menu flex flex-items-center flex-justify-end fill-v" data-reactid="166"><li class="flex flex-items-center mh05 relative" data-reactid="167"><div class="header__hamburger" data-reactid="168"><button class="hamburger hamburger--dots block z10 relative theme__accent mha" data-reactid="169"><span class="hamburger__bar absolute fit-x mxa" data-reactid="170"></span><span class="hamburger__bar absolute fit-x mxa" data-reactid="171"></span><span class="hamburger__bar absolute fit-x mxa" data-reactid="172"></span></button></div></li></div></div></section><ul class="nav__local__dropdown absolute fit-b fit-r bg-white" data-reactid="173"><li class="__link flex flex-items-center flex-justify-start" data-reactid="174"><div class="comments-button mr05 flex flex-items-center h5 theme__accent-hover" data-reactid="175"><a href="#comments" class="flex flex-items-center pangram" data-reactid="176"><svg class="o2" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="177"><path fill="currentColor" d="M9.4 4.2h31.2c8.6 0 9.4 7 9.4 15.6s-.7 15.6-9.4 15.6h-2.2l-.9 9.4-18.8-9.4H9.4c-8.6 0-9.4-7-9.4-15.6S.7 4.2 9.4 4.2z" data-reactid="178"></path></svg><div data-reactid="179"><span class="comments-button__count ml075 small mbold disqus-comment-count" data-disqus-identifier="77108 https://www.quantamagazine.org/?p=77108"></span></div><h6 class="uppercase kern ml05 mv0" data-reactid="180">Comments</h6></a></div></li><li class="__link flex flex-items-center flex-justify-start" data-reactid="181"><div class="relative" data-reactid="182"><button class="bookmark-button mh05 flex flex-items-center theme__accent-hover" aria-expanded="false" data-reactid="183"><svg class="icon" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="184"><path fill="currentColor" d="M2.1 0h45.8v50L25.5 37.5 2.1 50V0z" data-reactid="185"></path></svg><h6 class="uppercase kern ml1 mv0 theme__text" data-reactid="186">Read Later</h6></button><div class="q-tooltip hidden force-mobile-placement" style="width:130px;top:55px;" data-reactid="187"><div class="q-tooltip-content" data-reactid="188"><div class="q-tooltip-arrow" data-reactid="189"></div><div class="q-tooltip-inner" role="tooltip" data-reactid="190"><h6 class="relative z1 uppercase kern--w mx025" data-reactid="191"><span class="small no-wrap" data-reactid="192">Read Later</span></h6></div></div></div></div></li></ul><div class="nav__local__progress absolute fit-b fit-l fit-r z1 c-ff8600" data-reactid="193"><span class="block" style="transform:translateX(-100%);" data-reactid="194"></span></div></div></div><div id="postBody" class="theme__background-background theme__text" data-reactid="195"><!-- react-empty: 196 --><div data-reactid="197"><section class="post__title__wrapper relative" data-reactid="198"><section class="outer fill-h relative outer--content" data-reactid="199"><div class="mha container--s" data-reactid="200"><div class="header-spacer" data-reactid="201"></div><div class="post__title pv1 scale1 mha" data-reactid="202"><div class="scale0" data-reactid="203"><h6 class="mb1 pb025 mt0 block post__title__kicker" data-reactid="204"><a class="kicker theme__accent theme__text-hover uppercase" href="/tag/artificial-intelligence/" data-reactid="205">artificial intelligence</a></h6><h1 class="post__title__title mv025 noe" data-reactid="206">Machines Beat Humans on a Reading Test. But Do They Understand?</h1><!-- react-empty: 207 --><div class="post__title__author-date h5 mt1" data-reactid="208"><h6 class="byline relative flex flex-items-start merriweather mv025 mr1 gray3 theme__text-hover" data-reactid="209"><em class="byline__by gray4 mr075" data-reactid="210">By </em><a href="/authors/john-pavlus/" data-reactid="211"><span class="byline__author uppercase kern light small" data-reactid="212">John Pavlus</span></a></h6><p class="h6 o6 mv1 pv025" data-reactid="213"><em data-reactid="214">October 17, 2019</em></p></div><div class="post__title__meta flex flex-wrap flex-items-start" data-reactid="215"><div class="post__title__excerpt wysiwyg p italic mb1 mt025 pr2 o4" data-reactid="216">A tool known as BERT can now beat humans on advanced reading-comprehension tests. But it's also revealed how far AI has to go. </div><div class="post__title__actions h5 mt025 flex-auto flex flex-items-center" data-reactid="217"><div class="comments-button mr05 flex flex-items-center theme__accent" data-reactid="218"><a href="#comments" class="flex flex-items-center pangram" data-reactid="219"><svg viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="220"><path fill="currentColor" d="M9.4 4.2h31.2c8.6 0 9.4 7 9.4 15.6s-.7 15.6-9.4 15.6h-2.2l-.9 9.4-18.8-9.4H9.4c-8.6 0-9.4-7-9.4-15.6S.7 4.2 9.4 4.2z" data-reactid="221"></path></svg><div data-reactid="222"><span class="comments-button__count ml075 small mbold disqus-comment-count" data-disqus-identifier="77108 https://www.quantamagazine.org/?p=77108"></span></div></a></div><span class="o-divider mh075 relative" data-reactid="223"></span><div class="relative" data-reactid="224"><button class="bookmark-button mh05 flex flex-items-center theme__accent-hover" aria-expanded="false" data-reactid="225"><svg class="icon" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="226"><path fill="currentColor" d="M2.1 0h45.8v50L25.5 37.5 2.1 50V0z" data-reactid="227"></path></svg></button><div class="q-tooltip hidden force-mobile-placement" style="width:130px;top:55px;" data-reactid="228"><div class="q-tooltip-content" data-reactid="229"><div class="q-tooltip-arrow" data-reactid="230"></div><div class="q-tooltip-inner" role="tooltip" data-reactid="231"><h6 class="relative z1 uppercase kern--w mx025" data-reactid="232"><span class="small no-wrap" data-reactid="233">Read Later</span></h6></div></div></div></div></div></div></div></div></div></section></section></div><figure class="lh-0 w-100P m-0_auto d-flex align-items-center justify-content-center flex-direction-column max-width-1420 _p_last-of-type-mb-0 p-0 _19nesb1 _jrggmc _552kiq _rna4ro" data-reactid="234"><div class="w-100P d-flex justify-content-center _149bqoo _1syob6o _aylhnx _1ovb59i" data-reactid="235"><div class="w-auto max-width-100P max-height-100P mr-0p5em _last-of-type-m-0 _1oyl2xe _1mmfes9 _duy6tz _aylhnx component-img" data-reactid="236"><img alt="Illustration of cartoon characters working alongside a machine." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1820_Lede.jpg" class="w-initial max-width-100P mb-1p5em _rv3kk2 _rna4ro border-none" data-reactid="237"/><!-- react-empty: 238 --></div></div><figcaption class="d-block m-0_auto w-100P _112lb0a _192y3bk _dc69mj" data-reactid="239"><section class="p-0_3em _191d351 _rna4ro" data-reactid="240"><div class="max-width-560px w-100P m-0_auto d-flex flex-direction-column _1e0lyfy _k6y9ug _1ij7gf7 _1xqp4r2 _19one4x _eugonq _l378w0 _149bqoo _owlpzp _1re1wwt _pattribution-w-auto _46bwqc _pujp80 _pcaption-w-auto _1dxfdx3" data-reactid="241"><div class="caption wysiwyg h5 theme__anchors--solid fill-h" data-reactid="242"><p>The BERT neural network has led to a revolution in how machines understand human language.</p>
</div><div class="attribution theme__anchors--solid wysiwyg pangram h6 mb1 fill-h" data-reactid="243"><p><a href="http://www.soulofagiant.com/">Jon Fox</a> for Quanta Magazine</p>
</div></div></section></figcaption></figure><div class="acf-content scale1 mt2" data-reactid="244"><div class="post__wrapper scale0 show-dropcap" data-reactid="245"><div class="mha container--m" data-reactid="246"><div class="post__content relative flex flex-items-start flex-justify-between" data-reactid="247"><aside class="post__sidebar hide flex flex-justify-center" data-reactid="248"><div class="post__sidebar__content" data-reactid="249"><div class="post__sidebar__content__inner" data-reactid="250"><div class="align-c mb075" data-reactid="251"><div class="sidebar__author" data-reactid="252"><a class="theme__accent-hover transition--color" href="/authors/john-pavlus/" data-reactid="253"><div class="sidebar__author__avatar mha mb1" data-reactid="254"><div class="image mx0 relative image--circle" data-reactid="255"><div class="image__inner absolute fit-x" data-reactid="256"><img class="absolute fit-x fill-h fill-v mxa" data-reactid="257"/></div><noscript data-reactid="258"><img class="absolute fit-x fill-h fill-v is-loaded" src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/John_Pavlus1.jpg"/></noscript></div></div><h3 class="mv05" data-reactid="259">John Pavlus</h3><p class="h5 o8 mt05 mb1 theme__text" data-reactid="260"><em data-reactid="261">Contributing Writer</em></p></a></div><hr class="mb075 o1" data-reactid="262"/><p class="h6 o6 mv1 pv025" data-reactid="263"><em data-reactid="264">October 17, 2019</em></p></div><div class="sidebar__actions" data-reactid="265"><hr class="mt075 mb1 o1" data-reactid="266"/><a href="#" id="print-friendly-button" class="h6 pangram uppercase mv05 pb1 bold kern flex flex-items-center flex-justify-between sidebar__print transition--color theme__accent-hover" data-reactid="267"><small data-reactid="268">View PDF/Print Mode</small><svg class="icon-l theme__accent ml05" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="269"><path fill="currentColor" d="M39.9,27.5h4.9v22.4H0.1V5.1h22.4V10H5v35h35V27.5z M49.8,0.1h-2.4h-1H33.8V5h7.6L20.7,25.8l3.4,3.4L45,8.4v7.7h4.9V2.6L49.8,0.1z" data-reactid="270"></path></svg></a></div><div class="mt1 pt05 sidebar__tag-wrap" data-reactid="271"><a class="sidebar__tag h6 pangram medium inline-block mb0 relative" href="/tag/artificial-intelligence/" data-reactid="272"><span class="absolute fit-x theme__text-background o1" data-reactid="273"></span><span class="theme__text theme__accent-hover transition--color relative" data-reactid="274">artificial intelligence</span></a><a class="sidebar__tag h6 pangram medium inline-block mb0 relative" href="/tag/computer-science/" data-reactid="275"><span class="absolute fit-x theme__text-background o1" data-reactid="276"></span><span class="theme__text theme__accent-hover transition--color relative" data-reactid="277">computer science</span></a><a class="sidebar__tag h6 pangram medium inline-block mb0 relative" href="/tag/machine-learning/" data-reactid="278"><span class="absolute fit-x theme__text-background o1" data-reactid="279"></span><span class="theme__text theme__accent-hover transition--color relative" data-reactid="280">machine learning</span></a><a class="sidebar__tag h6 pangram medium inline-block mb0 relative" href="/tag/natural-language-processing/" data-reactid="281"><span class="absolute fit-x theme__text-background o1" data-reactid="282"></span><span class="theme__text theme__accent-hover transition--color relative" data-reactid="283">natural language processing</span></a><a class="sidebar__tag h6 pangram medium inline-block mb0 relative" href="/tag/neural-networks/" data-reactid="284"><span class="absolute fit-x theme__text-background o1" data-reactid="285"></span><span class="theme__text theme__accent-hover transition--color relative" data-reactid="286">neural networks</span></a></div></div><div class="sidebar__poster" data-reactid="287"><a href="https://www.quantamagazine.org/gift-store" title="Alice and Bob Meet the Wall of Fire - The Biggest Ideas in Science from Quanta – Available now!" class="sidebar__poster__desktop" target="_blank" data-reactid="288"><img src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Article_320x600_Science.jpg" alt="Alice and Bob Meet the Wall of Fire - The Biggest Ideas in Science from Quanta – Available now!" class="fill-h" data-reactid="289"/></a><a href="https://www.quantamagazine.org/gift-store" title="Alice and Bob Meet the Wall of Fire - The Biggest Ideas in Science from Quanta – Available now!" class="sidebar__poster__mobile" target="_blank" data-reactid="290"><img src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Mobile_250x200_2x_Science.jpg" alt="Alice and Bob Meet the Wall of Fire - The Biggest Ideas in Science from Quanta – Available now!" class="fill-h" data-reactid="291"/></a></div></div></aside><section class="outer mha js-router-anchors outer--content" data-reactid="292"><div class="flex-auto mha container--xs" data-reactid="293"><div class="post__content__section wysiwyg p theme__anchors--underline" data-reactid="294"><div class="post__content wysiwyg p theme__anchors--underline" data-reactid="295"><p>In the fall of 2017, <a href="http://www.nyu.edu/projects/bowman/">Sam Bowman</a>, a computational linguist at New York University, figured that computers still weren’t very good at understanding the written word. Sure, they had become decent at simulating that understanding in certain narrow domains, like automatic translation or sentiment analysis (for example, determining if a sentence sounds “mean or nice,” he said). But Bowman wanted measurable evidence of the genuine article: bona fide, human-style reading comprehension in English. So he came up with a test.</p>
<p>In an April 2018 <a href="https://arxiv.org/abs/1804.07461">paper</a> coauthored with collaborators from the University of Washington and DeepMind, the Google-owned artificial intelligence company, Bowman introduced a battery of nine reading-comprehension tasks for computers called GLUE (General Language Understanding Evaluation). The test was designed as “a fairly representative sample of what the research community thought were interesting challenges,” said Bowman, but also “pretty straightforward for humans.” For example, one task asks whether a sentence is true based on information offered in a preceding sentence. If you can tell that “President Trump landed in Iraq for the start of a seven-day visit” implies that “President Trump is on an overseas visit,” you’ve just passed.</p>
<p>The machines bombed. Even state-of-the-art neural networks scored no higher than 69 out of 100 across all nine tasks: a D-plus, in letter grade terms. Bowman and his coauthors weren’t surprised. Neural networks — layers of computational connections built in a crude approximation of how neurons communicate within mammalian brains — had shown promise in the field of “natural language processing” (NLP), but the researchers weren’t convinced that these systems were learning anything substantial about language itself. And GLUE seemed to prove it. “These early results indicate that solving GLUE is beyond the capabilities of current models and methods,” Bowman and his coauthors wrote.</p>
<div id='component-5e03cfe9c6847'><script type="text/template">{"type":"Blockquote","id":"component-5e03cfe9c6847","data":{"quote":"<p>We know we\u2019re somewhere in the gray area between solving language in a very boring, narrow sense, and solving AI.<\/p>\n","alignment":"right","quote_attribution":"<p>Sam Bowman<\/p>\n","twitter_text":""}}</script></div>
<p>Their appraisal would be short-lived. In October of 2018, Google introduced a new method nicknamed BERT (Bidirectional Encoder Representations from Transformers). It produced a GLUE score of 80.5. On this brand-new benchmark designed to measure machines’ real understanding of natural language — or to expose their lack thereof — the machines had jumped from a D-plus to a B-minus in just six months.</p>
<p>“That was definitely the ‘oh, crap’ moment,” Bowman recalled, using a more colorful interjection. “The general reaction in the field was incredulity. BERT was getting numbers on many of the tasks that were close to what we thought would be the limit of how well you could do.” Indeed, GLUE didn’t even bother to include human baseline scores before BERT; by the time Bowman and one of his Ph.D. students added them to GLUE in February 2019, they lasted just a few months before <a href="https://blogs.msdn.microsoft.com/stevengu/2019/06/20/microsoft-achieves-human-performance-estimate-on-glue-benchmark/">a BERT-based system from Microsoft</a> beat them.</p>
<p>As of this writing, nearly every position on the <a href="https://gluebenchmark.com/leaderboard/">GLUE leaderboard</a> is occupied by a system that incorporates, extends or optimizes BERT. Five of these systems outrank human performance.</p>
<p>But is AI actually starting to understand our language — or is it just getting better at gaming our systems? As BERT-based neural networks have taken benchmarks like GLUE by storm, new evaluation methods have emerged that seem to paint these powerful NLP systems as computational versions of Clever Hans, the early 20th-century horse who seemed smart enough to do arithmetic, but who was actually just following unconscious cues from his trainer.</p>
<p>“We know we’re somewhere in the gray area between solving language in a very boring, narrow sense, and solving AI,” Bowman said. “The general reaction of the field was: Why did this happen? What does this mean? What do we do now?”</p>
<h2 class="Body">Writing Their Own Rules</h2>
<p>In the famous Chinese Room thought experiment, a non-Chinese-speaking person sits in a room furnished with many rulebooks. Taken together, these rulebooks perfectly specify how to take any incoming sequence of Chinese symbols and craft an appropriate response. A person outside slips questions written in Chinese under the door. The person inside consults the rulebooks, then sends back perfectly coherent answers in Chinese.</p>
<p>The thought experiment has been used to argue that, no matter how it might appear from the outside, the person inside the room can’t be said to have any true understanding of Chinese. Still, even a simulacrum of understanding has been a good enough goal for natural language processing.</p>
<p>The only problem is that perfect rulebooks don’t exist, because natural language is far too complex and haphazard to be reduced to a rigid set of specifications. Take syntax, for example: the rules (and rules of thumb) that define how words group into meaningful sentences. The phrase “<a href="https://books.google.com/books?id=55YaAAAAIAAJ&amp;dq=colorless+green+ideas+sleep+furiously">colorless green ideas sleep furiously</a>” has perfect syntax, but any natural speaker knows it’s nonsense. What prewritten rulebook could capture this “unwritten” fact about natural language — or innumerable others?</p>
<p>NLP researchers have tried to square this circle by having neural networks write their own makeshift rulebooks, in a process called pretraining.</p>
<p>Before 2018, one of NLP’s main pretraining tools was something like a dictionary. Known as word embeddings, this dictionary encoded associations between words as numbers in a way that deep neural networks could accept as input — akin to giving the person inside a Chinese room a crude vocabulary book to work with. But a neural network pretrained with word embeddings is still blind to the meaning of words at the sentence level. “It would think that ‘a man bit the dog’ and ‘a dog bit the man’ are exactly the same thing,” said <a href="http://tallinzen.net/">Tal Linzen</a>, a computational linguist at Johns Hopkins University.</p>
<div id='component-5e03cfe9c9ab4'><script type="text/template">{"type":"Image","id":"component-5e03cfe9c9ab4","data":{"id":77506,"src":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","class":"","width":1500,"height":2000,"mobileSrc":false,"zoomSrc":false,"align":"align=\"right\"","wrapper_width":"","caption":"<p>Tal Linzen, a computational linguist at Johns Hopkins University, wonders \u201cto what extent these models are really understanding language,\u201d and not just \u201cpicking up weird tricks that happen to work.\u201d<\/p>\n","attribution":"<p>Will Kirk\/Johns Hopkins University<\/p>\n","variant":"shortcode","size":"default","disableZoom":true,"srcImage":{"ID":77506,"id":77506,"title":"Linzen-KirkJohnsHopkins_1500x2000","filename":"Linzen-KirkJohnsHopkins_1500x2000.jpg","filesize":809002,"url":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","link":"https:\/\/www.quantamagazine.org\/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\/linzen-kirkjohnshopkins_1500x2000\/","alt":"Photo of Tal Linzen","author":"3886","description":"Will Kirk\/Johns Hopkins University","caption":"Tal Linzen, a computational linguist at Johns Hopkins University, wonders \u201cto what extent these models are really understanding language,\u201d and not just \u201cpicking up weird tricks that happen to work.\u201d","name":"linzen-kirkjohnshopkins_1500x2000","status":"inherit","uploaded_to":77108,"date":"2019-10-16 20:45:15","modified":"2019-10-17 15:01:33","menu_order":0,"mime_type":"image\/jpeg","type":"image","subtype":"jpeg","icon":"https:\/\/api.quantamagazine.org\/wp-includes\/images\/media\/default.png","width":1500,"height":2000,"sizes":{"thumbnail":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000-390x520.jpg","thumbnail-width":390,"thumbnail-height":520,"medium":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000-1290x1720.jpg","medium-width":1290,"medium-height":1720,"medium_large":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000-768x1024.jpg","medium_large-width":768,"medium_large-height":1024,"large":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","large-width":1500,"large-height":2000,"square_small":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000-160x160.jpg","square_small-width":160,"square_small-height":160,"square_large":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000-520x520.jpg","square_large-width":520,"square_large-height":520,"apple_news_ca_landscape_12_9":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_landscape_12_9-width":1031,"apple_news_ca_landscape_12_9-height":1374,"apple_news_ca_landscape_9_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_landscape_9_7-width":774,"apple_news_ca_landscape_9_7-height":1032,"apple_news_ca_landscape_5_5":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_landscape_5_5-width":587,"apple_news_ca_landscape_5_5-height":783,"apple_news_ca_landscape_4_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_landscape_4_7-width":356,"apple_news_ca_landscape_4_7-height":474,"apple_news_ca_landscape_4_0":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_landscape_4_0-width":302,"apple_news_ca_landscape_4_0-height":402,"apple_news_ca_portrait_12_9":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_portrait_12_9-width":1122,"apple_news_ca_portrait_12_9-height":1496,"apple_news_ca_portrait_9_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_portrait_9_7-width":840,"apple_news_ca_portrait_9_7-height":1120,"apple_news_ca_portrait_5_5":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_portrait_5_5-width":687,"apple_news_ca_portrait_5_5-height":916,"apple_news_ca_portrait_4_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_portrait_4_7-width":414,"apple_news_ca_portrait_4_7-height":552,"apple_news_ca_portrait_4_0":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_portrait_4_0-width":354,"apple_news_ca_portrait_4_0-height":472,"apple_news_ca_square_12_9":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_square_12_9-width":1104,"apple_news_ca_square_12_9-height":1472,"apple_news_ca_square_9_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_square_9_7-width":828,"apple_news_ca_square_9_7-height":1104,"apple_news_ca_square_5_5":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_square_5_5-width":684,"apple_news_ca_square_5_5-height":912,"apple_news_ca_square_4_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_square_4_7-width":413,"apple_news_ca_square_4_7-height":550,"apple_news_ca_square_4_0":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Linzen-KirkJohnsHopkins_1500x2000.jpg","apple_news_ca_square_4_0-width":353,"apple_news_ca_square_4_0-height":470}},"largeForPrint":false,"externalLink":""}}</script></div>
<p>A better method would use pretraining to equip the network with richer rulebooks — not just for vocabulary, but for syntax and context as well — before training it to perform a specific NLP task. In early 2018, researchers at OpenAI, the University of San Francisco, the Allen Institute for Artificial Intelligence and the University of Washington simultaneously discovered a clever way to approximate this feat. Instead of pretraining just the first layer of a network with word embeddings, the researchers began training entire neural networks on a broader basic task called language modeling.</p>
<p>“The simplest kind of language model is: I’m going to read a bunch of words and then try to predict the next word,” explained <a href="https://research.fb.com/people/ott-myle/">Myle Ott</a>, a research scientist at Facebook. “If I say, ‘George Bush was born in,’ the model now has to predict the next word in that sentence.”</p>
<p>These deep pretrained language models could be produced relatively efficiently. Researchers simply fed their neural networks massive amounts of written text copied from freely available sources like Wikipedia — billions of words, preformatted into grammatically correct sentences — and let the networks derive next-word predictions on their own. In essence, it was like asking the person inside a Chinese room to write all his own rules, using only the incoming Chinese messages for reference.</p>
<p>“The great thing about this approach is it turns out that the model learns a ton of stuff about syntax,” Ott said.</p>
<p>What’s more, these pretrained neural networks could then apply their richer representations of language to the job of learning an unrelated, more specific NLP task, a process called fine-tuning.</p>
<p>“You can take the model from the pretraining stage and kind of adapt it for whatever actual task you care about,” Ott explained. “And when you do that, you get much better results than if you had just started with your end task in the first place.”</p>
<p>Indeed, in June of 2018, when OpenAI unveiled a neural network <a href="https://openai.com/blog/language-unsupervised/">called GPT</a>, which included a language model pretrained on nearly a billion words (sourced from 11,038 digital books) for an entire month, its GLUE score of 72.8 immediately took the top spot on the leaderboard. Still, Sam Bowman assumed that the field had a long way to go before any system could even begin to approach human-level performance.</p>
<p>Then BERT appeared.</p>
<h2 class="Body">A Powerful Recipe</h2>
<p>So what exactly is BERT?</p>
<p>First, it’s not a fully trained neural network capable of besting human performance right out of the box. Instead, said Bowman, BERT is “a very precise recipe for pretraining a neural network.” Just as a baker can follow a recipe to reliably produce a delicious prebaked pie crust — which can then be used to make many different kinds of pie, from blueberry to spinach quiche — Google researchers developed BERT’s recipe to serve as an ideal foundation for “baking” neural networks (that is, fine-tuning them) to do well on many different natural language processing tasks. Google also open-sourced BERT’s code, which means that other researchers don’t have to repeat the recipe from scratch — they can just download BERT as-is, like buying a prebaked pie crust from the supermarket.</p>
<p>If BERT is essentially a recipe, what’s the ingredient list? “It’s the result of three things coming together to really make things click,” said <a href="https://levyomer.wordpress.com/">Omer Levy</a>, a research scientist at Facebook who has <a href="https://arxiv.org/abs/1906.04341">analyzed BERT’s inner workings</a>.</p>
<div id='component-5e03cfe9ccfaa'><script type="text/template">{"type":"Image","id":"component-5e03cfe9ccfaa","data":{"id":77505,"src":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","class":"","width":1500,"height":2000,"mobileSrc":false,"zoomSrc":false,"align":"align=\"right\"","wrapper_width":"","caption":"<p>Omer Levy, a research scientist at Facebook, has studied why BERT is so successful.<\/p>\n","attribution":"<p>Courtesy of Omer Levy<\/p>\n","variant":"shortcode","size":"default","disableZoom":true,"srcImage":{"ID":77505,"id":77505,"title":"Levy-1500x2000","filename":"Levy-1500x2000.jpg","filesize":802656,"url":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","link":"https:\/\/www.quantamagazine.org\/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\/levy-1500x2000\/","alt":"Photo of Omer Levy","author":"3886","description":"Courtesy of Omer Levy","caption":"Omer Levy, a research scientist at Facebook, has studied why BERT is so successful.","name":"levy-1500x2000","status":"inherit","uploaded_to":77108,"date":"2019-10-16 20:45:14","modified":"2019-10-17 15:03:02","menu_order":0,"mime_type":"image\/jpeg","type":"image","subtype":"jpeg","icon":"https:\/\/api.quantamagazine.org\/wp-includes\/images\/media\/default.png","width":1500,"height":2000,"sizes":{"thumbnail":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000-390x520.jpg","thumbnail-width":390,"thumbnail-height":520,"medium":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000-1290x1720.jpg","medium-width":1290,"medium-height":1720,"medium_large":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000-768x1024.jpg","medium_large-width":768,"medium_large-height":1024,"large":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","large-width":1500,"large-height":2000,"square_small":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000-160x160.jpg","square_small-width":160,"square_small-height":160,"square_large":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000-520x520.jpg","square_large-width":520,"square_large-height":520,"apple_news_ca_landscape_12_9":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_landscape_12_9-width":1031,"apple_news_ca_landscape_12_9-height":1374,"apple_news_ca_landscape_9_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_landscape_9_7-width":774,"apple_news_ca_landscape_9_7-height":1032,"apple_news_ca_landscape_5_5":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_landscape_5_5-width":587,"apple_news_ca_landscape_5_5-height":783,"apple_news_ca_landscape_4_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_landscape_4_7-width":356,"apple_news_ca_landscape_4_7-height":474,"apple_news_ca_landscape_4_0":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_landscape_4_0-width":302,"apple_news_ca_landscape_4_0-height":402,"apple_news_ca_portrait_12_9":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_portrait_12_9-width":1122,"apple_news_ca_portrait_12_9-height":1496,"apple_news_ca_portrait_9_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_portrait_9_7-width":840,"apple_news_ca_portrait_9_7-height":1120,"apple_news_ca_portrait_5_5":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_portrait_5_5-width":687,"apple_news_ca_portrait_5_5-height":916,"apple_news_ca_portrait_4_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_portrait_4_7-width":414,"apple_news_ca_portrait_4_7-height":552,"apple_news_ca_portrait_4_0":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_portrait_4_0-width":354,"apple_news_ca_portrait_4_0-height":472,"apple_news_ca_square_12_9":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_square_12_9-width":1104,"apple_news_ca_square_12_9-height":1472,"apple_news_ca_square_9_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_square_9_7-width":828,"apple_news_ca_square_9_7-height":1104,"apple_news_ca_square_5_5":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_square_5_5-width":684,"apple_news_ca_square_5_5-height":912,"apple_news_ca_square_4_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_square_4_7-width":413,"apple_news_ca_square_4_7-height":550,"apple_news_ca_square_4_0":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Levy-1500x2000.jpg","apple_news_ca_square_4_0-width":353,"apple_news_ca_square_4_0-height":470}},"largeForPrint":false,"externalLink":""}}</script></div>
<p>The first is a pretrained language model, those reference books in our Chinese room. The second is the ability to figure out which features of a sentence are most important.</p>
<p>In 2017, an engineer at Google Brain named <a href="http://jakob.uszkoreit.net/">Jakob Uszkoreit</a> was working on ways to accelerate Google’s language-understanding efforts. He noticed that state-of-the-art neural networks also suffered from a built-in constraint: They all looked through the sequence of words one by one. This “sequentiality” seemed to match intuitions of how humans actually read written sentences. But Uszkoreit wondered if “it might be the case that understanding language in a linear, sequential fashion is suboptimal,” he said.</p>
<p>Uszkoreit and his collaborators devised a new architecture for neural networks focused on “attention,” a mechanism that lets each layer of the network assign more weight to some specific features of the input than to others. This new attention-focused architecture, called a transformer, could take a sentence like “a dog bites the man” as input and encode each word in many different ways in parallel. For example, a transformer might connect “bites” and “man” together as verb and object, while ignoring “a”; at the same time, it could connect “bites” and “dog” together as verb and subject, while mostly ignoring “the.”</p>
<p>The nonsequential nature of the transformer represented sentences in a more expressive form, which Uszkoreit calls treelike. Each layer of the neural network makes multiple, parallel connections between certain words while ignoring others — akin to a student diagramming a sentence in elementary school. These connections are often drawn between words that may not actually sit next to each other in the sentence. “Those structures effectively look like a number of trees that are overlaid,” Uszkoreit explained.</p>
<p>This treelike representation of sentences gave transformers a powerful way to model contextual meaning, and also to efficiently learn associations between words that might be far away from each other in complex sentences. “It’s a bit counterintuitive,” Uszkoreit said, “but it is rooted in results from linguistics, which has for a long time looked at treelike models of language.”</p>
<div id='component-5e03cfe9d03e3'><script type="text/template">{"type":"Image","id":"component-5e03cfe9d03e3","data":{"id":77508,"src":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","class":"","width":1500,"height":2000,"mobileSrc":false,"zoomSrc":false,"align":"align=\"right\"","wrapper_width":"","caption":"<p>Jakob Uszkoreit, who leads the Google AI Brain team in Berlin, helped develop a new architecture for neural networks that focuses on attention.<\/p>\n","attribution":"<p>Google<\/p>\n","variant":"shortcode","size":"default","disableZoom":true,"srcImage":{"ID":77508,"id":77508,"title":"Uszkoreit-Google_1500x2000","filename":"Uszkoreit-Google_1500x2000.jpg","filesize":997757,"url":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","link":"https:\/\/www.quantamagazine.org\/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\/uszkoreit-google_1500x2000\/","alt":"Photo of Jakob Uszkoreit","author":"3886","description":"Courtesy of Google","caption":"Jakob Uszkoreit, who leads the Google AI Brain team in Berlin, helped develop a new architecture for neural networks that focuses on attention.","name":"uszkoreit-google_1500x2000","status":"inherit","uploaded_to":77108,"date":"2019-10-16 20:45:19","modified":"2019-10-17 15:03:39","menu_order":0,"mime_type":"image\/jpeg","type":"image","subtype":"jpeg","icon":"https:\/\/api.quantamagazine.org\/wp-includes\/images\/media\/default.png","width":1500,"height":2000,"sizes":{"thumbnail":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000-390x520.jpg","thumbnail-width":390,"thumbnail-height":520,"medium":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000-1290x1720.jpg","medium-width":1290,"medium-height":1720,"medium_large":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000-768x1024.jpg","medium_large-width":768,"medium_large-height":1024,"large":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","large-width":1500,"large-height":2000,"square_small":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000-160x160.jpg","square_small-width":160,"square_small-height":160,"square_large":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000-520x520.jpg","square_large-width":520,"square_large-height":520,"apple_news_ca_landscape_12_9":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_landscape_12_9-width":1031,"apple_news_ca_landscape_12_9-height":1374,"apple_news_ca_landscape_9_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_landscape_9_7-width":774,"apple_news_ca_landscape_9_7-height":1032,"apple_news_ca_landscape_5_5":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_landscape_5_5-width":587,"apple_news_ca_landscape_5_5-height":783,"apple_news_ca_landscape_4_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_landscape_4_7-width":356,"apple_news_ca_landscape_4_7-height":474,"apple_news_ca_landscape_4_0":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_landscape_4_0-width":302,"apple_news_ca_landscape_4_0-height":402,"apple_news_ca_portrait_12_9":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_portrait_12_9-width":1122,"apple_news_ca_portrait_12_9-height":1496,"apple_news_ca_portrait_9_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_portrait_9_7-width":840,"apple_news_ca_portrait_9_7-height":1120,"apple_news_ca_portrait_5_5":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_portrait_5_5-width":687,"apple_news_ca_portrait_5_5-height":916,"apple_news_ca_portrait_4_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_portrait_4_7-width":414,"apple_news_ca_portrait_4_7-height":552,"apple_news_ca_portrait_4_0":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_portrait_4_0-width":354,"apple_news_ca_portrait_4_0-height":472,"apple_news_ca_square_12_9":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_square_12_9-width":1104,"apple_news_ca_square_12_9-height":1472,"apple_news_ca_square_9_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_square_9_7-width":828,"apple_news_ca_square_9_7-height":1104,"apple_news_ca_square_5_5":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_square_5_5-width":684,"apple_news_ca_square_5_5-height":912,"apple_news_ca_square_4_7":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_square_4_7-width":413,"apple_news_ca_square_4_7-height":550,"apple_news_ca_square_4_0":"https:\/\/d2r55xnwy6nx47.cloudfront.net\/uploads\/2019\/10\/Uszkoreit-Google_1500x2000.jpg","apple_news_ca_square_4_0-width":353,"apple_news_ca_square_4_0-height":470}},"largeForPrint":false,"externalLink":""}}</script></div>
<p>Finally, the third ingredient in BERT’s recipe takes nonlinear reading one step further.</p>
<p>Unlike other pretrained language models, many of which are created by having neural networks read terabytes of text from left to right, BERT’s model reads left to right and right to left at the same time, and learns to predict words in the middle that have been randomly masked from view. For example, BERT might accept as input a sentence like “George Bush was <span style="background-color: #000000;">[……..]</span> in Connecticut in 1946” and predict the masked word in the middle of the sentence (in this case, “born”) by parsing the text from both directions. “This bidirectionality is conditioning a neural network to try to get as much information as it can out of any subset of words,” Uszkoreit said.</p>
<p>The Mad-Libs-esque pretraining task that BERT uses — called masked-language modeling — isn’t new. In fact, it’s been used as a tool for assessing language comprehension in humans for decades. For Google, it also offered a practical way of enabling bidirectionality in neural networks, as opposed to the unidirectional pretraining methods that had previously dominated the field. “Before BERT, unidirectional language modeling was the standard, even though it is an unnecessarily restrictive constraint,” said <a href="https://kentonl.com/">Kenton Lee</a>, a research scientist at Google.</p>
<p>Each of these three ingredients — a deep pretrained language model, attention and bidirectionality — existed independently before BERT. But until Google released its recipe in late 2018, no one had combined them in such a powerful way.</p>
<h2 class="Body">Refining the Recipe</h2>
<p>Like any good recipe, BERT was soon adapted by cooks to their own tastes. In the spring of 2019, there was a period “when Microsoft and Alibaba were leapfrogging each other week by week, continuing to tune their models and trade places at the number one spot on the leaderboard,” Bowman recalled. When an improved version of BERT called RoBERTa first came on the scene in August, the DeepMind researcher <a href="http://ruder.io/">Sebastian Ruder</a> <a href="http://newsletter.ruder.io/issues/nlp-in-industry-leaderboard-madness-fast-ai-nlp-transfer-learning-tools-186245">dryly noted the occasion in his widely read NLP newsletter</a>: “Another month, another state-of-the-art pretrained language model.”</p>
<div id='component-5e03cfe9d0570'><script type="text/template">{"type":"Blockquote","id":"component-5e03cfe9d0570","data":{"quote":"<p>We\u2019re still figuring out what recipes work and which ones don\u2019t.<\/p>\n","alignment":"right","quote_attribution":"<p>Myle Ott<\/p>\n","twitter_text":""}}</script></div>
<p>BERT&#8217;s “pie crust” incorporates a number of structural design decisions that affect how well it works. These include the size of the neural network being baked, the amount of pretraining data, how that pretraining data is masked and how long the neural network gets to train on it. Subsequent recipes like RoBERTa result from researchers tweaking these design decisions, much like chefs refining a dish.</p>
<p>In RoBERTa’s case, researchers at Facebook and the University of Washington increased some ingredients (more pretraining data, longer input sequences, more training time), took one away (a “next sentence prediction” task, originally included in BERT, that actually degraded performance) and modified another (they made the masked-language pretraining task harder). The result? First place on GLUE — briefly. Six weeks later, researchers from Microsoft and the University of Maryland <a href="https://arxiv.org/abs/1909.11764">added</a> their own tweaks to RoBERTa and eked out a new win. As of this writing, yet another model called ALBERT, short for “A Lite BERT,” has taken GLUE’s top spot by further adjusting BERT’s basic design.</p>
<p>“We’re still figuring out what recipes work and which ones don’t,” said Facebook’s Ott, who worked on RoBERTa.</p>
<p>Still, just as perfecting your pie-baking technique isn’t likely to teach you the principles of chemistry, incrementally optimizing BERT doesn’t necessarily impart much theoretical knowledge about advancing NLP. “I’ll be perfectly honest with you: I don’t follow these papers, because they are extremely boring to me,” said Linzen, the computational linguist from Johns Hopkins. “There is a scientific puzzle there,” he grants, but it doesn’t lie in figuring out how to make BERT and all its spawn smarter, or even in figuring out how they got smart in the first place. Instead, “we are trying to understand to what extent these models are really understanding language,” he said, and not “picking up weird tricks that happen to work on the data sets that we commonly evaluate our models on.”</p>
<p>In other words: BERT is doing something right. But what if it’s for the wrong reasons?</p>
<h2 class="Body">Clever but Not Smart</h2>
<p>In July 2019, two researchers from Taiwan’s National Cheng Kung University used BERT to achieve an impressive result on a relatively obscure natural language understanding benchmark called the argument reasoning comprehension task. Performing the task requires selecting the appropriate implicit premise (called a warrant) that will back up a reason for arguing some claim. For example, to argue that “smoking causes cancer” (the claim) because “scientific studies have shown a link between smoking and cancer” (the reason), you need to presume that “scientific studies are credible” (the warrant), as opposed to “scientific studies are expensive” (which may be true, but makes no sense in the context of the argument). Got all that?</p>
<p>If not, don’t worry. Even human beings don’t do particularly well on this task without practice: The average baseline score for an untrained person is 80 out of 100. BERT got 77 — “surprising,” in the authors’ understated opinion.</p>
<p>But instead of concluding that BERT could apparently imbue neural networks with near-Aristotelian reasoning skills, they suspected a simpler explanation: that BERT was picking up on superficial patterns in the way the warrants were phrased. Indeed, after re-analyzing their training data, the authors found ample evidence of these so-called spurious cues. For example, simply choosing a warrant with the word “not” in it led to correct answers 61% of the time. After these patterns were scrubbed from the data, BERT’s score dropped from 77 to 53 — equivalent to random guessing. An article in <i>The Gradient</i>, a machine-learning magazine published out of the Stanford Artificial Intelligence Laboratory, <a href="https://thegradient.pub/nlps-clever-hans-moment-has-arrived/">compared BERT to Clever Hans</a>, the horse with the phony powers of arithmetic.</p>
<div id='component-5e03cfe9d06d3'><script type="text/template">{"type":"Blockquote","id":"component-5e03cfe9d06d3","data":{"quote":"<p>Chess felt like a serious test of intelligence until we figured out how to write a chess program.<\/p>\n","alignment":"right","quote_attribution":"<p>Sam Bowman<\/p>\n","twitter_text":""}}</script></div>
<p>In another paper called “<a href="https://www.aclweb.org/anthology/P19-1334">Right for the Wrong Reasons</a>,” Linzen and his coauthors published evidence that BERT’s high performance on certain GLUE tasks might also be attributed to spurious cues in the training data for those tasks. (The paper included an alternative data set designed to specifically expose the kind of shortcut that Linzen suspected BERT was using on GLUE. The data set’s name: Heuristic Analysis for Natural-Language-Inference Systems, or HANS.)</p>
<p>So is BERT, and all of its benchmark-busting siblings, essentially a sham? Bowman agrees with Linzen that some of GLUE’s training data is messy — shot through with subtle biases introduced by the humans who created it, all of which are potentially exploitable by a powerful BERT-based neural network. “There’s no single ‘cheap trick’ that will let it solve everything [in GLUE], but there are lots of shortcuts it can take that will really help,” Bowman said, “and the model can pick up on those shortcuts.” But he doesn’t think BERT’s foundation is built on sand, either. “It seems like we have a model that has really learned something substantial about language,” he said. “But it’s definitely not understanding English in a comprehensive and robust way.”</p>
<p>According to <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>, a computer scientist at the University of Washington and the Allen Institute, one way to encourage progress toward robust understanding is to focus not just on building a better BERT, but also on designing better benchmarks and training data that lower the possibility of Clever Hans–style cheating. Her work explores an approach called adversarial filtering, which uses algorithms to scan NLP training data sets and remove examples that are overly repetitive or that otherwise introduce spurious cues for a neural network to pick up on. After this adversarial filtering, “BERT’s performance can reduce significantly,” she said, while “human performance does not drop so much.”</p>
<p>Still, some NLP researchers believe that even with better training, neural language models may still face a fundamental obstacle to real understanding. Even with its powerful pretraining, BERT is not designed to perfectly model language in general. Instead, after fine-tuning, it models “a specific NLP task, or even a specific data set for that task,” said <a href="https://www.cs.uml.edu/~arogers/">Anna Rogers</a>, a computational linguist at the Text Machine Lab at the University of Massachusetts, Lowell. And it’s likely that no training data set, no matter how comprehensively designed or carefully filtered, can capture all the edge cases and unforeseen inputs that humans effortlessly cope with when we use natural language.</p>
<div id='component-5e03cfe9d1842'><script type="text/template">{"type":"LinkList","id":"component-5e03cfe9d1842","data":{"title":"Related:","links":[{"type":"internal","link":"https:\/\/www.quantamagazine.org\/computers-and-humans-see-differently-does-it-matter-20190917\/","title":"Computers and Humans \u2018See\u2019 Differently. Does It Matter?"},{"type":"internal","link":"https:\/\/www.quantamagazine.org\/been-kim-is-building-a-translator-for-artificial-intelligence-20190110\/","title":"A New Approach to Understanding How Machines Think"},{"type":"internal","link":"https:\/\/www.quantamagazine.org\/foundations-built-for-a-general-theory-of-neural-networks-20190131\/","title":"Foundations Built for a General Theory of Neural Networks"},{"type":"internal","link":"https:\/\/www.quantamagazine.org\/why-alphazeros-artificial-intelligence-has-trouble-with-the-real-world-20180221\/","title":"Why Artificial Intelligence Like AlphaZero Has Trouble With the Real World"}]}}</script></div>
<p>Bowman points out that it’s hard to know how we would ever be fully convinced that a neural network achieves anything like real understanding. Standardized tests, after all, are supposed to reveal something intrinsic and generalizable about the test-taker’s knowledge. But as anyone who has taken an SAT prep course knows, tests can be gamed. “We have a hard time making tests that are hard enough and trick-proof enough that solving [them] really convinces us that we’ve fully solved some aspect of AI or language technology,” he said.</p>
<p>Indeed, Bowman and his collaborators recently introduced a test called <a href="https://super.gluebenchmark.com/leaderboard">SuperGLUE</a> that’s specifically designed to be hard for BERT-based systems. So far, no neural network can beat human performance on it. But even if (or when) it happens, does it mean that machines can really understand language any better than before? Or does just it mean that science has gotten better at teaching machines to the test?</p>
<p>“That’s a good analogy,” Bowman said. “We figured out how to solve the LSAT and the MCAT, and we might not actually be qualified to be doctors and lawyers.” Still, he added, this seems to be the way that artificial intelligence research moves forward. “Chess felt like a serious test of intelligence until we figured out how to write a chess program,” he said. “We’re definitely in an era where the goal is to keep coming up with harder problems that represent language understanding, and keep figuring out how to solve those problems.”</p>
<p><em>Clarification: On October 17, this article was updated to clarify the point made by Anna Rogers.</em></p>
<p class="p1"><span class="s1"><i>This article was reprinted on </i><a href="https://www.wired.com/story/computers-are-learning-to-read-but-theyre-still-not-so-smart/"><i>Wired.com</i></a><i>.</i></span></p>
</div></div></div></section><aside class="post__sidebar hide flex flex-justify-center theme__anchors--solid" data-reactid="296"><div class="post__sidebar__content" data-reactid="297"><div class="post__sidebar__content__inner" data-reactid="298"><h3 class="mt0" data-reactid="299">Share this article</h3><div data-reactid="300"><div class="social-links social-links--share flex flex-justify-between" data-reactid="301"><a href="http://www.facebook.com/sharer.php?u=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="_blank" class="social-links__link flex flex-items-center relative facebook" data-reactid="302"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="303"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="304"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="305"><path fill="currentColor" d="M13 16.5h5.1v-5c-.2-2.7.3-5.4 1.7-7.7 1.8-2.5 4.9-4 8-3.8 3.1-.1 6.2.2 9.2 1l-1.3 7.7C34.4 8.3 33 8 31.6 8c-2 0-3.8.7-3.8 2.7v5.9H36l-.6 7.5h-7.6V50h-9.6V23.9H13v-7.4z" data-reactid="306"></path></svg></div></a><a href="https://twitter.com/share?url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/&amp;text=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?&amp;via=QuantaMagazine" target="_blank" class="social-links__link flex flex-items-center relative twitter" data-reactid="307"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="308"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="309"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="310"><path fill="currentColor" d="M50 9.9c-1.9.8-3.8 1.3-5.9 1.6 2.1-1.3 3.7-3.2 4.5-5.6-2 1.2-4.2 2-6.5 2.5-3.8-4.1-10.3-4.5-14.5-.8-2.8 2.5-4 6.3-3.1 10-8.2-.5-15.8-4.3-21-10.6-2.7 4.6-1.3 10.5 3.2 13.5C5 20.4 3.4 20 2 19.2c0 4.8 3.4 8.9 8.2 9.9-.9.2-1.8.4-2.7.3-.6 0-1.3-.1-1.9-.2 1.3 4.1 5.2 6.9 9.5 7C10.8 39.5 5.4 41 0 40.4c13.5 8.5 31.5 4.6 40.2-8.7 3-4.6 4.6-10 4.6-15.5v-1.3c2-1.3 3.7-3.1 5.2-5" data-reactid="311"></path></svg></div></a><a href="#0" target="" class="social-links__link flex flex-items-center relative link" data-reactid="312"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="313"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="314"></div><svg class="absolute fit-x mxa c-1a1a1a" x="0px" y="0px" viewBox="0 0 50 50" enable-background="new 0 0 50 50" xml:space="preserve" data-reactid="315"><g data-reactid="316"><!-- react-text: 317 --> <!-- /react-text --><path fill="currentColor" d="M20.6,38.5c-0.8,0-1.6,0.3-2.2,0.8L16,41.9c-1.1,1-2.4,1.6-3.9,1.6c-1.5,0-2.8-0.5-3.9-1.6c-0.5-0.5-0.9-1.1-1.2-1.8 c-0.3-0.7-0.4-1.4-0.4-2.1c0-0.7,0.1-1.4,0.4-2.1c0.3-0.7,0.7-1.2,1.2-1.8l9.1-9c1-0.9,2.2-1.8,3.8-2.7s3-0.7,4.3,0.7 c0.6,0.6,1.3,0.8,2.2,0.8s1.5-0.3,2.1-0.9c0.6-0.6,0.9-1.3,0.9-2.2s-0.3-1.6-0.9-2.2c-2.2-2.2-4.8-3.1-7.8-2.7 c-3,0.4-5.9,2-8.8,4.8l-9.2,9c-1.1,1.1-1.9,2.4-2.5,3.8C0.7,35,0.4,36.5,0.4,38c0,1.6,0.3,3,0.9,4.4c0.6,1.4,1.4,2.7,2.5,3.8 c1.1,1.1,2.4,2,3.8,2.5c1.4,0.6,2.9,0.8,4.4,0.8s2.9-0.3,4.3-0.8c1.4-0.6,2.7-1.4,3.8-2.5l2.5-2.5c0.6-0.6,0.9-1.3,0.9-2.1 s-0.3-1.6-0.9-2.2C22.1,38.8,21.4,38.5,20.6,38.5z" data-reactid="318"></path><!-- react-text: 319 --> <!-- /react-text --><path fill="currentColor" d="M48.7,7.9c-0.6-1.4-1.4-2.7-2.5-3.8c-2.4-2.4-5.1-3.6-8-3.7c-3-0.1-5.5,0.9-7.7,3.1l-3.1,3.1c-0.6,0.6-0.9,1.3-0.9,2.1 s0.3,1.6,0.9,2.2s1.3,0.9,2.2,0.9s1.6-0.3,2.2-0.8l3.1-3.1c1.2-1.1,2.4-1.5,3.7-1.3c1.3,0.3,2.5,0.9,3.4,1.9 c0.5,0.5,0.9,1.1,1.2,1.8c0.3,0.7,0.4,1.4,0.4,2.1c0,0.7-0.1,1.4-0.4,2.1c-0.3,0.7-0.7,1.2-1.2,1.8l-9.7,9.6 c-2.2,2.2-3.9,3.1-5.1,2.7s-2-0.8-2.4-1.3c-0.6-0.6-1.3-0.8-2.2-0.8s-1.5,0.3-2.1,0.9c-0.6,0.6-0.9,1.3-0.9,2.2s0.3,1.5,0.9,2.1 c1,1,2.1,1.8,3.2,2.3s2.4,0.7,3.6,0.7c1.5,0,3-0.4,4.6-1.1c1.6-0.7,3.1-1.9,4.6-3.4l9.8-9.6c1.1-1.1,1.9-2.4,2.5-3.8 c0.6-1.4,0.9-2.9,0.9-4.4C49.6,10.8,49.3,9.3,48.7,7.9z" data-reactid="320"></path><!-- react-text: 321 --> <!-- /react-text --></g></svg></div></a><div class="q-tooltip hidden force-mobile-placement" style="width:unsetpx;top:140px;" data-reactid="322"><div class="q-tooltip-content" data-reactid="323"><div class="q-tooltip-arrow" data-reactid="324"></div><div class="q-tooltip-inner" role="tooltip" data-reactid="325"><h6 class="relative z1 uppercase kern mv0" data-reactid="326">Copied!</h6></div></div></div><a href="mailto:?subject=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?&amp;body=A%20tool%20known%20as%20BERT%20can%20now%20beat%20humans%20on%20advanced%20reading-comprehension%20tests.%20But%20it&#x27;s%20also%20revealed%20how%20far%20AI%20has%20to%20go.%0A%0Ahttps://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="" class="social-links__link flex flex-items-center relative email" data-reactid="327"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="328"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="329"></div><svg class="absolute fit-x mxa c-1a1a1a" x="0px" y="0px" viewBox="0 0 50 50" enable-background="new 0 0 50 50" xml:space="preserve" data-reactid="330"><path fill="currentColor" d="M25,29.5l-5.2-4.3L1.8,43.8h46L30.1,25.2L25,29.5z M32.6,23.2l17.2,17.9c0-0.2,0.1-0.3,0.1-0.5c0-0.2,0-0.4,0-0.6V9.1 L32.6,23.2z M0,9.1v31c0,0.2,0,0.4,0,0.6s0.1,0.3,0.1,0.5l17.3-17.8L0,9.1z M48.4,6.2H1.6L25,25L48.4,6.2z" data-reactid="331"></path></svg></div></a></div><div class="social-hide closed" data-reactid="332"><div class="social-links social-links--share flex flex-justify-between" data-reactid="333"><a href="https://getpocket.com/save?url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/&amp;title=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?" target="_blank" class="social-links__link flex flex-items-center relative pocket" data-reactid="334"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="335"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="336"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="337"><path fill="currentColor" d="M2.6,1.7C1.3,1.6,0.1,2.7,0,4.1c0,0.1,0,0.3,0,0.4v9.9c0,8.1,8,14.4,15,14.4c8-0.1,14.6-6.4,15-14.4v-10 c0.1-1.4-0.9-2.6-2.3-2.8c-0.2,0-0.4,0-0.5,0L2.6,1.7z M9,9.8l6,5.7l6-5.7c2.8-1.1,3.9,2,2.8,2.8L16,20.1c-0.6,0.3-1.3,0.3-1.9,0 l-7.9-7.5C5.2,11.5,6.5,8.4,9,9.8L9,9.8z" data-reactid="338"></path></svg></div></a><a href="https://www.reddit.com/submit?url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="_blank" class="social-links__link flex flex-items-center relative reddit" data-reactid="339"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="340"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="341"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="4 0 33 33" enable-background="new 0 0 30 30" data-reactid="342"><path fill="currentColor" d="M39.58,19.65A4.72,4.72,0,0,0,31.91,16a22.4,22.4,0,0,0-10.42-3.09l2-6.38,5.6,1.31a3.91,3.91,0,1,0,.43-2.08L23.05,4.27A1.08,1.08,0,0,0,21.79,5L19.26,12.9A22.6,22.6,0,0,0,8,16a4.68,4.68,0,1,0-5.56,7.51,8.32,8.32,0,0,0-.08,1.12c0,3.21,1.89,6.2,5.31,8.41a22.69,22.69,0,0,0,12.23,3.3A22.67,22.67,0,0,0,32.15,33c3.43-2.21,5.31-5.2,5.31-8.41a8.77,8.77,0,0,0-.06-1,4.65,4.65,0,0,0,2.18-3.93M33.05,5.8a1.78,1.78,0,1,1-1.8,1.78,1.79,1.79,0,0,1,1.8-1.78M11.52,22.53a2.71,2.71,0,0,1,2.69-2.66,2.65,2.65,0,1,1-2.69,2.66m14.93,7.73c-1.37,1.35-3.47,2-6.43,2h0c-3,0-5.06-.65-6.43-2a1.05,1.05,0,0,1,0-1.5,1.09,1.09,0,0,1,1.52,0c.94.93,2.54,1.38,4.91,1.38h0c2.37,0,4-.45,4.91-1.38a1.08,1.08,0,0,1,1.52,0,1.07,1.07,0,0,1,0,1.5m-.63-5.1a2.65,2.65,0,1,1,2.66-2.63,2.65,2.65,0,0,1-2.66,2.63" transform="translate(-0.42 -3.68)" data-reactid="343"></path></svg></div></a><a href="https://news.ycombinator.com/submitlink?u=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/&amp;t=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?" target="_blank" class="social-links__link flex flex-items-center relative hackernews" data-reactid="344"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="345"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="346"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="347"><path fill="currentColor" d="M12.9,18L3.2-0.1h4.4l5.7,11.5l0.3,0.6c0.1,0.2,0.2,0.4,0.3,0.7c0,0.1,0,0.2,0,0.2v0.2l0.4,0.9l0.5,0.7 l0.8-1.6l0.9-1.8l5.8-11.5h4.1l-9.8,18.3v11.7h-3.7V18z" data-reactid="348"></path></svg></div></a><a href="https://share.flipboard.com/bookmarklet/popout?v=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?&amp;url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="_blank" class="social-links__link flex flex-items-center relative flipboard" data-reactid="349"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="350"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="351"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="352"><path fill="currentColor" d="M30,0 0,0 0,30 10,30 10,20 20,20 20,10 30,10 z" data-reactid="353"></path></svg></div></a></div></div><div class="flex flex-justify-center social-more" data-reactid="354"><svg class="ml05 icon icon-offset closed" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="355"><path fill="currentColor" d="M15,20.7c-0.1,0-0.3,0-0.4-0.1L0.3,10.7l0.9-1.2L15,19l13.8-9.5l0.9,1.2l-14.3,9.8C15.3,20.6,15.1,20.7,15,20.7 z" data-reactid="356"></path></svg></div></div><div class="sidebar__newsletter" data-reactid="357"><div class="pv05" data-reactid="358"><hr class="o2 mv1" data-reactid="359"/></div><h3 class="mv0" data-reactid="360">Newsletter</h3><p class="scale5 o4 mb1 mt025" data-reactid="361"><em data-reactid="362">Get Quanta Magazine delivered to your inbox</em></p></div><div class="theme__text theme__accent-hover mb05" data-reactid="363"><a href="#newsletter" data-reactid="364"><button class="button button--small pangram bold scale5 fill-h" data-reactid="365">Subscribe now</button></a></div><a href="http://us1.campaign-archive2.com/home/?u=0d6ddf7dc1a0b7297c8e06618&amp;id=f0cb61321c" class="pangram h5 relative" target="_blank" data-reactid="366"><small class="flex flex-items-center" data-reactid="367"><span data-reactid="368">Most recent newsletter</span><svg class="ml05 icon" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="369"><path fill="currentColor" d="M50 25l-17.4-8.7v6.5H0v4.4h32.6v6.5" data-reactid="370"></path></svg></small></a></div></div></aside></div></div></div></div><div class="pv2" data-reactid="371"></div><div class="post__footer" data-reactid="372"><div class="mha container--m" data-reactid="373"><div class="flex flex-wrap flex-items-stretch" data-reactid="374"><div class="post__footer__col fill-h pv2 flex flex-items-center flex-justify-center" data-reactid="375"><section class="outer" data-reactid="376"><aside class="post__sidebar hide flex flex-justify-center post__sidebar--footer" data-reactid="377"><div class="post__sidebar__content" data-reactid="378"><div class="post__sidebar__content__inner" data-reactid="379"><div class="align-c mb075" data-reactid="380"><div class="sidebar__author" data-reactid="381"><a class="theme__accent-hover transition--color" href="/authors/john-pavlus/" data-reactid="382"><div class="sidebar__author__avatar mha mb1" data-reactid="383"><div class="image mx0 relative image--circle" data-reactid="384"><div class="image__inner absolute fit-x" data-reactid="385"><img class="absolute fit-x fill-h fill-v mxa" data-reactid="386"/></div><noscript data-reactid="387"><img class="absolute fit-x fill-h fill-v is-loaded" src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/John_Pavlus1.jpg"/></noscript></div></div><h3 class="mv05" data-reactid="388">John Pavlus</h3><p class="h5 o8 mt05 mb1 theme__text" data-reactid="389"><em data-reactid="390">Contributing Writer</em></p></a></div><hr class="mb075 o1" data-reactid="391"/><p class="h6 o6 mv1 pv025" data-reactid="392"><em data-reactid="393">October 17, 2019</em></p></div><div class="sidebar__actions" data-reactid="394"><hr class="mt075 mb1 o1" data-reactid="395"/><a href="#" id="print-friendly-button" class="h6 pangram uppercase mv05 pb1 bold kern flex flex-items-center flex-justify-between sidebar__print transition--color theme__accent-hover" data-reactid="396"><small data-reactid="397">View PDF/Print Mode</small><svg class="icon-l theme__accent ml05" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="398"><path fill="currentColor" d="M39.9,27.5h4.9v22.4H0.1V5.1h22.4V10H5v35h35V27.5z M49.8,0.1h-2.4h-1H33.8V5h7.6L20.7,25.8l3.4,3.4L45,8.4v7.7h4.9V2.6L49.8,0.1z" data-reactid="399"></path></svg></a></div><div class="mt1 pt05 sidebar__tag-wrap" data-reactid="400"><a class="sidebar__tag h6 pangram medium inline-block mb0 relative" href="/tag/artificial-intelligence/" data-reactid="401"><span class="absolute fit-x theme__text-background o1" data-reactid="402"></span><span class="theme__text theme__accent-hover transition--color relative" data-reactid="403">artificial intelligence</span></a><a class="sidebar__tag h6 pangram medium inline-block mb0 relative" href="/tag/computer-science/" data-reactid="404"><span class="absolute fit-x theme__text-background o1" data-reactid="405"></span><span class="theme__text theme__accent-hover transition--color relative" data-reactid="406">computer science</span></a><a class="sidebar__tag h6 pangram medium inline-block mb0 relative" href="/tag/machine-learning/" data-reactid="407"><span class="absolute fit-x theme__text-background o1" data-reactid="408"></span><span class="theme__text theme__accent-hover transition--color relative" data-reactid="409">machine learning</span></a><a class="sidebar__tag h6 pangram medium inline-block mb0 relative" href="/tag/natural-language-processing/" data-reactid="410"><span class="absolute fit-x theme__text-background o1" data-reactid="411"></span><span class="theme__text theme__accent-hover transition--color relative" data-reactid="412">natural language processing</span></a><a class="sidebar__tag h6 pangram medium inline-block mb0 relative" href="/tag/neural-networks/" data-reactid="413"><span class="absolute fit-x theme__text-background o1" data-reactid="414"></span><span class="theme__text theme__accent-hover transition--color relative" data-reactid="415">neural networks</span></a></div></div><div class="sidebar__poster" data-reactid="416"><a href="https://www.quantamagazine.org/gift-store" title="Alice and Bob Meet the Wall of Fire - The Biggest Ideas in Science from Quanta – Available now!" class="sidebar__poster__desktop" target="_blank" data-reactid="417"><img src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Article_320x600_Science.jpg" alt="Alice and Bob Meet the Wall of Fire - The Biggest Ideas in Science from Quanta – Available now!" class="fill-h" data-reactid="418"/></a><a href="https://www.quantamagazine.org/gift-store" title="Alice and Bob Meet the Wall of Fire - The Biggest Ideas in Science from Quanta – Available now!" class="sidebar__poster__mobile" target="_blank" data-reactid="419"><img src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Mobile_250x200_2x_Science.jpg" alt="Alice and Bob Meet the Wall of Fire - The Biggest Ideas in Science from Quanta – Available now!" class="fill-h" data-reactid="420"/></a></div></div></aside></section></div><div class="post__footer__col fill-h pv2 flex flex-items-center flex-justify-center" data-reactid="421"><section class="outer fill-h" data-reactid="422"><aside class="post__sidebar hide flex flex-justify-center theme__anchors--solid post__sidebar--footer" data-reactid="423"><div class="post__sidebar__content" data-reactid="424"><div class="post__sidebar__content__inner" data-reactid="425"><h3 class="mt0" data-reactid="426">Share this article</h3><div data-reactid="427"><div class="social-links social-links--share flex flex-justify-between" data-reactid="428"><a href="http://www.facebook.com/sharer.php?u=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="_blank" class="social-links__link flex flex-items-center relative facebook" data-reactid="429"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="430"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="431"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="432"><path fill="currentColor" d="M13 16.5h5.1v-5c-.2-2.7.3-5.4 1.7-7.7 1.8-2.5 4.9-4 8-3.8 3.1-.1 6.2.2 9.2 1l-1.3 7.7C34.4 8.3 33 8 31.6 8c-2 0-3.8.7-3.8 2.7v5.9H36l-.6 7.5h-7.6V50h-9.6V23.9H13v-7.4z" data-reactid="433"></path></svg></div></a><a href="https://twitter.com/share?url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/&amp;text=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?&amp;via=QuantaMagazine" target="_blank" class="social-links__link flex flex-items-center relative twitter" data-reactid="434"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="435"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="436"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="437"><path fill="currentColor" d="M50 9.9c-1.9.8-3.8 1.3-5.9 1.6 2.1-1.3 3.7-3.2 4.5-5.6-2 1.2-4.2 2-6.5 2.5-3.8-4.1-10.3-4.5-14.5-.8-2.8 2.5-4 6.3-3.1 10-8.2-.5-15.8-4.3-21-10.6-2.7 4.6-1.3 10.5 3.2 13.5C5 20.4 3.4 20 2 19.2c0 4.8 3.4 8.9 8.2 9.9-.9.2-1.8.4-2.7.3-.6 0-1.3-.1-1.9-.2 1.3 4.1 5.2 6.9 9.5 7C10.8 39.5 5.4 41 0 40.4c13.5 8.5 31.5 4.6 40.2-8.7 3-4.6 4.6-10 4.6-15.5v-1.3c2-1.3 3.7-3.1 5.2-5" data-reactid="438"></path></svg></div></a><a href="#0" target="" class="social-links__link flex flex-items-center relative link" data-reactid="439"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="440"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="441"></div><svg class="absolute fit-x mxa c-1a1a1a" x="0px" y="0px" viewBox="0 0 50 50" enable-background="new 0 0 50 50" xml:space="preserve" data-reactid="442"><g data-reactid="443"><!-- react-text: 444 --> <!-- /react-text --><path fill="currentColor" d="M20.6,38.5c-0.8,0-1.6,0.3-2.2,0.8L16,41.9c-1.1,1-2.4,1.6-3.9,1.6c-1.5,0-2.8-0.5-3.9-1.6c-0.5-0.5-0.9-1.1-1.2-1.8 c-0.3-0.7-0.4-1.4-0.4-2.1c0-0.7,0.1-1.4,0.4-2.1c0.3-0.7,0.7-1.2,1.2-1.8l9.1-9c1-0.9,2.2-1.8,3.8-2.7s3-0.7,4.3,0.7 c0.6,0.6,1.3,0.8,2.2,0.8s1.5-0.3,2.1-0.9c0.6-0.6,0.9-1.3,0.9-2.2s-0.3-1.6-0.9-2.2c-2.2-2.2-4.8-3.1-7.8-2.7 c-3,0.4-5.9,2-8.8,4.8l-9.2,9c-1.1,1.1-1.9,2.4-2.5,3.8C0.7,35,0.4,36.5,0.4,38c0,1.6,0.3,3,0.9,4.4c0.6,1.4,1.4,2.7,2.5,3.8 c1.1,1.1,2.4,2,3.8,2.5c1.4,0.6,2.9,0.8,4.4,0.8s2.9-0.3,4.3-0.8c1.4-0.6,2.7-1.4,3.8-2.5l2.5-2.5c0.6-0.6,0.9-1.3,0.9-2.1 s-0.3-1.6-0.9-2.2C22.1,38.8,21.4,38.5,20.6,38.5z" data-reactid="445"></path><!-- react-text: 446 --> <!-- /react-text --><path fill="currentColor" d="M48.7,7.9c-0.6-1.4-1.4-2.7-2.5-3.8c-2.4-2.4-5.1-3.6-8-3.7c-3-0.1-5.5,0.9-7.7,3.1l-3.1,3.1c-0.6,0.6-0.9,1.3-0.9,2.1 s0.3,1.6,0.9,2.2s1.3,0.9,2.2,0.9s1.6-0.3,2.2-0.8l3.1-3.1c1.2-1.1,2.4-1.5,3.7-1.3c1.3,0.3,2.5,0.9,3.4,1.9 c0.5,0.5,0.9,1.1,1.2,1.8c0.3,0.7,0.4,1.4,0.4,2.1c0,0.7-0.1,1.4-0.4,2.1c-0.3,0.7-0.7,1.2-1.2,1.8l-9.7,9.6 c-2.2,2.2-3.9,3.1-5.1,2.7s-2-0.8-2.4-1.3c-0.6-0.6-1.3-0.8-2.2-0.8s-1.5,0.3-2.1,0.9c-0.6,0.6-0.9,1.3-0.9,2.2s0.3,1.5,0.9,2.1 c1,1,2.1,1.8,3.2,2.3s2.4,0.7,3.6,0.7c1.5,0,3-0.4,4.6-1.1c1.6-0.7,3.1-1.9,4.6-3.4l9.8-9.6c1.1-1.1,1.9-2.4,2.5-3.8 c0.6-1.4,0.9-2.9,0.9-4.4C49.6,10.8,49.3,9.3,48.7,7.9z" data-reactid="447"></path><!-- react-text: 448 --> <!-- /react-text --></g></svg></div></a><div class="q-tooltip hidden force-mobile-placement" style="width:unsetpx;top:140px;" data-reactid="449"><div class="q-tooltip-content" data-reactid="450"><div class="q-tooltip-arrow" data-reactid="451"></div><div class="q-tooltip-inner" role="tooltip" data-reactid="452"><h6 class="relative z1 uppercase kern mv0" data-reactid="453">Copied!</h6></div></div></div><a href="mailto:?subject=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?&amp;body=A%20tool%20known%20as%20BERT%20can%20now%20beat%20humans%20on%20advanced%20reading-comprehension%20tests.%20But%20it&#x27;s%20also%20revealed%20how%20far%20AI%20has%20to%20go.%0A%0Ahttps://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="" class="social-links__link flex flex-items-center relative email" data-reactid="454"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="455"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="456"></div><svg class="absolute fit-x mxa c-1a1a1a" x="0px" y="0px" viewBox="0 0 50 50" enable-background="new 0 0 50 50" xml:space="preserve" data-reactid="457"><path fill="currentColor" d="M25,29.5l-5.2-4.3L1.8,43.8h46L30.1,25.2L25,29.5z M32.6,23.2l17.2,17.9c0-0.2,0.1-0.3,0.1-0.5c0-0.2,0-0.4,0-0.6V9.1 L32.6,23.2z M0,9.1v31c0,0.2,0,0.4,0,0.6s0.1,0.3,0.1,0.5l17.3-17.8L0,9.1z M48.4,6.2H1.6L25,25L48.4,6.2z" data-reactid="458"></path></svg></div></a></div><div class="social-hide closed" data-reactid="459"><div class="social-links social-links--share flex flex-justify-between" data-reactid="460"><a href="https://getpocket.com/save?url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/&amp;title=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?" target="_blank" class="social-links__link flex flex-items-center relative pocket" data-reactid="461"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="462"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="463"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="464"><path fill="currentColor" d="M2.6,1.7C1.3,1.6,0.1,2.7,0,4.1c0,0.1,0,0.3,0,0.4v9.9c0,8.1,8,14.4,15,14.4c8-0.1,14.6-6.4,15-14.4v-10 c0.1-1.4-0.9-2.6-2.3-2.8c-0.2,0-0.4,0-0.5,0L2.6,1.7z M9,9.8l6,5.7l6-5.7c2.8-1.1,3.9,2,2.8,2.8L16,20.1c-0.6,0.3-1.3,0.3-1.9,0 l-7.9-7.5C5.2,11.5,6.5,8.4,9,9.8L9,9.8z" data-reactid="465"></path></svg></div></a><a href="https://www.reddit.com/submit?url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="_blank" class="social-links__link flex flex-items-center relative reddit" data-reactid="466"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="467"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="468"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="4 0 33 33" enable-background="new 0 0 30 30" data-reactid="469"><path fill="currentColor" d="M39.58,19.65A4.72,4.72,0,0,0,31.91,16a22.4,22.4,0,0,0-10.42-3.09l2-6.38,5.6,1.31a3.91,3.91,0,1,0,.43-2.08L23.05,4.27A1.08,1.08,0,0,0,21.79,5L19.26,12.9A22.6,22.6,0,0,0,8,16a4.68,4.68,0,1,0-5.56,7.51,8.32,8.32,0,0,0-.08,1.12c0,3.21,1.89,6.2,5.31,8.41a22.69,22.69,0,0,0,12.23,3.3A22.67,22.67,0,0,0,32.15,33c3.43-2.21,5.31-5.2,5.31-8.41a8.77,8.77,0,0,0-.06-1,4.65,4.65,0,0,0,2.18-3.93M33.05,5.8a1.78,1.78,0,1,1-1.8,1.78,1.79,1.79,0,0,1,1.8-1.78M11.52,22.53a2.71,2.71,0,0,1,2.69-2.66,2.65,2.65,0,1,1-2.69,2.66m14.93,7.73c-1.37,1.35-3.47,2-6.43,2h0c-3,0-5.06-.65-6.43-2a1.05,1.05,0,0,1,0-1.5,1.09,1.09,0,0,1,1.52,0c.94.93,2.54,1.38,4.91,1.38h0c2.37,0,4-.45,4.91-1.38a1.08,1.08,0,0,1,1.52,0,1.07,1.07,0,0,1,0,1.5m-.63-5.1a2.65,2.65,0,1,1,2.66-2.63,2.65,2.65,0,0,1-2.66,2.63" transform="translate(-0.42 -3.68)" data-reactid="470"></path></svg></div></a><a href="https://news.ycombinator.com/submitlink?u=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/&amp;t=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?" target="_blank" class="social-links__link flex flex-items-center relative hackernews" data-reactid="471"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="472"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="473"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="474"><path fill="currentColor" d="M12.9,18L3.2-0.1h4.4l5.7,11.5l0.3,0.6c0.1,0.2,0.2,0.4,0.3,0.7c0,0.1,0,0.2,0,0.2v0.2l0.4,0.9l0.5,0.7 l0.8-1.6l0.9-1.8l5.8-11.5h4.1l-9.8,18.3v11.7h-3.7V18z" data-reactid="475"></path></svg></div></a><a href="https://share.flipboard.com/bookmarklet/popout?v=Machines%20Beat%20Humans%20on%20a%20Reading%20Test.%20But%20Do%20They%20Understand?&amp;url=https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/" target="_blank" class="social-links__link flex flex-items-center relative flipboard" data-reactid="476"><div class="icon-button inline-block relative pointer _hover_div-c-ff8600 _hover_div-opacity-1 _hover_svg-c-ff8600" data-reactid="477"><div class="absolute fit-x mxa o2 c-1a1a1a" data-reactid="478"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="479"><path fill="currentColor" d="M30,0 0,0 0,30 10,30 10,20 20,20 20,10 30,10 z" data-reactid="480"></path></svg></div></a></div></div><div class="flex flex-justify-center social-more" data-reactid="481"><svg class="ml05 icon icon-offset closed" viewBox="0 0 30 30" enable-background="new 0 0 30 30" data-reactid="482"><path fill="currentColor" d="M15,20.7c-0.1,0-0.3,0-0.4-0.1L0.3,10.7l0.9-1.2L15,19l13.8-9.5l0.9,1.2l-14.3,9.8C15.3,20.6,15.1,20.7,15,20.7 z" data-reactid="483"></path></svg></div></div><div class="sidebar__newsletter" data-reactid="484"><div class="pv05" data-reactid="485"><hr class="o2 mv1" data-reactid="486"/></div><h3 class="mv0" data-reactid="487">Newsletter</h3><p class="scale5 o4 mb1 mt025" data-reactid="488"><em data-reactid="489">Get Quanta Magazine delivered to your inbox</em></p></div><div class="theme__text theme__accent-hover mb05" data-reactid="490"><a href="#newsletter" data-reactid="491"><button class="button button--small pangram bold scale5 fill-h" data-reactid="492">Subscribe now</button></a></div><a href="http://us1.campaign-archive2.com/home/?u=0d6ddf7dc1a0b7297c8e06618&amp;id=f0cb61321c" class="pangram h5 relative" target="_blank" data-reactid="493"><small class="flex flex-items-center" data-reactid="494"><span data-reactid="495">Most recent newsletter</span><svg class="ml05 icon" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="496"><path fill="currentColor" d="M50 25l-17.4-8.7v6.5H0v4.4h32.6v6.5" data-reactid="497"></path></svg></small></a></div></div></aside></section></div></div></div></div></div><section class="outer newsletter bg-gray1 align-c pv1 scale1" id="newsletter" data-reactid="498"><div class="scale0 mt1 pv05 mha container--xs" data-reactid="499"><h2 class="newsletter__title h1 noe mv0" data-reactid="500">The Quanta Newsletter</h2><p class="gray4 mt025 scale5" data-reactid="501"><em data-reactid="502">Get highlights of the most important news delivered to your email inbox</em></p><div class="newsletter__form block mha" data-reactid="503"><form action="https://quantamagazine.us1.list-manage.com/subscribe/post?u=0d6ddf7dc1a0b7297c8e06618&amp;id=f0cb61321c" target="_blank" method="post" class="bg-white" data-reactid="504"><div class="newsletter__form__inner flex flex-items-start mha" data-reactid="505"><div class="newsletter__form__field flex flex-auto relative fill-v" data-reactid="506"><input type="email" class="flex fill-h px1 input--transparent pangram light scale3" name="EMAIL" placeholder="Email address" autocorrect="off" autocapitalize="off" data-reactid="507"/></div><button type="submit" class="ph2 pangram scale5 medium fill-v orange hover--black" data-reactid="508">Subscribe</button></div></form></div><h4 class="inline-block" data-reactid="509"><a target="_blank" href="http://us1.campaign-archive2.com/home/?u=0d6ddf7dc1a0b7297c8e06618&amp;id=f0cb61321c" class="newsletter__link inline-block link--underline orange hover--black transition--color" data-reactid="510"><span class="" data-reactid="511">Most recent newsletter</span></a></h4></div><div class="mega__other__divider mv2 white o2 shop_divider" data-reactid="512"></div></section><section class="outer post__category pv2 outer--content" data-reactid="513"><div class="loader relative fill-h" data-reactid="514"></div></section><section class="outer comments relative fill-h bg-gray1 pt2 outer--content" id="comments" data-reactid="515"><h1 class="h1 noe pb025 align-c mt1" data-reactid="516">Comment on this article</h1><div class="mha container--s" data-reactid="517"><div class="comments__inner bg-white mha p ph1 pt2 pb1 mb1" data-reactid="518"><div class="mha container--xs" data-reactid="519"><div class="comments__disclaimer scale5 o6 italic align-l mv1 pb1" data-reactid="520"><p class="byline"><small><em>Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. </em></small></p>
</div><div data-reactid="521"><div id="disqus_thread" data-reactid="522"></div></div></div></div></div><div class="comments__expand absolute align-c fit-b fit-l fit-r flex flex-items-center flex-justify-center" data-reactid="523"><button class="link--underline orange hover--black pangram bold inline-block" data-reactid="524">Show comments</button></div></section><div class="next-post block relative fill-h" style="background-image:url();" data-reactid="525"><div class="next-post__image-wrapper absolute z0 fit-r fit-l fit-t" data-reactid="526"><div class="image mx0 relative image--wide" data-reactid="527"><div class="image__inner absolute fit-x" data-reactid="528"><img class="absolute fit-x fill-h fill-v mxa" alt="Illustration of two strips of movie film coiled around each other in a double helix." data-reactid="529"/></div><noscript data-reactid="530"><img class="absolute fit-x fill-h fill-v is-loaded" src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_2880x1220Lede-2880x1220.jpg" alt="Illustration of two strips of movie film coiled around each other in a double helix."/></noscript></div></div><div class="overlay bg-black o4 absolute fit-x" data-reactid="531"></div><section class="outer outer--content" data-reactid="532"><div class="next-post__content relative z1 fit-x align-c pb12 pt10" data-reactid="533"><h1 class="h6 uppercase kern mb1 mv0 inline-block white" data-reactid="534">Next article</h1><h2 class="h1 mt05 mb0 noe mha white" data-reactid="535">Inherited Learning? It Happens, but How Is Uncertain</h2></div></section><a class="absolute fit-x z10" href="/inherited-learning-it-happens-but-how-is-uncertain-20191016/" data-reactid="536"></a></div></div></div></div><footer class="footer" data-reactid="537"><section class="outer footer__outer" data-reactid="538"><div class="relative z0 fill-v mha container--m" data-reactid="539"><section class="outer footer__section footer__section--top flex flex-column flex-items-center flex-justify-between outer--content" data-reactid="540"><div class="flex flex-justify-center" data-reactid="541"><a href="/" class="footer__logo block" data-reactid="542"><svg x="0px" y="0px" viewBox="0 0 353.5 49.5" enable-background="new 0 0 353.5 49.5" xml:space="preserve" data-reactid="543"><g id="logo" data-reactid="544"><path id="logo__mark" class="black transition--color" fill="currentColor" d="M28.4,5.9c1,0,1.9-0.8,1.9-1.9c0-1-0.8-1.9-1.9-1.9c-1,0-1.9,0.8-1.9,1.9C26.5,5.1,27.3,5.9,28.4,5.9z M28.4,43.6c-1,0-1.9,0.8-1.9,1.9c0,1,0.8,1.9,1.9,1.9c1,0,1.9-0.8,1.9-1.9C30.3,44.5,29.4,43.6,28.4,43.6z M10.9,33.3 c-0.5-0.1-1-0.1-1.4,0.2c-0.4,0.3-0.7,0.7-0.9,1.1c-0.1,0.5-0.1,1,0.2,1.4c0.4,0.6,1,0.9,1.6,0.9c0.3,0,0.6-0.1,0.9-0.3 c0.4-0.3,0.8-0.7,0.9-1.1c0.1-0.5,0.1-1-0.2-1.4C11.8,33.7,11.4,33.4,10.9,33.3z M46.8,12.6c-0.5-0.1-1-0.1-1.4,0.2 c-0.9,0.5-1.2,1.7-0.7,2.6c0.3,0.4,0.7,0.7,1.1,0.9c0.2,0,0.3,0.1,0.5,0.1c0.3,0,0.6-0.1,0.9-0.3c0.4-0.3,0.8-0.7,0.9-1.1 c0.1-0.5,0.1-1-0.2-1.4C47.7,13,47.3,12.7,46.8,12.6z M47.3,33.5c-0.4-0.3-0.9-0.3-1.4-0.2c-0.3,0.1-0.6,0.3-0.8,0.5l-3.4-2 c0.2-0.5,0.2-1,0.1-1.5c-0.2-0.7-0.6-1.2-1.2-1.6c-1.3-0.7-2.9-0.3-3.6,1c-0.4,0.6-0.4,1.3-0.3,2c0,0.1,0,0.1,0.1,0.2l-6.3,3.6 c-0.5-0.6-1.2-0.9-2-0.9c-0.8,0-1.5,0.4-2,0.9l-6.3-3.6c0-0.1,0-0.1,0.1-0.2c0.2-0.7,0.1-1.4-0.3-2c-0.4-0.6-0.9-1-1.6-1.2 c-0.1,0-0.1,0-0.2,0v-7.3c0.1,0,0.1,0,0.2,0c0.7-0.2,1.2-0.6,1.6-1.2c0.4-0.6,0.4-1.3,0.3-2c0-0.1,0-0.1-0.1-0.2l6.3-3.6 c0.5,0.6,1.2,0.9,2,0.9c1.5,0,2.6-1.2,2.6-2.6s-1.2-2.6-2.6-2.6s-2.6,1.2-2.6,2.6c0,0.3,0.1,0.6,0.2,0.9l-6.3,3.6 c-0.2-0.2-0.4-0.4-0.7-0.6c-0.6-0.4-1.3-0.4-2-0.3c-0.7,0.2-1.2,0.6-1.6,1.2c-0.7,1.3-0.3,2.9,1,3.6l0,0c0.3,0.1,0.5,0.2,0.8,0.3 v7.3c-0.3,0.1-0.6,0.1-0.8,0.3c-0.6,0.4-1,0.9-1.2,1.6c-0.2,0.7-0.1,1.4,0.3,2c0.4,0.6,0.9,1,1.6,1.2c0.2,0.1,0.5,0.1,0.7,0.1 c0.5,0,0.9-0.1,1.3-0.4c0.3-0.1,0.5-0.3,0.7-0.6l6.3,3.6c-0.1,0.3-0.2,0.6-0.2,0.9c0,1.5,1.2,2.6,2.6,2.6s2.6-1.2,2.6-2.6 c0-0.3-0.1-0.6-0.2-0.9l6.3-3.6c0.2,0.2,0.4,0.4,0.7,0.6l0,0c0.4,0.2,0.9,0.4,1.3,0.4c0.7,0,1.5-0.3,2-0.9l3.4,2 c-0.1,0.3-0.1,0.6,0,1c0.1,0.5,0.4,0.9,0.9,1.1c0.3,0.2,0.6,0.3,0.9,0.3c0.2,0,0.3,0,0.5-0.1c0.5-0.1,0.9-0.4,1.1-0.9 c0.3-0.4,0.3-0.9,0.2-1.4C48,34.2,47.7,33.7,47.3,33.5z M9.5,16c0.3,0.2,0.6,0.3,0.9,0.3c0.2,0,0.3,0,0.5-0.1 c0.5-0.1,0.9-0.4,1.1-0.9c0.5-0.9,0.2-2.1-0.7-2.6c-0.9-0.5-2.1-0.2-2.6,0.7c-0.3,0.4-0.3,0.9-0.2,1.4C8.7,15.4,9,15.8,9.5,16z M15.7,2.8c0.7-0.4,0.9-1.3,0.5-2c-0.4-0.7-1.3-0.9-2-0.5c-0.7,0.4-0.9,1.3-0.5,2C14.1,2.9,15,3.2,15.7,2.8z M41.1,46.8 c-0.7,0.4-0.9,1.3-0.5,2c0.4,0.7,1.3,0.9,2,0.5c0.7-0.4,0.9-1.3,0.5-2C42.7,46.6,41.8,46.4,41.1,46.8z M15.7,46.8 c-0.7-0.4-1.6-0.2-2,0.5c-0.4,0.7-0.2,1.6,0.5,2c0.7,0.4,1.6,0.2,2-0.5C16.6,48.1,16.4,47.2,15.7,46.8z M41.1,2.8 c0.7,0.4,1.6,0.2,2-0.5c0.4-0.7,0.2-1.6-0.5-2c-0.7-0.4-1.6-0.2-2,0.5C40.1,1.4,40.4,2.3,41.1,2.8z M55.3,23.3 c-0.8,0-1.5,0.7-1.5,1.5c0,0.8,0.7,1.5,1.5,1.5c0.8,0,1.5-0.7,1.5-1.5C56.7,24,56.1,23.3,55.3,23.3z M1.5,23.3C0.7,23.3,0,24,0,24.8 c0,0.8,0.7,1.5,1.5,1.5s1.5-0.7,1.5-1.5C2.9,24,2.3,23.3,1.5,23.3z M39.1,21.2c0.4,0,0.9-0.1,1.3-0.4c1.3-0.7,1.7-2.3,1-3.6 c-0.7-1.3-2.3-1.7-3.6-1l0,0c-0.6,0.4-1,0.9-1.2,1.6c-0.2,0.7-0.1,1.4,0.3,2C37.3,20.7,38.2,21.2,39.1,21.2z" data-reactid="545"></path><path id="logo__quanta" class="black" fill="currentColor" d="M309.9,14c0,1.1-0.9,1.8-2,1.8c-0.9,0-1.8-0.7-1.8-1.8c0-1.2,0.8-2,1.9-2C309.2,12,309.9,12.8,309.9,14z M85.5,28.7c0.6-1.3,0.8-2.6,0.8-4.2c0-2.9-1-5.2-2.9-7.1c-1.9-1.9-4.2-2.8-7-2.8s-5.1,0.9-7,2.8c-1.9,1.9-2.9,4.2-2.9,7.1 c0,2.9,1,5.2,2.9,7.1c1.9,1.9,4.2,2.8,7,2.8c2.7,0,4.9-0.9,6.8-2.6l2.6,1.7l2.2-3.3L85.5,28.7z M82.1,26.5L79.8,25l-2.2,3.3l2.3,1.5 c-1,0.7-2.1,1.1-3.5,1.1c-1.8,0-3.2-0.6-4.3-1.7c-1.1-1.2-1.6-2.7-1.6-4.6c0-1.9,0.5-3.4,1.6-4.6c1.1-1.2,2.5-1.7,4.3-1.7 c1.8,0,3.2,0.6,4.3,1.7c1.1,1.1,1.6,2.7,1.6,4.6C82.3,25.2,82.2,25.9,82.1,26.5z M103.2,27.3c0,1.2-0.3,2.1-0.9,2.8 c-0.6,0.6-1.5,1-2.5,1s-1.9-0.3-2.5-1c-0.6-0.6-0.9-1.6-0.9-2.8v-8.5h-3.9v9c0,2,0.6,3.7,1.7,4.8c1.1,1.2,2.5,1.7,4.3,1.7 c2.2,0,3.6-0.4,4.8-1.7v1.5h3.9V18.9h-3.9V27.3z M144.3,18.9c-2.2,0-3.6,0.4-4.8,1.7v-1.5h-3.9v15.4h3.9V26c0-1.2,0.3-2.1,0.9-2.8 c0.6-0.6,1.5-1,2.5-1c1.1,0,1.9,0.3,2.5,1c0.6,0.6,0.9,1.6,0.9,2.8v8.5h3.9v-9c0-2-0.6-3.7-1.7-4.8C147.4,19.5,146,18.9,144.3,18.9z M124.8,18.9v1.5c-0.8-0.8-2.7-1.7-4.8-1.7c-2.1,0-3.8,0.7-5.2,2.2c-1.4,1.5-2.1,3.4-2.1,5.7c0,2.3,0.7,4.2,2.1,5.7 c1.4,1.5,3.1,2.2,5.2,2.2c1.3,0,3-0.2,4.8-1.6v1.4h3.9V18.9H124.8z M123.6,29.9c-0.8,0.8-1.8,1.2-2.8,1.2c-1.1,0-2-0.4-2.8-1.2 c-0.8-0.8-1.2-1.9-1.2-3.3c0-1.4,0.4-2.5,1.2-3.3c0.8-0.8,1.8-1.2,2.8-1.2c1.1,0,2,0.4,2.9,1.2c0.8,0.8,1.2,1.9,1.2,3.3 C124.8,28,124.4,29.1,123.6,29.9z M180.1,18.9v1.5c-0.8-0.8-2.7-1.7-4.8-1.7c-2.1,0-3.8,0.7-5.2,2.2c-1.4,1.5-2.1,3.4-2.1,5.7 c0,2.3,0.7,4.2,2.1,5.7c1.4,1.5,3.1,2.2,5.2,2.2c1.3,0,3-0.2,4.8-1.6v1.4h3.9V18.9H180.1z M178.9,29.9c-0.8,0.8-1.8,1.2-2.8,1.2 c-1.1,0-2-0.4-2.8-1.2c-0.8-0.8-1.2-1.9-1.2-3.3c0-1.4,0.4-2.5,1.2-3.3C174,22.4,175,22,176,22c1.1,0,2,0.4,2.9,1.2 c0.8,0.8,1.2,1.9,1.2,3.3C180.1,28,179.7,29.1,178.9,29.9z M161.4,31c-1.1,0-1.9-0.7-1.9-2.1v-6.4h4.1v-3.2h-4.1v-4h-3.7v4v3.2v6.4 c0,3.7,2.1,5.5,5.3,5.4c1.1,0,2-0.2,3-0.6l-1-3.1C162.6,30.9,161.9,31,161.4,31z" data-reactid="546"></path><path id="logo__magazine" class="gray3" fill="currentColor" d="M218.3,33.5l-0.1,1c-1.1,0-2.4-0.1-3.9-0.1c-1.5,0-2.7,0.1-3.6,0.1v-1c1.6-0.1,2-0.3,2-0.9 c0.1-0.8,0.1-2.4,0.1-5.1c0-4.4,0-4.9-0.3-5.4c-0.4-0.9-1.2-1.4-2.4-1.4c-1.6,0-3,1-3.7,2.3c-0.2,0.5-0.4,0.9-0.4,1.5v4.7 c0,1.3,0,2.6,0.1,3.4c0,0.7,0.4,0.9,2.2,0.9l-0.1,1c-0.9,0-2.5-0.1-3.9-0.1c-1.4,0-2.6,0.1-3.5,0.1v-1c1.6-0.1,2-0.2,2-1 c0.1-1.1,0.1-2.2,0.1-4.4v-2.8c0-2.4,0-2.8-0.2-3.3c-0.4-0.9-1.1-1.3-2.3-1.3c-1.5,0-3,0.9-3.8,2.4c-0.3,0.6-0.4,0.9-0.4,1.7v4.6 c0,1.4,0,2.5,0.1,3.3c0.1,0.7,0.4,0.8,2.1,0.9l-0.1,0.9c-0.8,0-2.5-0.1-3.8-0.1c-1.3,0-2.6,0.1-3.7,0.1v-1c1.8,0,2.1-0.2,2.1-1 c0-0.9,0.1-2.3,0.1-4.2v-2.9c0-1.9,0-3.4-0.1-4.3c0-0.5-0.3-0.6-2.2-0.6l0.1-0.9c1.7,0,3.6-0.2,5.2-0.5c0.1,0.6,0.2,2.2,0.2,2.7 c1.3-1.3,3.2-2.9,5.7-2.9c2,0,2.9,0.8,3.4,1.5c0.3,0.4,0.5,0.9,0.6,1.3c1.2-1.2,3-2.8,5.7-2.8c2.1,0,3.3,1.1,3.8,2 c0.4,0.7,0.5,1.5,0.5,2.3v9.4C216,33.3,216.2,33.4,218.3,33.5z M238.4,31l0.9,0.4c-0.5,2.5-1.9,3.4-3.5,3.4c-1.8,0-2.5-1.1-2.7-2.6 c-1.5,1.7-3.4,2.6-5,2.6c-2.7,0-4.3-1.9-4.3-4.3c0-1.4,0.6-2.6,2-3.2c2.4-1,6-2.1,7.4-3.1v-1.4c0-1.5-0.7-3-2.7-3 c-2.1,0-3,1.1-3,2.5c0,0.4,0.1,0.8,0.1,1.1c0.1,0.3-0.1,0.6-0.3,0.7c-0.3,0.2-0.7,0.4-1.2,0.4c-0.8,0-1.5-0.4-1.5-1.6 c0-1.8,2.6-4.1,6.4-4.1c3,0,4.3,1.3,4.7,2c0.3,0.5,0.5,1.2,0.5,1.8v8.9c0,1.3,0.4,1.5,0.8,1.5C237.5,33.1,238,32.4,238.4,31z M233,25.3c-1,0.5-2.8,1.3-4.1,2c-1.1,0.6-1.8,1.1-1.8,2.7c0,1.7,0.9,3,2.5,3c1.7,0,2.7-1,3.3-2.3c0.1-0.4,0.2-1,0.2-1.5V25.3z M255.8,27.1c-1.3,0-2.8-0.1-3.7-0.1l0,0.9l1.5,0.1c1.2,0.1,1.4,0.3,1.4,1.3c0,1,0,2.4-0.1,3.2c-0.1,0.8-1.1,1.3-2.5,1.3 c-1.5,0-2.8-0.5-3.8-1.8c-0.9-1.1-1.3-3.1-1.3-5.1c0-2.2,0.5-3.9,1.4-5.1c0.8-1.2,2-1.8,3.5-1.8c2.6,0,4.1,1.7,4.4,5l0.9,0 c-0.1-2.1,0.2-4.8,0.4-5.7l-0.8-0.3l-0.5,1.3c-0.5-0.5-1.8-1.4-4.3-1.4c-1.6,0-3,0.3-4.2,1c-2.4,1.3-3.8,3.9-3.8,7 c0,2.4,0.6,4.2,1.7,5.5c1.2,1.5,3.2,2.3,6.1,2.3c1.2,0,2.5-0.3,3.6-0.6c1-0.3,1.8-0.6,2.4-0.7c-0.1-0.5-0.2-1.3-0.2-2.5 c0-0.7,0-1.7,0.1-2.3c0-0.5,0.3-0.6,1.5-0.8l0-0.9C258.4,27.1,257.1,27.1,255.8,27.1z M279.4,31l0.9,0.4c-0.5,2.5-1.9,3.4-3.5,3.4 c-1.8,0-2.5-1.1-2.7-2.6c-1.5,1.7-3.4,2.6-5,2.6c-2.7,0-4.3-1.9-4.3-4.3c0-1.4,0.6-2.6,2-3.2c2.4-1,6-2.1,7.4-3.1v-1.4 c0-1.5-0.7-3-2.7-3c-2.1,0-3,1.1-3,2.5c0,0.4,0.1,0.8,0.1,1.1c0.1,0.3-0.1,0.6-0.3,0.7c-0.3,0.2-0.7,0.4-1.2,0.4 c-0.8,0-1.5-0.4-1.5-1.6c0-1.8,2.6-4.1,6.4-4.1c3,0,4.3,1.3,4.7,2c0.3,0.5,0.5,1.2,0.5,1.8v8.9c0,1.3,0.4,1.5,0.8,1.5 C278.5,33.1,279,32.4,279.4,31z M274,25.3c-1,0.5-2.8,1.3-4.1,2c-1.1,0.6-1.8,1.1-1.8,2.7c0,1.7,0.9,3,2.5,3c1.7,0,2.7-1,3.3-2.3 c0.1-0.4,0.2-1,0.2-1.5V25.3z M295.1,33c-1,0.2-2.8,0.3-5.6,0.3c1.8-2.8,7.1-10.8,7.9-12c0.4-0.7,0.8-1.4,0.9-2.1 c-1.4,0-2.6,0.1-5.3,0.1h-3c-2,0-3.2-0.1-3.8-0.4c0,2.1-0.2,4.4-0.4,5.8l0.9-0.2c0.2-0.8,0.4-1.7,0.7-2.6c0.4-1.1,0.9-1.4,2.4-1.5 c1.4-0.1,2.9-0.1,4.4-0.1c-0.9,1.8-5.2,8.8-9,13.4l0.4,0.7c0.6,0,1.7-0.1,3.7-0.1c3.8,0,7.8,0.1,9.1,0.2c0.1-1.6,0.4-4.3,0.6-5.8 l-0.9-0.2C297.3,32,296.5,32.9,295.1,33z M309.9,32.5c0-0.7-0.1-1.9-0.1-4.1v-4.1c0-2.6,0.1-4.6,0.1-5.4c-1.6,0.4-3.9,0.5-5.6,0.6 l0,0.9c1.9-0.1,2.2,0,2.2,0.5c0,0.5,0.1,1.7,0.1,3.6v3.9c0,2-0.1,3.5-0.1,4.1c0,0.6-0.3,0.9-2.4,1l0,1c1.1,0,2.1-0.1,3.8-0.1 c1.7,0,3,0.1,4,0.1l0-1C310.3,33.4,309.9,33.3,309.9,32.5z M332.9,32.5v-9.3c0-0.8-0.1-1.6-0.5-2.2c-0.5-1.1-1.7-2.1-4-2.1 c-2.5,0-4.2,1.5-5.5,2.7c0-0.5-0.1-1.9-0.2-2.6c-1.6,0.3-3.4,0.5-5.1,0.5l-0.1,0.9c1.8,0,2.1,0.1,2.1,0.6c0.1,0.9,0.1,2.4,0.1,4.3 v3.1c0,1.7-0.1,3-0.1,4c0,0.8-0.3,0.9-2.1,1v1c1,0,2.2-0.1,3.7-0.1c1.3,0,3,0.1,3.9,0.1l0.1-1c-1.8-0.1-2.1-0.2-2.1-0.9 c-0.1-0.8-0.1-2.2-0.1-3.7v-4.1c0-0.8,0.1-1.3,0.4-1.8c0.8-1.4,2.1-2.2,3.8-2.2c1.2,0,1.9,0.5,2.4,1.3c0.3,0.6,0.4,1,0.4,5.4 c0,2.8-0.1,4.4-0.1,5.1c-0.1,0.7-0.4,0.8-2,0.9l0,1c0.8,0,2-0.1,3.6-0.1c1.5,0,2.8,0.1,3.9,0.1l0.1-1 C333.1,33.4,332.9,33.3,332.9,32.5z M352.5,29.8l0.9,0.5c-1.1,3.2-3.3,4.5-6.3,4.5c-2.7,0-4.4-0.8-5.6-2.4c-0.9-1.2-1.5-3.2-1.5-5.3 c0-4.4,2.5-8.3,7.4-8.3c5.1,0,6,4,6,6.1c0,0.7-0.2,1.2-0.7,1.4c-0.6,0.2-2.3,0.4-4.6,0.5c-1.2,0-3.1,0-4.6,0 c-0.1,1.9,0.4,3.6,1.1,4.6c0.8,1.2,1.9,1.8,3.5,1.8C350.3,33.2,351.6,32.2,352.5,29.8z M343.6,25.7h2.9c1.7,0,2.6-0.1,3.1-0.2 c0.5-0.1,0.7-0.5,0.7-1.2c0-1.9-0.8-4.4-3.1-4.4C344.8,19.9,343.7,22.8,343.6,25.7z" data-reactid="547"></path></g></svg></a></div><div class="footer__social flex flex-justify-center scale0" data-reactid="548"><div class="social-links flex flex-justify-between flex-items-center social-links--footer" data-reactid="549"><a href="https://www.facebook.com/QuantaNews" target="_blank" class="social-links__link flex flex-items-center relative mh05 theme__accent theme__text-hover transition--color" data-reactid="550"><div class="icon-button inline-block relative pointer _hover_div-c-1a1a1a _hover_div-opacity-1 _hover_svg-c-1a1a1a" data-reactid="551"><div class="absolute fit-x mxa c-ff8600" data-reactid="552"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="553"><path fill="currentColor" d="M13 16.5h5.1v-5c-.2-2.7.3-5.4 1.7-7.7 1.8-2.5 4.9-4 8-3.8 3.1-.1 6.2.2 9.2 1l-1.3 7.7C34.4 8.3 33 8 31.6 8c-2 0-3.8.7-3.8 2.7v5.9H36l-.6 7.5h-7.6V50h-9.6V23.9H13v-7.4z" data-reactid="554"></path></svg></div></a><a href="https://twitter.com/QuantaMagazine" target="_blank" class="social-links__link flex flex-items-center relative mh05 theme__accent theme__text-hover transition--color" data-reactid="555"><div class="icon-button inline-block relative pointer _hover_div-c-1a1a1a _hover_div-opacity-1 _hover_svg-c-1a1a1a" data-reactid="556"><div class="absolute fit-x mxa c-ff8600" data-reactid="557"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="558"><path fill="currentColor" d="M50 9.9c-1.9.8-3.8 1.3-5.9 1.6 2.1-1.3 3.7-3.2 4.5-5.6-2 1.2-4.2 2-6.5 2.5-3.8-4.1-10.3-4.5-14.5-.8-2.8 2.5-4 6.3-3.1 10-8.2-.5-15.8-4.3-21-10.6-2.7 4.6-1.3 10.5 3.2 13.5C5 20.4 3.4 20 2 19.2c0 4.8 3.4 8.9 8.2 9.9-.9.2-1.8.4-2.7.3-.6 0-1.3-.1-1.9-.2 1.3 4.1 5.2 6.9 9.5 7C10.8 39.5 5.4 41 0 40.4c13.5 8.5 31.5 4.6 40.2-8.7 3-4.6 4.6-10 4.6-15.5v-1.3c2-1.3 3.7-3.1 5.2-5" data-reactid="559"></path></svg></div></a><a href="http://youtube.com/c/QuantamagazineOrgNews" target="_blank" class="social-links__link flex flex-items-center relative mh05 theme__accent theme__text-hover transition--color" data-reactid="560"><div class="icon-button inline-block relative pointer _hover_div-c-1a1a1a _hover_div-opacity-1 _hover_svg-c-1a1a1a" data-reactid="561"><div class="absolute fit-x mxa c-ff8600" data-reactid="562"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="563"><path fill="currentColor" d="M18.7 33.7V16.1l15.7 8.8-15.7 8.8zM43.3 8.2c-12.2-.9-24.4-.9-36.6 0-1.8.2-3.4 1.2-4.3 2.8C1.3 12.5.6 14.3.3 16.2c-.5 5.9-.5 11.8 0 17.7.2 1.9.9 3.7 2.1 5.2 1 1.5 2.5 2.6 4.3 2.9 12.2.8 24.4.8 36.6 0 1.8-.4 3.3-1.5 4.3-3 1.1-1.5 1.8-3.3 2.1-5.1.5-6 .5-12.1 0-18.1-.2-1.8-.8-3.6-1.9-5.1-1-1.6-2.7-2.5-4.5-2.5z" data-reactid="564"></path></svg></div></a><a href="https://instagram.com/quantamag" target="_blank" class="social-links__link flex flex-items-center relative mh05 theme__accent theme__text-hover transition--color" data-reactid="565"><div class="icon-button inline-block relative pointer _hover_div-c-1a1a1a _hover_div-opacity-1 _hover_svg-c-1a1a1a" data-reactid="566"><div class="absolute fit-x mxa c-ff8600" data-reactid="567"></div><svg class="absolute fit-x mxa c-1a1a1a" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="568"><path fill="currentColor" d="M33.4 0H16.6C7.5 0 0 7.5 0 16.6v16.8C0 42.5 7.5 50 16.6 50h16.8C42.5 50 50 42.5 50 33.4V16.6C50 7.5 42.5 0 33.4 0zM25 36.6c-6.4 0-11.6-5.2-11.6-11.6S18.6 13.4 25 13.4 36.6 18.6 36.6 25 31.4 36.6 25 36.6zm15.1-23.2c-1.8 0-3.2-1.4-3.2-3.2S38.3 7 40.1 7s3.2 1.4 3.2 3.2c0 1.7-1.5 3.2-3.2 3.2z" data-reactid="569"></path></svg></div></a></div></div></section><hr class="footer__section-divider hide gray2" data-reactid="570"/><section class="outer footer__section footer__section--bottom flex flex-wrap flex-justify-center flex-items-center pv2 outer--content" data-reactid="571"><nav class="footer__nav fill-h pb1" data-reactid="572"><ul class="footer__list flex flex-column flex-items-center flex-justify-center gray3" data-reactid="573"><li class="footer__list-item mb1" data-reactid="574"><a class="footer__link h5 pangram gray3 flex flex-items-center relative mh05 ph025 light" href="/about/" data-reactid="575"><span data-reactid="576">About Quanta</span></a></li><li class="footer__list-item mb1" data-reactid="577"><a href="/archive" target="_blank" class="footer__link h5 pangram gray3 flex flex-items-center relative mh05 ph025 light" data-reactid="578"><span data-reactid="579">Archive</span></a></li><li class="footer__list-item mb1" data-reactid="580"><a class="footer__link h5 pangram gray3 flex flex-items-center relative mh05 ph025 light" href="/contact-us/" data-reactid="581"><span data-reactid="582">Contact Us</span></a></li><li class="footer__list-item mb1" data-reactid="583"><a class="footer__link h5 pangram gray3 flex flex-items-center relative mh05 ph025 light" href="/terms-conditions/" data-reactid="584"><span data-reactid="585">Terms &#038; Conditions</span></a></li><li class="footer__list-item mb1" data-reactid="586"><a class="footer__link h5 pangram gray3 flex flex-items-center relative mh05 ph025 light" href="/privacy-policy/" data-reactid="587"><span data-reactid="588">Privacy Policy</span></a></li><li class="footer__list-item mb1" data-reactid="589"><a href="http://www.simonsfoundation.org" target="_blank" class="footer__link h5 pangram gray3 flex flex-items-center relative mh05 ph025 light" data-reactid="590"><span data-reactid="591">Simons Foundation</span></a></li></ul></nav><div class="footer__copyright flex-shrink h5 pangram gray3 light" data-reactid="592"><small data-reactid="593"><!-- react-text: 594 -->All Rights Reserved © <!-- /react-text --><!-- react-text: 595 -->2019<!-- /react-text --></small></div><div class="footer__credits flex-shrink flex-justify-right o6" data-reactid="596"><a href="http://www.dogstudio.be/" target="_blank" title="Designed by Dogstudio" data-reactid="597"><svg class="icon-l" viewBox="0 0 50 50" enable-background="new 0 0 50 50" data-reactid="598"><path fill="currentColor" d="M15.7,29.7c1.2,0,2.4-0.1,3.6-0.4c0,3.9,0.5,8,1.4,10.7v0.2h0.2c0.2,0,0.2-0.1,0.3-0.5c0.1-0.2,0.1-0.5,0.2-0.7 c3.3-8.7,9.6-12.7,14.4-14.4l0,0l0.8-0.3c2.3-0.8,3.9-0.9,3.9-0.9l0.3,0L40.7,23c0,0-1.9-2.4-4.2-6c-0.6-0.9-1.5-1.8-2.6-2.5 c0.2-1.2,0.3-2.3,0.3-3.5c0-1.7-0.2-3.4-0.7-5l-0.4-1.6l-0.7,1.5c0,0-0.8,1.6-2.3,3.5c0.1-0.3,0.2-0.5,0.3-0.6l0.8-1.8l-1.6,1 c-5.2,3.2-9.3,9.1-10.1,10.2c-0.6,0.8-1.2,1.6-1.7,2.3c-1.2,1.7-2.4,3.4-4.3,5c-1.3,1.1-2.7,2-3.1,2.3l-1,0.7l1.2,0.4 C10.7,29,12.7,29.7,15.7,29.7z M21.1,36.5c-0.4-2.3-0.6-4.9-0.6-7.5c1.4-0.4,2.7-0.9,4-1.6c0.2-0.1,2.3-1.2,4.3-3.2 c0.4,0.6,0.7,1.3,0.9,2.1C26,29,23.1,32.4,21.1,36.5z M24.4,21.4c0.8,0.1,1.3,0.3,2.1,0.7c0.6,0.3,1.1,0.7,1.5,1.2 c-1.9,1.9-4,3-4.1,3.1c-1.1,0.6-2.2,1-3.4,1.4c0.1-1.7,0.2-2.9,0.5-4.4C21.9,23.2,23.4,22.5,24.4,21.4z M21.4,22.1c0,0,0-0.1,0-0.1 c0-0.2,0.1-0.4,0.1-0.5c0.2,0,0.6-0.1,1.1-0.1C22.2,21.6,21.7,21.9,21.4,22.1z M32.8,8c0.2,1,0.3,2.1,0.3,3.1c0,1-0.1,1.9-0.2,2.9 c-1.2-0.5-2.4-0.8-3.7-0.8c-0.4,0-0.7,0-1.1,0.1C30.4,11.4,31.9,9.3,32.8,8z M28.5,10.3c-0.2,0.4-0.4,1-0.5,1.5 c-0.7,0.7-1.5,1.3-2.3,1.7c-0.5,0.2-1,0.4-1.4,0.7C25.8,12.6,27.2,11.3,28.5,10.3z M25.7,15.3c1.1-0.6,2.2-0.8,3.4-0.8 c2.8,0,5.3,1.6,6.3,3.2c1.3,2.1,2.4,3.7,3.2,4.7c-0.7,0.2-1.5,0.4-2.2,0.6c-1.7-3.8-4.6-5.3-6.7-5.8c-1-0.3-1.9-0.4-2.8-0.4 c-1.5,0-2.8,0.3-3.8,0.7C23.9,16.6,24.7,15.8,25.7,15.3z M22.2,19.4c1.4-1.1,4.4-1.8,7.3-1c1.8,0.5,4.3,1.8,5.8,5.1 c-1.6,0.6-3.2,1.4-4.6,2.3c-0.7-2.2-1.9-3.7-3.6-4.7c-1.4-0.8-2.9-1-4-1c-0.5,0-0.9,0-1.2,0.1C22,19.9,22.1,19.6,22.2,19.4z M18.8,21.3c0.5-0.7,1.6-2.2,1.6-2.2l0.1-0.1c0.4-0.5,0.8-1,1.2-1.4c-0.7,1.2-1.2,2.7-1.6,4.5c-0.4,1.8-0.7,3.8-0.7,5.9 c-0.8,0.2-1.6,0.3-2.4,0.3c-0.1-0.4-0.3-0.7-0.5-1c-0.4-0.6-0.9-1-1.5-1.4C16.6,24.4,17.8,22.8,18.8,21.3z M13.9,26.8 c0.6,0.3,1.1,0.7,1.5,1.2c0.1,0.1,0.2,0.2,0.2,0.4c-1.4,0-2.6-0.2-3.4-0.3C12.7,27.8,13.3,27.3,13.9,26.8z M5.4,1.4l0,33.1 l19.7,14.9l0.1,0.1l19.8-15V1.4H5.4z M43.7,33.8l-18.5,14l-18.5-14l0-31h36.9V33.8z" data-reactid="599"></path></svg></a></div></section></div></section></footer></div></div><script type="text/javascript" data-reactid="6">window.__APOLLO_STATE__ = {"$ROOT_QUERY.getCurrentUser":{"savedArticleIDs":{"type":"json","json":[]},"loggedIn":false,"editor":null,"userEmail":null,"__typename":"CurrentUser"},"ROOT_QUERY":{"getCurrentUser":{"type":"id","generated":true,"id":"$ROOT_QUERY.getCurrentUser","typename":"CurrentUser"},"options":{"type":"id","generated":true,"id":"$ROOT_QUERY.options","typename":"Options"},"getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\",\"type\":\"\"})":{"type":"id","generated":true,"id":"$ROOT_QUERY.getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\",\"type\":\"\"})","typename":"PostPageArchive"},"getPageMeta({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\",\"type\":\"\"})":{"type":"id","generated":true,"id":"$ROOT_QUERY.getPageMeta({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\",\"type\":\"\"})","typename":"PageMeta"},"menu({\"slug\":\"main-menu\"})":{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"main-menu\"})","typename":"Menu"},"menu({\"slug\":\"secondary-menu\"})":{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"})","typename":"Menu"},"menu({\"slug\":\"footer\"})":{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"footer\"})","typename":"Menu"},"getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\"})":{"type":"id","generated":true,"id":"$ROOT_QUERY.getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\"})","typename":"PostPageArchive"}},"$ROOT_QUERY.options.acf.featured_image":{"alt":"","caption":"","url":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default.gif","width":1200,"height":600,"sizes":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.featured_image.sizes","typename":"ImageSizes"},"__typename":"Image"},"$ROOT_QUERY.options.acf.featured_image.sizes":{"thumbnail":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default-520x260.gif","square_small":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default-160x160.gif","square_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default-520x520.gif","medium":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default.gif","medium_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default-768x384.gif","large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default.gif","__typename":"ImageSizes"},"$ROOT_QUERY.options.acf":{"featured_image":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.featured_image","typename":"Image"},"__typename":"ThemeOptions","ad_behavior":"everywhere","ad_url":"https://www.quantamagazine.org/gift-store","ad_image_alt":"Alice and Bob Meet the Wall of Fire - The Biggest Ideas in Science from Quanta – Available now!","ad_homepage_image":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Default_250x342_2x_Science.jpg","ad_tablet_image":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Tablet_890x250_2x_Science.jpg","ad_mobile_image":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Mobile_250x200_2x_Science.jpg","ad_article_side_image":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Article_320x600_Science.jpg","newsletter_signup_action_url":"https://quantamagazine.us1.list-manage.com/subscribe/post?u=0d6ddf7dc1a0b7297c8e06618&id=f0cb61321c","newsletter_most_recent_url":"http://us1.campaign-archive2.com/home/?u=0d6ddf7dc1a0b7297c8e06618&id=f0cb61321c","social_media_links":[{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.social_media_links.0","typename":"SocialMediaLink"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.social_media_links.1","typename":"SocialMediaLink"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.social_media_links.2","typename":"SocialMediaLink"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.social_media_links.3","typename":"SocialMediaLink"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.social_media_links.4","typename":"SocialMediaLink"}],"comments_header":"\u003cp class=\"byline\">\u003csmall>\u003cem>Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. \u003c/em>\u003c/small>\u003c/p>\n","itunes_subscribe_link":"https://itunes.apple.com/us/podcast/quanta-science-podcast/id1021340531?mt=2&ls=1","android_subscribe_link":"https://subscribeonandroid.com/www.quantamagazine.org/feed/podcast/","tracking_scripts":"\u003c\!-- Facebook Pixel Code -->\r\n\u003cscript>\r\n!function(f,b,e,v,n,t,s)\r\n{if(f.fbq)return;n=f.fbq=function()\r\n{n.callMethod? n.callMethod.apply(n,arguments):n.queue.push(arguments)}\r\n;\r\nif(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';\r\nn.queue=[];t=b.createElement(e);t.async=!0;\r\nt.src=v;s=b.getElementsByTagName(e)[0];\r\ns.parentNode.insertBefore(t,s)}(window,document,'script',\r\n'https://connect.facebook.net/en_US/fbevents.js');\r\nfbq('init', '190747804793608'); \r\nfbq('track', 'PageView');\r\n\u003c\/script>\r\n\u003cnoscript>\r\n\u003cimg height=\"1\" width=\"1\" \r\nsrc=\"https://www.facebook.com/tr?id=190747804793608&ev=PageView\r\n&noscript=1\"/>\r\n\u003c/noscript>\r\n\u003c\!-- End Facebook Pixel Code -->\r\n\r\n\u003c\!-- Chartbeat -->\u003cscript type=\"text/javascript\">var _sf_async_config = { uid: 65564, domain: 'quantamagazine.org', useCanonical: true };(function() {function loadChartbeat(){ window._sf_endpt = (new Date()).getTime(); var e = document.createElement('script'); e.setAttribute('language', 'javascript'); e.setAttribute('type', 'text/javascript'); e.setAttribute('src','//static.chartbeat.com/js/chartbeat.js'); document.body.appendChild(e); };var oldonload = window.onload;window.onload = (typeof window.onload != 'function') ?loadChartbeat : function(){ oldonload(); loadChartbeat(); };})();\u003c\/script>\u003c\!-- End Chartbeat -->\r\n\r\n\u003c\!--Parsely-->\u003cscript id=\"parsely-cfg\" src=\"//cdn.parsely.com/keys/quantamagazine.org/p.js\">\u003c\/script>","google_analytics":"","popular_searches":[{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.popular_searches.0","typename":"PopularSearch"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.popular_searches.1","typename":"PopularSearch"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.popular_searches.2","typename":"PopularSearch"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.popular_searches.3","typename":"PopularSearch"}],"search_topics":[{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.0","typename":"SearchTopic"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.1","typename":"SearchTopic"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.2","typename":"SearchTopic"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.3","typename":"SearchTopic"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.4","typename":"SearchTopic"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.5","typename":"SearchTopic"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.6","typename":"SearchTopic"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.7","typename":"SearchTopic"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.8","typename":"SearchTopic"}],"search_sections":[{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_sections.0","typename":"Term"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_sections.1","typename":"Term"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_sections.2","typename":"Term"},{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_sections.3","typename":"Term"}]},"$ROOT_QUERY.options":{"acf":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf","typename":"ThemeOptions"},"__typename":"Options"},"$ROOT_QUERY.getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\",\"type\":\"\"}).data.0.acf":{"custom_page_colors":"","page_accent_color":null,"page_text_color":null,"page_background_color":null,"header_type":"default","header_gradient_color":null,"header_gradient_opacity":null,"header_solid_colors":"","header_solid_primary_color":null,"header_solid_secondary_color":null,"header_solid_hover_color":null,"header_transparent_colors":null,"header_transparent_primary_color":null,"header_transparent_secondary_color":null,"header_transparent_hover_color":null,"__typename":"ACFFields"},"$ROOT_QUERY.getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\",\"type\":\"\"}).data.0":{"acf":{"type":"id","generated":true,"id":"$ROOT_QUERY.getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\",\"type\":\"\"}).data.0.acf","typename":"ACFFields"},"__typename":"Post"},"$ROOT_QUERY.getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\",\"type\":\"\"})":{"data":[{"type":"id","generated":true,"id":"$ROOT_QUERY.getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\",\"type\":\"\"}).data.0","typename":"Post"}],"__typename":"PostPageArchive"},"$ROOT_QUERY.getPageMeta({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\",\"type\":\"\"})":{"redirect_path":null,"meta":"\n\u003c\!-- All in One SEO Pack 2.3.11.4 by Michael Torbert of Semper Fi Web Designob_start_detected [-1,-1] -->\n\u003cmeta name=\"description\"  content=\"A tool known as BERT can now beat humans on advanced reading-comprehension tests. But it's also revealed how far AI has to go.\" />\n\n\u003cmeta name=\"keywords\"  content=\"computer science,artificial intelligence,neural networks,machine learning,natural language processing,bert,nlp\" />\n\n\u003clink rel=\"canonical\" href=\"https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/\" />\n\u003cmeta property=\"og:title\" content=\"Machines Beat Humans on a Reading Test. But Do They Understand? | Quanta Magazine\" />\n\u003cmeta property=\"og:type\" content=\"article\" />\n\u003cmeta property=\"og:url\" content=\"https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/\" />\n\u003cmeta property=\"og:image\" content=\"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_1200_Social.jpg\" />\n\u003cmeta property=\"og:image:width\" content=\"1200\" />\n\u003cmeta property=\"og:image:height\" content=\"630\" />\n\u003cmeta property=\"og:site_name\" content=\"Quanta Magazine\" />\n\u003cmeta property=\"fb:app_id\" content=\"533309373681765\" />\n\u003cmeta name=\"twitter:card\" content=\"summary_large_image\" />\n\u003cmeta name=\"twitter:site\" content=\"@QuantaMagazine\" />\n\u003cmeta name=\"twitter:domain\" content=\"quantamagazine.org\" />\n\u003cmeta name=\"twitter:title\" content=\"Machines Beat Humans on a Reading Test. But Do They Understand? | Quanta Magazine\" />\n\u003cmeta name=\"twitter:image\" content=\"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_1200_Social.jpg\" />\n\u003cmeta itemprop=\"image\" content=\"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_1200_Social.jpg\" />\n\t\t\t\u003cscript>\n\t\t\t(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t\t\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\t\t\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n\t\t\t})(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n\n\t\t\tga('create', 'UA-8526335-13', 'auto');\n\t\t\tga('require', 'displayfeatures');\n\t\t\tga('send', 'pageview');\n\t\t\t\u003c\/script>\n\u003c\!-- /all in one seo pack -->\n\u003cmeta name=\"twitter:description\" content=\"A tool known as BERT can now beat humans on advanced reading-comprehension tests. But it&#039;s also revealed how far AI has to go.\" />","__typename":"PageMeta"},"$ROOT_QUERY.options.acf.social_media_links.0":{"type":"facebook","label":"Facebook","url":"https://www.facebook.com/QuantaNews","__typename":"SocialMediaLink"},"$ROOT_QUERY.options.acf.social_media_links.1":{"type":"twitter","label":"Twitter","url":"https://twitter.com/QuantaMagazine","__typename":"SocialMediaLink"},"$ROOT_QUERY.options.acf.social_media_links.2":{"type":"youtube","label":"YouTube","url":"http://youtube.com/c/QuantamagazineOrgNews","__typename":"SocialMediaLink"},"$ROOT_QUERY.options.acf.social_media_links.3":{"type":"rss","label":"RSS","url":"https://api.quantamagazine.org/feed/","__typename":"SocialMediaLink"},"$ROOT_QUERY.options.acf.social_media_links.4":{"type":"instagram","label":"Instagram","url":"https://instagram.com/quantamag","__typename":"SocialMediaLink"},"$ROOT_QUERY.options.acf.popular_searches.0":{"term":"math","label":"Mathematics","__typename":"PopularSearch"},"$ROOT_QUERY.options.acf.popular_searches.1":{"term":"physics","label":"Physics","__typename":"PopularSearch"},"$ROOT_QUERY.options.acf.popular_searches.2":{"term":"black holes","label":"Black Holes","__typename":"PopularSearch"},"$ROOT_QUERY.options.acf.popular_searches.3":{"term":"evolution","label":"Evolution","__typename":"PopularSearch"},"$ROOT_QUERY.options.acf.search_topics.0":{"type":"Tag","label":"Podcasts","tag":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.0.tag","typename":"Term"},"category":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.0.category","typename":"Term"},"__typename":"SearchTopic"},"$ROOT_QUERY.options.acf.search_topics.0.tag":{"name":"podcast","slug":"podcast","term_id":"552","__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.0.category":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.1":{"type":"Tag","label":"Columns","tag":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.1.tag","typename":"Term"},"category":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.1.category","typename":"Term"},"__typename":"SearchTopic"},"$ROOT_QUERY.options.acf.search_topics.1.tag":{"name":"Quantized Columns","slug":"quantized","term_id":"551","__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.1.category":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.2":{"type":"Series","label":"Series","tag":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.2.tag","typename":"Term"},"category":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.2.category","typename":"Term"},"__typename":"SearchTopic"},"$ROOT_QUERY.options.acf.search_topics.2.tag":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.2.category":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.3":{"type":"Category","label":"Interviews","tag":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.3.tag","typename":"Term"},"category":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.3.category","typename":"Term"},"__typename":"SearchTopic"},"$ROOT_QUERY.options.acf.search_topics.3.tag":{"name":"Q&amp;A","slug":"qa","term_id":"567","__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.3.category":{"name":"Q&amp;A","slug":"qa","term_id":"176","__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.4":{"type":"Category","label":"Multimedia","tag":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.4.tag","typename":"Term"},"category":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.4.category","typename":"Term"},"__typename":"SearchTopic"},"$ROOT_QUERY.options.acf.search_topics.4.tag":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.4.category":{"name":"Multimedia","slug":"multimedia","term_id":"43","__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.5":{"type":"Category","label":"Puzzles","tag":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.5.tag","typename":"Term"},"category":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.5.category","typename":"Term"},"__typename":"SearchTopic"},"$ROOT_QUERY.options.acf.search_topics.5.tag":{"name":"puzzles","slug":"puzzles","term_id":"542","__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.5.category":{"name":"Puzzles","slug":"puzzles","term_id":"546","__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.6":{"type":"Category","label":"Blog Posts","tag":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.6.tag","typename":"Term"},"category":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.6.category","typename":"Term"},"__typename":"SearchTopic"},"$ROOT_QUERY.options.acf.search_topics.6.tag":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.6.category":{"name":"Abstractions blog","slug":"abstractions","term_id":"619","__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.7":{"type":"news","label":"News Articles","tag":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.7.tag","typename":"Term"},"category":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.7.category","typename":"Term"},"__typename":"SearchTopic"},"$ROOT_QUERY.options.acf.search_topics.7.tag":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.7.category":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.8":{"type":"videos","label":"Videos","tag":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.8.tag","typename":"Term"},"category":{"type":"id","generated":true,"id":"$ROOT_QUERY.options.acf.search_topics.8.category","typename":"Term"},"__typename":"SearchTopic"},"$ROOT_QUERY.options.acf.search_topics.8.tag":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"$ROOT_QUERY.options.acf.search_topics.8.category":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"$ROOT_QUERY.options.acf.search_sections.0":{"name":"Mathematics","slug":"mathematics","term_id":"188","__typename":"Term"},"$ROOT_QUERY.options.acf.search_sections.1":{"name":"Physics","slug":"physics","term_id":"189","__typename":"Term"},"$ROOT_QUERY.options.acf.search_sections.2":{"name":"Biology","slug":"biology","term_id":"191","__typename":"Term"},"$ROOT_QUERY.options.acf.search_sections.3":{"name":"Computer Science","slug":"computer-science","term_id":"190","__typename":"Term"},"$ROOT_QUERY.menu({\"slug\":\"main-menu\"}).items.0":{"title":"Physics","url":"https://www.quantamagazine.org/physics/","order":1,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"main-menu\"}).items.1":{"title":"Mathematics","url":"https://www.quantamagazine.org/mathematics/","order":2,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"main-menu\"}).items.2":{"title":"Biology","url":"https://www.quantamagazine.org/biology/","order":3,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"main-menu\"}).items.3":{"title":"Computer Science","url":"https://www.quantamagazine.org/computer-science/","order":4,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"main-menu\"}).items.4":{"title":"All Articles","url":"https://www.quantamagazine.org/archive/","order":5,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"main-menu\"})":{"items":[{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"main-menu\"}).items.0","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"main-menu\"}).items.1","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"main-menu\"}).items.2","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"main-menu\"}).items.3","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"main-menu\"}).items.4","typename":"MenuItem"}],"__typename":"Menu"},"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.0":{"title":"Blog","url":"https://www.quantamagazine.org/abstractions/","order":1,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.1":{"title":"Columns","url":"/tag/quantized","order":2,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.2":{"title":"Q&A","url":"https://www.quantamagazine.org/qa/","order":3,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.3":{"title":"Puzzles","url":"https://www.quantamagazine.org/puzzles/","order":4,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.4":{"title":"Videos","url":"/videos","order":5,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.5":{"title":"Multimedia","url":"https://www.quantamagazine.org/multimedia/","order":6,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.6":{"title":"Podcasts","url":"https://www.quantamagazine.org/tag/podcast","order":7,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.7":{"title":"About Quanta","url":"https://www.quantamagazine.org/about/","order":8,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"})":{"items":[{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.0","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.1","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.2","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.3","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.4","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.5","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.6","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"secondary-menu\"}).items.7","typename":"MenuItem"}],"__typename":"Menu"},"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.0":{"title":"About Quanta","url":"https://www.quantamagazine.org/about/","order":1,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.1":{"title":"Archive","url":"/archive","order":2,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.2":{"title":"Contact Us","url":"https://www.quantamagazine.org/contact-us/","order":3,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.3":{"title":"Terms &#038; Conditions","url":"https://www.quantamagazine.org/terms-conditions/","order":4,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.4":{"title":"Privacy Policy","url":"https://www.quantamagazine.org/privacy-policy/","order":5,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.5":{"title":"Simons Foundation","url":"http://www.simonsfoundation.org","order":6,"__typename":"MenuItem"},"$ROOT_QUERY.menu({\"slug\":\"footer\"})":{"items":[{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.0","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.1","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.2","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.3","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.4","typename":"MenuItem"},{"type":"id","generated":true,"id":"$ROOT_QUERY.menu({\"slug\":\"footer\"}).items.5","typename":"MenuItem"}],"__typename":"Menu"},"$ROOT_QUERY.getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\"})":{"type":"post","meta":{"type":"id","generated":true,"id":"$ROOT_QUERY.getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\"}).meta","typename":"PageData"},"data":[{"type":"id","generated":false,"id":"Post:77108","typename":"Post"}],"__typename":"PostPageArchive"},"$ROOT_QUERY.getPostPageArchive({\"slug\":\"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\"}).meta":{"title":"Machines Beat Humans on a Reading Test. But Do They Understand? | Quanta Magazine","max_num_pages":0,"author":{"type":"id","generated":false,"id":"Author:null","typename":"Author"},"tag":{"type":"id","generated":false,"id":"Term:null","typename":"Term"},"category":{"type":"id","generated":false,"id":"Term:null","typename":"Term"},"__typename":"PageData"},"Author:null":{"id":null,"name":null,"link":null,"description":null,"url":null,"public_email":null,"facebook":null,"twitter":null,"instagram":null,"acf":null,"__typename":"Author"},"Term:null":{"id":null,"slug":null,"name":null,"link":null,"description":null,"image":"","__typename":"Term"},"Post:77108":{"id":"77108","title":"Machines Beat Humans on a Reading Test. But Do They Understand?","excerpt":"\u003cp>A tool known as BERT can now beat humans on advanced reading-comprehension tests. But it&#8217;s also revealed how far AI has to go. \u003c/p>\n","link":"https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/","slug":"machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017","disqus":"77108 https://www.quantamagazine.org/?p=77108","date":"2019-10-17T12:30:05","featured_media_image":null,"authors":[{"type":"id","generated":true,"id":"Post:77108.authors.0","typename":"Author"}],"podcast":null,"acf":{"type":"id","generated":true,"id":"$Post:77108.acf","typename":"ACFFields"},"__typename":"Post","status":"publish","content":"","tags":[{"type":"id","generated":true,"id":"Post:77108.tags.0","typename":"Term"},{"type":"id","generated":true,"id":"Post:77108.tags.1","typename":"Term"},{"type":"id","generated":true,"id":"Post:77108.tags.2","typename":"Term"},{"type":"id","generated":true,"id":"Post:77108.tags.3","typename":"Term"},{"type":"id","generated":true,"id":"Post:77108.tags.4","typename":"Term"}],"categories":[{"type":"id","generated":false,"id":"Term:190","typename":"Term"}],"attachments":{"type":"id","generated":true,"id":"$Post:77108.attachments","typename":"Attachments"},"series_prev":null,"series_next":null,"next":{"type":"id","generated":true,"id":"$Post:77108.next","typename":"PostPageArchive"}},"Post:77108.authors.0":{"name":"John Pavlus","link":"https://www.quantamagazine.org/authors/john-pavlus/","__typename":"Author","acf":{"type":"id","generated":true,"id":"$Post:77108.authors.0.acf","typename":"AuthorACF"}},"$Post:77108.acf":{"featured_block_title":"","kicker":{"type":"id","generated":true,"id":"$Post:77108.acf.kicker","typename":"Term"},"featured_image_default":{"type":"id","generated":true,"id":"$Post:77108.acf.featured_image_default","typename":"Image"},"featured_image_full_width":{"type":"id","generated":true,"id":"$Post:77108.acf.featured_image_full_width","typename":"Image"},"featured_image_gif":false,"featured_video":"false","full_page_interactive":null,"__typename":"ACFFields","interactive_type":null,"iframe_url":null,"interactive_html":null,"interactive_css":null,"interactive_js":null,"interactive_blurb":null,"related_article":null,"modules":[{"type":"id","generated":true,"id":"$Post:77108.acf.modules.0","typename":"ACFImageComponent"},{"type":"id","generated":true,"id":"$Post:77108.acf.modules.1","typename":"ACFContent"}],"template":"article","subtitle":"A tool known as BERT can now beat humans on advanced reading-comprehension tests. But it's also revealed how far AI has to go. ","title_layout":"default","title_background_type":null,"title_background_image":null,"title_background_video":null,"title_background_attribution":null,"title_background_image_gif":null,"title_overlay_enable":null,"title_overlay_color":null,"title_overlay_opacity":null,"title_text_color":null,"featured_image_attribution":"\u003cp>\u003ca href=\"http://www.soulofagiant.com/\">Jon Fox\u003c/a> for Quanta Magazine\u003c/p>\n","featured_overlay_enable":"false","featured_overlay_color":null,"featured_overlay_opacity":null,"series":{"type":"id","generated":true,"id":"$Post:77108.acf.series","typename":"Term"},"intro_content":null,"make_image_full_width":null,"hide_ad_on_post":false},"$Post:77108.acf.kicker":{"name":"artificial intelligence","link":"https://www.quantamagazine.org/tag/artificial-intelligence/","__typename":"Term"},"$Post:77108.acf.featured_image_default":{"alt":"Illustration of cartoon characters working alongside a machine.","caption":"The BERT neural network has led to a revolution in how machines understand human language.","url":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_520x292.jpg","width":520,"height":292,"sizes":{"type":"id","generated":true,"id":"$Post:77108.acf.featured_image_default.sizes","typename":"ImageSizes"},"__typename":"Image"},"$Post:77108.acf.featured_image_default.sizes":{"thumbnail":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_520x292-520x292.jpg","square_small":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_520x292-160x160.jpg","square_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_520x292-520x292.jpg","medium":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_520x292.jpg","medium_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_520x292.jpg","large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_520x292.jpg","__typename":"ImageSizes"},"$Post:77108.acf.featured_image_full_width":{"alt":"Illustration of cartoon characters working alongside a machine.","caption":"The BERT neural network has led to a revolution in how machines understand human language.","url":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1220_HPA.jpg","width":2880,"height":1220,"sizes":{"type":"id","generated":true,"id":"$Post:77108.acf.featured_image_full_width.sizes","typename":"ImageSizes"},"__typename":"Image"},"$Post:77108.acf.featured_image_full_width.sizes":{"thumbnail":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1220_HPA-520x220.jpg","square_small":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1220_HPA-160x160.jpg","square_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1220_HPA-520x520.jpg","medium":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1220_HPA-1720x729.jpg","medium_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1220_HPA-768x325.jpg","large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1220_HPA-2880x1220.jpg","__typename":"ImageSizes"},"Post:77108.tags.0":{"name":"artificial intelligence","link":"https://www.quantamagazine.org/tag/artificial-intelligence/","__typename":"Term"},"Post:77108.tags.1":{"name":"computer science","link":"https://www.quantamagazine.org/tag/computer-science/","__typename":"Term"},"Post:77108.tags.2":{"name":"machine learning","link":"https://www.quantamagazine.org/tag/machine-learning/","__typename":"Term"},"Post:77108.tags.3":{"name":"natural language processing","link":"https://www.quantamagazine.org/tag/natural-language-processing/","__typename":"Term"},"Post:77108.tags.4":{"name":"neural networks","link":"https://www.quantamagazine.org/tag/neural-networks/","__typename":"Term"},"Term:190":{"id":"190","name":"Computer Science","slug":"computer-science","link":"https://www.quantamagazine.org/computer-science/","__typename":"Term"},"$Post:77108.authors.0.acf":{"tagline":"Contributing Writer","avatar":{"type":"id","generated":true,"id":"$Post:77108.authors.0.acf.avatar","typename":"Image"},"__typename":"AuthorACF"},"$Post:77108.authors.0.acf.avatar":{"alt":"","caption":"","url":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/John_Pavlus1.jpg","width":1500,"height":1500,"sizes":{"type":"id","generated":true,"id":"$Post:77108.authors.0.acf.avatar.sizes","typename":"ImageSizes"},"__typename":"Image"},"$Post:77108.authors.0.acf.avatar.sizes":{"thumbnail":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/John_Pavlus1-520x520.jpg","square_small":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/John_Pavlus1-160x160.jpg","square_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/John_Pavlus1-520x520.jpg","medium":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/John_Pavlus1.jpg","medium_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/John_Pavlus1-768x768.jpg","large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/John_Pavlus1.jpg","__typename":"ImageSizes"},"$Post:77108.acf.modules.0":{"acf_fc_layout":"image_component","layout":"large","settings":"large_margin","attribution":"\u003cp>\u003ca href=\"http://www.soulofagiant.com/\">Jon Fox\u003c/a> for Quanta Magazine\u003c/p>\n","caption":"\u003cp>The BERT neural network has led to a revolution in how machines understand human language.\u003c/p>\n","mobile_comp_caption":"","mobile_comp_attribution":"","sets":[{"type":"id","generated":true,"id":"$Post:77108.acf.modules.0.sets.0","typename":"ImageSet"}],"__typename":"ACFImageComponent"},"$Post:77108.acf.modules.0.sets.0":{"settings":"","image":{"type":"id","generated":true,"id":"$Post:77108.acf.modules.0.sets.0.image","typename":"Image"},"mobile_image":{"type":"id","generated":true,"id":"$Post:77108.acf.modules.0.sets.0.mobile_image","typename":"Image"},"mobile_caption":"","mobile_attribution":"","zoom_image":{"type":"id","generated":true,"id":"$Post:77108.acf.modules.0.sets.0.zoom_image","typename":"Image"},"zoom_caption":"","zoom_attribution":"","external_link":"","__typename":"ImageSet"},"$Post:77108.acf.modules.0.sets.0.image":{"alt":"Illustration of cartoon characters working alongside a machine.","caption":"The BERT neural network has led to a revolution in how machines understand human language.","url":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1820_Lede.jpg","width":2880,"height":1820,"sizes":{"type":"id","generated":true,"id":"$Post:77108.acf.modules.0.sets.0.image.sizes","typename":"ImageSizes"},"__typename":"Image"},"$Post:77108.acf.modules.0.sets.0.image.sizes":{"thumbnail":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1820_Lede-520x329.jpg","square_small":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1820_Lede-160x160.jpg","square_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1820_Lede-520x520.jpg","medium":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1820_Lede-1720x1087.jpg","medium_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1820_Lede-768x485.jpg","large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_2880x1820_Lede-2880x1820.jpg","__typename":"ImageSizes"},"$Post:77108.acf.modules.0.sets.0.mobile_image":{"alt":null,"caption":null,"url":null,"width":null,"height":null,"sizes":{"type":"id","generated":true,"id":"$Post:77108.acf.modules.0.sets.0.mobile_image.sizes","typename":"ImageSizes"},"__typename":"Image"},"$Post:77108.acf.modules.0.sets.0.mobile_image.sizes":{"thumbnail":null,"square_small":null,"square_large":null,"medium":null,"medium_large":null,"large":null,"__typename":"ImageSizes"},"$Post:77108.acf.modules.0.sets.0.zoom_image":{"alt":null,"caption":null,"url":null,"width":null,"height":null,"sizes":{"type":"id","generated":true,"id":"$Post:77108.acf.modules.0.sets.0.zoom_image.sizes","typename":"ImageSizes"},"__typename":"Image"},"$Post:77108.acf.modules.0.sets.0.zoom_image.sizes":{"thumbnail":null,"square_small":null,"square_large":null,"medium":null,"medium_large":null,"large":null,"__typename":"ImageSizes"},"$Post:77108.acf.modules.1":{"acf_fc_layout":"content_area","show_sidebars":true,"content":"\u003cp>In the fall of 2017, \u003ca href=\"http://www.nyu.edu/projects/bowman/\">Sam Bowman\u003c/a>, a computational linguist at New York University, figured that computers still weren’t very good at understanding the written word. Sure, they had become decent at simulating that understanding in certain narrow domains, like automatic translation or sentiment analysis (for example, determining if a sentence sounds “mean or nice,” he said). But Bowman wanted measurable evidence of the genuine article: bona fide, human-style reading comprehension in English. So he came up with a test.\u003c/p>\n\u003cp>In an April 2018 \u003ca href=\"https://arxiv.org/abs/1804.07461\">paper\u003c/a> coauthored with collaborators from the University of Washington and DeepMind, the Google-owned artificial intelligence company, Bowman introduced a battery of nine reading-comprehension tasks for computers called GLUE (General Language Understanding Evaluation). The test was designed as “a fairly representative sample of what the research community thought were interesting challenges,” said Bowman, but also “pretty straightforward for humans.” For example, one task asks whether a sentence is true based on information offered in a preceding sentence. If you can tell that “President Trump landed in Iraq for the start of a seven-day visit” implies that “President Trump is on an overseas visit,” you’ve just passed.\u003c/p>\n\u003cp>The machines bombed. Even state-of-the-art neural networks scored no higher than 69 out of 100 across all nine tasks: a D-plus, in letter grade terms. Bowman and his coauthors weren’t surprised. Neural networks — layers of computational connections built in a crude approximation of how neurons communicate within mammalian brains — had shown promise in the field of “natural language processing” (NLP), but the researchers weren’t convinced that these systems were learning anything substantial about language itself. And GLUE seemed to prove it. “These early results indicate that solving GLUE is beyond the capabilities of current models and methods,” Bowman and his coauthors wrote.\u003c/p>\n\u003cdiv id='component-5e03cfe9c6847'>\u003cscript type=\"text/template\">{\"type\":\"Blockquote\",\"id\":\"component-5e03cfe9c6847\",\"data\":{\"quote\":\"\u003cp>We know we\\u2019re somewhere in the gray area between solving language in a very boring, narrow sense, and solving AI.\u003c\\/p>\\n\",\"alignment\":\"right\",\"quote_attribution\":\"\u003cp>Sam Bowman\u003c\\/p>\\n\",\"twitter_text\":\"\"}}\u003c\/script>\u003c/div>\n\u003cp>Their appraisal would be short-lived. In October of 2018, Google introduced a new method nicknamed BERT (Bidirectional Encoder Representations from Transformers). It produced a GLUE score of 80.5. On this brand-new benchmark designed to measure machines’ real understanding of natural language — or to expose their lack thereof — the machines had jumped from a D-plus to a B-minus in just six months.\u003c/p>\n\u003cp>“That was definitely the ‘oh, crap’ moment,” Bowman recalled, using a more colorful interjection. “The general reaction in the field was incredulity. BERT was getting numbers on many of the tasks that were close to what we thought would be the limit of how well you could do.” Indeed, GLUE didn’t even bother to include human baseline scores before BERT; by the time Bowman and one of his Ph.D. students added them to GLUE in February 2019, they lasted just a few months before \u003ca href=\"https://blogs.msdn.microsoft.com/stevengu/2019/06/20/microsoft-achieves-human-performance-estimate-on-glue-benchmark/\">a BERT-based system from Microsoft\u003c/a> beat them.\u003c/p>\n\u003cp>As of this writing, nearly every position on the \u003ca href=\"https://gluebenchmark.com/leaderboard/\">GLUE leaderboard\u003c/a> is occupied by a system that incorporates, extends or optimizes BERT. Five of these systems outrank human performance.\u003c/p>\n\u003cp>But is AI actually starting to understand our language — or is it just getting better at gaming our systems? As BERT-based neural networks have taken benchmarks like GLUE by storm, new evaluation methods have emerged that seem to paint these powerful NLP systems as computational versions of Clever Hans, the early 20th-century horse who seemed smart enough to do arithmetic, but who was actually just following unconscious cues from his trainer.\u003c/p>\n\u003cp>“We know we’re somewhere in the gray area between solving language in a very boring, narrow sense, and solving AI,” Bowman said. “The general reaction of the field was: Why did this happen? What does this mean? What do we do now?”\u003c/p>\n\u003ch2 class=\"Body\">Writing Their Own Rules\u003c/h2>\n\u003cp>In the famous Chinese Room thought experiment, a non-Chinese-speaking person sits in a room furnished with many rulebooks. Taken together, these rulebooks perfectly specify how to take any incoming sequence of Chinese symbols and craft an appropriate response. A person outside slips questions written in Chinese under the door. The person inside consults the rulebooks, then sends back perfectly coherent answers in Chinese.\u003c/p>\n\u003cp>The thought experiment has been used to argue that, no matter how it might appear from the outside, the person inside the room can’t be said to have any true understanding of Chinese. Still, even a simulacrum of understanding has been a good enough goal for natural language processing.\u003c/p>\n\u003cp>The only problem is that perfect rulebooks don’t exist, because natural language is far too complex and haphazard to be reduced to a rigid set of specifications. Take syntax, for example: the rules (and rules of thumb) that define how words group into meaningful sentences. The phrase “\u003ca href=\"https://books.google.com/books?id=55YaAAAAIAAJ&amp;dq=colorless+green+ideas+sleep+furiously\">colorless green ideas sleep furiously\u003c/a>” has perfect syntax, but any natural speaker knows it’s nonsense. What prewritten rulebook could capture this “unwritten” fact about natural language — or innumerable others?\u003c/p>\n\u003cp>NLP researchers have tried to square this circle by having neural networks write their own makeshift rulebooks, in a process called pretraining.\u003c/p>\n\u003cp>Before 2018, one of NLP’s main pretraining tools was something like a dictionary. Known as word embeddings, this dictionary encoded associations between words as numbers in a way that deep neural networks could accept as input — akin to giving the person inside a Chinese room a crude vocabulary book to work with. But a neural network pretrained with word embeddings is still blind to the meaning of words at the sentence level. “It would think that ‘a man bit the dog’ and ‘a dog bit the man’ are exactly the same thing,” said \u003ca href=\"http://tallinzen.net/\">Tal Linzen\u003c/a>, a computational linguist at Johns Hopkins University.\u003c/p>\n\u003cdiv id='component-5e03cfe9c9ab4'>\u003cscript type=\"text/template\">{\"type\":\"Image\",\"id\":\"component-5e03cfe9c9ab4\",\"data\":{\"id\":77506,\"src\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"class\":\"\",\"width\":1500,\"height\":2000,\"mobileSrc\":false,\"zoomSrc\":false,\"align\":\"align=\\\"right\\\"\",\"wrapper_width\":\"\",\"caption\":\"\u003cp>Tal Linzen, a computational linguist at Johns Hopkins University, wonders \\u201cto what extent these models are really understanding language,\\u201d and not just \\u201cpicking up weird tricks that happen to work.\\u201d\u003c\\/p>\\n\",\"attribution\":\"\u003cp>Will Kirk\\/Johns Hopkins University\u003c\\/p>\\n\",\"variant\":\"shortcode\",\"size\":\"default\",\"disableZoom\":true,\"srcImage\":{\"ID\":77506,\"id\":77506,\"title\":\"Linzen-KirkJohnsHopkins_1500x2000\",\"filename\":\"Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"filesize\":809002,\"url\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"link\":\"https:\\/\\/www.quantamagazine.org\\/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\\/linzen-kirkjohnshopkins_1500x2000\\/\",\"alt\":\"Photo of Tal Linzen\",\"author\":\"3886\",\"description\":\"Will Kirk\\/Johns Hopkins University\",\"caption\":\"Tal Linzen, a computational linguist at Johns Hopkins University, wonders \\u201cto what extent these models are really understanding language,\\u201d and not just \\u201cpicking up weird tricks that happen to work.\\u201d\",\"name\":\"linzen-kirkjohnshopkins_1500x2000\",\"status\":\"inherit\",\"uploaded_to\":77108,\"date\":\"2019-10-16 20:45:15\",\"modified\":\"2019-10-17 15:01:33\",\"menu_order\":0,\"mime_type\":\"image\\/jpeg\",\"type\":\"image\",\"subtype\":\"jpeg\",\"icon\":\"https:\\/\\/api.quantamagazine.org\\/wp-includes\\/images\\/media\\/default.png\",\"width\":1500,\"height\":2000,\"sizes\":{\"thumbnail\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000-390x520.jpg\",\"thumbnail-width\":390,\"thumbnail-height\":520,\"medium\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000-1290x1720.jpg\",\"medium-width\":1290,\"medium-height\":1720,\"medium_large\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000-768x1024.jpg\",\"medium_large-width\":768,\"medium_large-height\":1024,\"large\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"large-width\":1500,\"large-height\":2000,\"square_small\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000-160x160.jpg\",\"square_small-width\":160,\"square_small-height\":160,\"square_large\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000-520x520.jpg\",\"square_large-width\":520,\"square_large-height\":520,\"apple_news_ca_landscape_12_9\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_landscape_12_9-width\":1031,\"apple_news_ca_landscape_12_9-height\":1374,\"apple_news_ca_landscape_9_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_landscape_9_7-width\":774,\"apple_news_ca_landscape_9_7-height\":1032,\"apple_news_ca_landscape_5_5\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_landscape_5_5-width\":587,\"apple_news_ca_landscape_5_5-height\":783,\"apple_news_ca_landscape_4_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_landscape_4_7-width\":356,\"apple_news_ca_landscape_4_7-height\":474,\"apple_news_ca_landscape_4_0\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_landscape_4_0-width\":302,\"apple_news_ca_landscape_4_0-height\":402,\"apple_news_ca_portrait_12_9\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_portrait_12_9-width\":1122,\"apple_news_ca_portrait_12_9-height\":1496,\"apple_news_ca_portrait_9_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_portrait_9_7-width\":840,\"apple_news_ca_portrait_9_7-height\":1120,\"apple_news_ca_portrait_5_5\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_portrait_5_5-width\":687,\"apple_news_ca_portrait_5_5-height\":916,\"apple_news_ca_portrait_4_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_portrait_4_7-width\":414,\"apple_news_ca_portrait_4_7-height\":552,\"apple_news_ca_portrait_4_0\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_portrait_4_0-width\":354,\"apple_news_ca_portrait_4_0-height\":472,\"apple_news_ca_square_12_9\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_square_12_9-width\":1104,\"apple_news_ca_square_12_9-height\":1472,\"apple_news_ca_square_9_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_square_9_7-width\":828,\"apple_news_ca_square_9_7-height\":1104,\"apple_news_ca_square_5_5\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_square_5_5-width\":684,\"apple_news_ca_square_5_5-height\":912,\"apple_news_ca_square_4_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_square_4_7-width\":413,\"apple_news_ca_square_4_7-height\":550,\"apple_news_ca_square_4_0\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Linzen-KirkJohnsHopkins_1500x2000.jpg\",\"apple_news_ca_square_4_0-width\":353,\"apple_news_ca_square_4_0-height\":470}},\"largeForPrint\":false,\"externalLink\":\"\"}}\u003c\/script>\u003c/div>\n\u003cp>A better method would use pretraining to equip the network with richer rulebooks — not just for vocabulary, but for syntax and context as well — before training it to perform a specific NLP task. In early 2018, researchers at OpenAI, the University of San Francisco, the Allen Institute for Artificial Intelligence and the University of Washington simultaneously discovered a clever way to approximate this feat. Instead of pretraining just the first layer of a network with word embeddings, the researchers began training entire neural networks on a broader basic task called language modeling.\u003c/p>\n\u003cp>“The simplest kind of language model is: I’m going to read a bunch of words and then try to predict the next word,” explained \u003ca href=\"https://research.fb.com/people/ott-myle/\">Myle Ott\u003c/a>, a research scientist at Facebook. “If I say, ‘George Bush was born in,’ the model now has to predict the next word in that sentence.”\u003c/p>\n\u003cp>These deep pretrained language models could be produced relatively efficiently. Researchers simply fed their neural networks massive amounts of written text copied from freely available sources like Wikipedia — billions of words, preformatted into grammatically correct sentences — and let the networks derive next-word predictions on their own. In essence, it was like asking the person inside a Chinese room to write all his own rules, using only the incoming Chinese messages for reference.\u003c/p>\n\u003cp>“The great thing about this approach is it turns out that the model learns a ton of stuff about syntax,” Ott said.\u003c/p>\n\u003cp>What’s more, these pretrained neural networks could then apply their richer representations of language to the job of learning an unrelated, more specific NLP task, a process called fine-tuning.\u003c/p>\n\u003cp>“You can take the model from the pretraining stage and kind of adapt it for whatever actual task you care about,” Ott explained. “And when you do that, you get much better results than if you had just started with your end task in the first place.”\u003c/p>\n\u003cp>Indeed, in June of 2018, when OpenAI unveiled a neural network \u003ca href=\"https://openai.com/blog/language-unsupervised/\">called GPT\u003c/a>, which included a language model pretrained on nearly a billion words (sourced from 11,038 digital books) for an entire month, its GLUE score of 72.8 immediately took the top spot on the leaderboard. Still, Sam Bowman assumed that the field had a long way to go before any system could even begin to approach human-level performance.\u003c/p>\n\u003cp>Then BERT appeared.\u003c/p>\n\u003ch2 class=\"Body\">A Powerful Recipe\u003c/h2>\n\u003cp>So what exactly is BERT?\u003c/p>\n\u003cp>First, it’s not a fully trained neural network capable of besting human performance right out of the box. Instead, said Bowman, BERT is “a very precise recipe for pretraining a neural network.” Just as a baker can follow a recipe to reliably produce a delicious prebaked pie crust — which can then be used to make many different kinds of pie, from blueberry to spinach quiche — Google researchers developed BERT’s recipe to serve as an ideal foundation for “baking” neural networks (that is, fine-tuning them) to do well on many different natural language processing tasks. Google also open-sourced BERT’s code, which means that other researchers don’t have to repeat the recipe from scratch — they can just download BERT as-is, like buying a prebaked pie crust from the supermarket.\u003c/p>\n\u003cp>If BERT is essentially a recipe, what’s the ingredient list? “It’s the result of three things coming together to really make things click,” said \u003ca href=\"https://levyomer.wordpress.com/\">Omer Levy\u003c/a>, a research scientist at Facebook who has \u003ca href=\"https://arxiv.org/abs/1906.04341\">analyzed BERT’s inner workings\u003c/a>.\u003c/p>\n\u003cdiv id='component-5e03cfe9ccfaa'>\u003cscript type=\"text/template\">{\"type\":\"Image\",\"id\":\"component-5e03cfe9ccfaa\",\"data\":{\"id\":77505,\"src\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"class\":\"\",\"width\":1500,\"height\":2000,\"mobileSrc\":false,\"zoomSrc\":false,\"align\":\"align=\\\"right\\\"\",\"wrapper_width\":\"\",\"caption\":\"\u003cp>Omer Levy, a research scientist at Facebook, has studied why BERT is so successful.\u003c\\/p>\\n\",\"attribution\":\"\u003cp>Courtesy of Omer Levy\u003c\\/p>\\n\",\"variant\":\"shortcode\",\"size\":\"default\",\"disableZoom\":true,\"srcImage\":{\"ID\":77505,\"id\":77505,\"title\":\"Levy-1500x2000\",\"filename\":\"Levy-1500x2000.jpg\",\"filesize\":802656,\"url\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"link\":\"https:\\/\\/www.quantamagazine.org\\/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\\/levy-1500x2000\\/\",\"alt\":\"Photo of Omer Levy\",\"author\":\"3886\",\"description\":\"Courtesy of Omer Levy\",\"caption\":\"Omer Levy, a research scientist at Facebook, has studied why BERT is so successful.\",\"name\":\"levy-1500x2000\",\"status\":\"inherit\",\"uploaded_to\":77108,\"date\":\"2019-10-16 20:45:14\",\"modified\":\"2019-10-17 15:03:02\",\"menu_order\":0,\"mime_type\":\"image\\/jpeg\",\"type\":\"image\",\"subtype\":\"jpeg\",\"icon\":\"https:\\/\\/api.quantamagazine.org\\/wp-includes\\/images\\/media\\/default.png\",\"width\":1500,\"height\":2000,\"sizes\":{\"thumbnail\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000-390x520.jpg\",\"thumbnail-width\":390,\"thumbnail-height\":520,\"medium\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000-1290x1720.jpg\",\"medium-width\":1290,\"medium-height\":1720,\"medium_large\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000-768x1024.jpg\",\"medium_large-width\":768,\"medium_large-height\":1024,\"large\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"large-width\":1500,\"large-height\":2000,\"square_small\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000-160x160.jpg\",\"square_small-width\":160,\"square_small-height\":160,\"square_large\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000-520x520.jpg\",\"square_large-width\":520,\"square_large-height\":520,\"apple_news_ca_landscape_12_9\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_landscape_12_9-width\":1031,\"apple_news_ca_landscape_12_9-height\":1374,\"apple_news_ca_landscape_9_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_landscape_9_7-width\":774,\"apple_news_ca_landscape_9_7-height\":1032,\"apple_news_ca_landscape_5_5\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_landscape_5_5-width\":587,\"apple_news_ca_landscape_5_5-height\":783,\"apple_news_ca_landscape_4_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_landscape_4_7-width\":356,\"apple_news_ca_landscape_4_7-height\":474,\"apple_news_ca_landscape_4_0\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_landscape_4_0-width\":302,\"apple_news_ca_landscape_4_0-height\":402,\"apple_news_ca_portrait_12_9\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_portrait_12_9-width\":1122,\"apple_news_ca_portrait_12_9-height\":1496,\"apple_news_ca_portrait_9_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_portrait_9_7-width\":840,\"apple_news_ca_portrait_9_7-height\":1120,\"apple_news_ca_portrait_5_5\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_portrait_5_5-width\":687,\"apple_news_ca_portrait_5_5-height\":916,\"apple_news_ca_portrait_4_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_portrait_4_7-width\":414,\"apple_news_ca_portrait_4_7-height\":552,\"apple_news_ca_portrait_4_0\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_portrait_4_0-width\":354,\"apple_news_ca_portrait_4_0-height\":472,\"apple_news_ca_square_12_9\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_square_12_9-width\":1104,\"apple_news_ca_square_12_9-height\":1472,\"apple_news_ca_square_9_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_square_9_7-width\":828,\"apple_news_ca_square_9_7-height\":1104,\"apple_news_ca_square_5_5\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_square_5_5-width\":684,\"apple_news_ca_square_5_5-height\":912,\"apple_news_ca_square_4_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_square_4_7-width\":413,\"apple_news_ca_square_4_7-height\":550,\"apple_news_ca_square_4_0\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Levy-1500x2000.jpg\",\"apple_news_ca_square_4_0-width\":353,\"apple_news_ca_square_4_0-height\":470}},\"largeForPrint\":false,\"externalLink\":\"\"}}\u003c\/script>\u003c/div>\n\u003cp>The first is a pretrained language model, those reference books in our Chinese room. The second is the ability to figure out which features of a sentence are most important.\u003c/p>\n\u003cp>In 2017, an engineer at Google Brain named \u003ca href=\"http://jakob.uszkoreit.net/\">Jakob Uszkoreit\u003c/a> was working on ways to accelerate Google’s language-understanding efforts. He noticed that state-of-the-art neural networks also suffered from a built-in constraint: They all looked through the sequence of words one by one. This “sequentiality” seemed to match intuitions of how humans actually read written sentences. But Uszkoreit wondered if “it might be the case that understanding language in a linear, sequential fashion is suboptimal,” he said.\u003c/p>\n\u003cp>Uszkoreit and his collaborators devised a new architecture for neural networks focused on “attention,” a mechanism that lets each layer of the network assign more weight to some specific features of the input than to others. This new attention-focused architecture, called a transformer, could take a sentence like “a dog bites the man” as input and encode each word in many different ways in parallel. For example, a transformer might connect “bites” and “man” together as verb and object, while ignoring “a”; at the same time, it could connect “bites” and “dog” together as verb and subject, while mostly ignoring “the.”\u003c/p>\n\u003cp>The nonsequential nature of the transformer represented sentences in a more expressive form, which Uszkoreit calls treelike. Each layer of the neural network makes multiple, parallel connections between certain words while ignoring others — akin to a student diagramming a sentence in elementary school. These connections are often drawn between words that may not actually sit next to each other in the sentence. “Those structures effectively look like a number of trees that are overlaid,” Uszkoreit explained.\u003c/p>\n\u003cp>This treelike representation of sentences gave transformers a powerful way to model contextual meaning, and also to efficiently learn associations between words that might be far away from each other in complex sentences. “It’s a bit counterintuitive,” Uszkoreit said, “but it is rooted in results from linguistics, which has for a long time looked at treelike models of language.”\u003c/p>\n\u003cdiv id='component-5e03cfe9d03e3'>\u003cscript type=\"text/template\">{\"type\":\"Image\",\"id\":\"component-5e03cfe9d03e3\",\"data\":{\"id\":77508,\"src\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"class\":\"\",\"width\":1500,\"height\":2000,\"mobileSrc\":false,\"zoomSrc\":false,\"align\":\"align=\\\"right\\\"\",\"wrapper_width\":\"\",\"caption\":\"\u003cp>Jakob Uszkoreit, who leads the Google AI Brain team in Berlin, helped develop a new architecture for neural networks that focuses on attention.\u003c\\/p>\\n\",\"attribution\":\"\u003cp>Google\u003c\\/p>\\n\",\"variant\":\"shortcode\",\"size\":\"default\",\"disableZoom\":true,\"srcImage\":{\"ID\":77508,\"id\":77508,\"title\":\"Uszkoreit-Google_1500x2000\",\"filename\":\"Uszkoreit-Google_1500x2000.jpg\",\"filesize\":997757,\"url\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"link\":\"https:\\/\\/www.quantamagazine.org\\/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017\\/uszkoreit-google_1500x2000\\/\",\"alt\":\"Photo of Jakob Uszkoreit\",\"author\":\"3886\",\"description\":\"Courtesy of Google\",\"caption\":\"Jakob Uszkoreit, who leads the Google AI Brain team in Berlin, helped develop a new architecture for neural networks that focuses on attention.\",\"name\":\"uszkoreit-google_1500x2000\",\"status\":\"inherit\",\"uploaded_to\":77108,\"date\":\"2019-10-16 20:45:19\",\"modified\":\"2019-10-17 15:03:39\",\"menu_order\":0,\"mime_type\":\"image\\/jpeg\",\"type\":\"image\",\"subtype\":\"jpeg\",\"icon\":\"https:\\/\\/api.quantamagazine.org\\/wp-includes\\/images\\/media\\/default.png\",\"width\":1500,\"height\":2000,\"sizes\":{\"thumbnail\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000-390x520.jpg\",\"thumbnail-width\":390,\"thumbnail-height\":520,\"medium\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000-1290x1720.jpg\",\"medium-width\":1290,\"medium-height\":1720,\"medium_large\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000-768x1024.jpg\",\"medium_large-width\":768,\"medium_large-height\":1024,\"large\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"large-width\":1500,\"large-height\":2000,\"square_small\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000-160x160.jpg\",\"square_small-width\":160,\"square_small-height\":160,\"square_large\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000-520x520.jpg\",\"square_large-width\":520,\"square_large-height\":520,\"apple_news_ca_landscape_12_9\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_landscape_12_9-width\":1031,\"apple_news_ca_landscape_12_9-height\":1374,\"apple_news_ca_landscape_9_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_landscape_9_7-width\":774,\"apple_news_ca_landscape_9_7-height\":1032,\"apple_news_ca_landscape_5_5\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_landscape_5_5-width\":587,\"apple_news_ca_landscape_5_5-height\":783,\"apple_news_ca_landscape_4_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_landscape_4_7-width\":356,\"apple_news_ca_landscape_4_7-height\":474,\"apple_news_ca_landscape_4_0\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_landscape_4_0-width\":302,\"apple_news_ca_landscape_4_0-height\":402,\"apple_news_ca_portrait_12_9\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_portrait_12_9-width\":1122,\"apple_news_ca_portrait_12_9-height\":1496,\"apple_news_ca_portrait_9_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_portrait_9_7-width\":840,\"apple_news_ca_portrait_9_7-height\":1120,\"apple_news_ca_portrait_5_5\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_portrait_5_5-width\":687,\"apple_news_ca_portrait_5_5-height\":916,\"apple_news_ca_portrait_4_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_portrait_4_7-width\":414,\"apple_news_ca_portrait_4_7-height\":552,\"apple_news_ca_portrait_4_0\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_portrait_4_0-width\":354,\"apple_news_ca_portrait_4_0-height\":472,\"apple_news_ca_square_12_9\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_square_12_9-width\":1104,\"apple_news_ca_square_12_9-height\":1472,\"apple_news_ca_square_9_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_square_9_7-width\":828,\"apple_news_ca_square_9_7-height\":1104,\"apple_news_ca_square_5_5\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_square_5_5-width\":684,\"apple_news_ca_square_5_5-height\":912,\"apple_news_ca_square_4_7\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_square_4_7-width\":413,\"apple_news_ca_square_4_7-height\":550,\"apple_news_ca_square_4_0\":\"https:\\/\\/d2r55xnwy6nx47.cloudfront.net\\/uploads\\/2019\\/10\\/Uszkoreit-Google_1500x2000.jpg\",\"apple_news_ca_square_4_0-width\":353,\"apple_news_ca_square_4_0-height\":470}},\"largeForPrint\":false,\"externalLink\":\"\"}}\u003c\/script>\u003c/div>\n\u003cp>Finally, the third ingredient in BERT’s recipe takes nonlinear reading one step further.\u003c/p>\n\u003cp>Unlike other pretrained language models, many of which are created by having neural networks read terabytes of text from left to right, BERT’s model reads left to right and right to left at the same time, and learns to predict words in the middle that have been randomly masked from view. For example, BERT might accept as input a sentence like “George Bush was \u003cspan style=\"background-color: #000000;\">[……..]\u003c/span> in Connecticut in 1946” and predict the masked word in the middle of the sentence (in this case, “born”) by parsing the text from both directions. “This bidirectionality is conditioning a neural network to try to get as much information as it can out of any subset of words,” Uszkoreit said.\u003c/p>\n\u003cp>The Mad-Libs-esque pretraining task that BERT uses — called masked-language modeling — isn’t new. In fact, it’s been used as a tool for assessing language comprehension in humans for decades. For Google, it also offered a practical way of enabling bidirectionality in neural networks, as opposed to the unidirectional pretraining methods that had previously dominated the field. “Before BERT, unidirectional language modeling was the standard, even though it is an unnecessarily restrictive constraint,” said \u003ca href=\"https://kentonl.com/\">Kenton Lee\u003c/a>, a research scientist at Google.\u003c/p>\n\u003cp>Each of these three ingredients — a deep pretrained language model, attention and bidirectionality — existed independently before BERT. But until Google released its recipe in late 2018, no one had combined them in such a powerful way.\u003c/p>\n\u003ch2 class=\"Body\">Refining the Recipe\u003c/h2>\n\u003cp>Like any good recipe, BERT was soon adapted by cooks to their own tastes. In the spring of 2019, there was a period “when Microsoft and Alibaba were leapfrogging each other week by week, continuing to tune their models and trade places at the number one spot on the leaderboard,” Bowman recalled. When an improved version of BERT called RoBERTa first came on the scene in August, the DeepMind researcher \u003ca href=\"http://ruder.io/\">Sebastian Ruder\u003c/a> \u003ca href=\"http://newsletter.ruder.io/issues/nlp-in-industry-leaderboard-madness-fast-ai-nlp-transfer-learning-tools-186245\">dryly noted the occasion in his widely read NLP newsletter\u003c/a>: “Another month, another state-of-the-art pretrained language model.”\u003c/p>\n\u003cdiv id='component-5e03cfe9d0570'>\u003cscript type=\"text/template\">{\"type\":\"Blockquote\",\"id\":\"component-5e03cfe9d0570\",\"data\":{\"quote\":\"\u003cp>We\\u2019re still figuring out what recipes work and which ones don\\u2019t.\u003c\\/p>\\n\",\"alignment\":\"right\",\"quote_attribution\":\"\u003cp>Myle Ott\u003c\\/p>\\n\",\"twitter_text\":\"\"}}\u003c\/script>\u003c/div>\n\u003cp>BERT&#8217;s “pie crust” incorporates a number of structural design decisions that affect how well it works. These include the size of the neural network being baked, the amount of pretraining data, how that pretraining data is masked and how long the neural network gets to train on it. Subsequent recipes like RoBERTa result from researchers tweaking these design decisions, much like chefs refining a dish.\u003c/p>\n\u003cp>In RoBERTa’s case, researchers at Facebook and the University of Washington increased some ingredients (more pretraining data, longer input sequences, more training time), took one away (a “next sentence prediction” task, originally included in BERT, that actually degraded performance) and modified another (they made the masked-language pretraining task harder). The result? First place on GLUE — briefly. Six weeks later, researchers from Microsoft and the University of Maryland \u003ca href=\"https://arxiv.org/abs/1909.11764\">added\u003c/a> their own tweaks to RoBERTa and eked out a new win. As of this writing, yet another model called ALBERT, short for “A Lite BERT,” has taken GLUE’s top spot by further adjusting BERT’s basic design.\u003c/p>\n\u003cp>“We’re still figuring out what recipes work and which ones don’t,” said Facebook’s Ott, who worked on RoBERTa.\u003c/p>\n\u003cp>Still, just as perfecting your pie-baking technique isn’t likely to teach you the principles of chemistry, incrementally optimizing BERT doesn’t necessarily impart much theoretical knowledge about advancing NLP. “I’ll be perfectly honest with you: I don’t follow these papers, because they are extremely boring to me,” said Linzen, the computational linguist from Johns Hopkins. “There is a scientific puzzle there,” he grants, but it doesn’t lie in figuring out how to make BERT and all its spawn smarter, or even in figuring out how they got smart in the first place. Instead, “we are trying to understand to what extent these models are really understanding language,” he said, and not “picking up weird tricks that happen to work on the data sets that we commonly evaluate our models on.”\u003c/p>\n\u003cp>In other words: BERT is doing something right. But what if it’s for the wrong reasons?\u003c/p>\n\u003ch2 class=\"Body\">Clever but Not Smart\u003c/h2>\n\u003cp>In July 2019, two researchers from Taiwan’s National Cheng Kung University used BERT to achieve an impressive result on a relatively obscure natural language understanding benchmark called the argument reasoning comprehension task. Performing the task requires selecting the appropriate implicit premise (called a warrant) that will back up a reason for arguing some claim. For example, to argue that “smoking causes cancer” (the claim) because “scientific studies have shown a link between smoking and cancer” (the reason), you need to presume that “scientific studies are credible” (the warrant), as opposed to “scientific studies are expensive” (which may be true, but makes no sense in the context of the argument). Got all that?\u003c/p>\n\u003cp>If not, don’t worry. Even human beings don’t do particularly well on this task without practice: The average baseline score for an untrained person is 80 out of 100. BERT got 77 — “surprising,” in the authors’ understated opinion.\u003c/p>\n\u003cp>But instead of concluding that BERT could apparently imbue neural networks with near-Aristotelian reasoning skills, they suspected a simpler explanation: that BERT was picking up on superficial patterns in the way the warrants were phrased. Indeed, after re-analyzing their training data, the authors found ample evidence of these so-called spurious cues. For example, simply choosing a warrant with the word “not” in it led to correct answers 61% of the time. After these patterns were scrubbed from the data, BERT’s score dropped from 77 to 53 — equivalent to random guessing. An article in \u003ci>The Gradient\u003c/i>, a machine-learning magazine published out of the Stanford Artificial Intelligence Laboratory, \u003ca href=\"https://thegradient.pub/nlps-clever-hans-moment-has-arrived/\">compared BERT to Clever Hans\u003c/a>, the horse with the phony powers of arithmetic.\u003c/p>\n\u003cdiv id='component-5e03cfe9d06d3'>\u003cscript type=\"text/template\">{\"type\":\"Blockquote\",\"id\":\"component-5e03cfe9d06d3\",\"data\":{\"quote\":\"\u003cp>Chess felt like a serious test of intelligence until we figured out how to write a chess program.\u003c\\/p>\\n\",\"alignment\":\"right\",\"quote_attribution\":\"\u003cp>Sam Bowman\u003c\\/p>\\n\",\"twitter_text\":\"\"}}\u003c\/script>\u003c/div>\n\u003cp>In another paper called “\u003ca href=\"https://www.aclweb.org/anthology/P19-1334\">Right for the Wrong Reasons\u003c/a>,” Linzen and his coauthors published evidence that BERT’s high performance on certain GLUE tasks might also be attributed to spurious cues in the training data for those tasks. (The paper included an alternative data set designed to specifically expose the kind of shortcut that Linzen suspected BERT was using on GLUE. The data set’s name: Heuristic Analysis for Natural-Language-Inference Systems, or HANS.)\u003c/p>\n\u003cp>So is BERT, and all of its benchmark-busting siblings, essentially a sham? Bowman agrees with Linzen that some of GLUE’s training data is messy — shot through with subtle biases introduced by the humans who created it, all of which are potentially exploitable by a powerful BERT-based neural network. “There’s no single ‘cheap trick’ that will let it solve everything [in GLUE], but there are lots of shortcuts it can take that will really help,” Bowman said, “and the model can pick up on those shortcuts.” But he doesn’t think BERT’s foundation is built on sand, either. “It seems like we have a model that has really learned something substantial about language,” he said. “But it’s definitely not understanding English in a comprehensive and robust way.”\u003c/p>\n\u003cp>According to \u003ca href=\"https://homes.cs.washington.edu/~yejin/\">Yejin Choi\u003c/a>, a computer scientist at the University of Washington and the Allen Institute, one way to encourage progress toward robust understanding is to focus not just on building a better BERT, but also on designing better benchmarks and training data that lower the possibility of Clever Hans–style cheating. Her work explores an approach called adversarial filtering, which uses algorithms to scan NLP training data sets and remove examples that are overly repetitive or that otherwise introduce spurious cues for a neural network to pick up on. After this adversarial filtering, “BERT’s performance can reduce significantly,” she said, while “human performance does not drop so much.”\u003c/p>\n\u003cp>Still, some NLP researchers believe that even with better training, neural language models may still face a fundamental obstacle to real understanding. Even with its powerful pretraining, BERT is not designed to perfectly model language in general. Instead, after fine-tuning, it models “a specific NLP task, or even a specific data set for that task,” said \u003ca href=\"https://www.cs.uml.edu/~arogers/\">Anna Rogers\u003c/a>, a computational linguist at the Text Machine Lab at the University of Massachusetts, Lowell. And it’s likely that no training data set, no matter how comprehensively designed or carefully filtered, can capture all the edge cases and unforeseen inputs that humans effortlessly cope with when we use natural language.\u003c/p>\n\u003cdiv id='component-5e03cfe9d1842'>\u003cscript type=\"text/template\">{\"type\":\"LinkList\",\"id\":\"component-5e03cfe9d1842\",\"data\":{\"title\":\"Related:\",\"links\":[{\"type\":\"internal\",\"link\":\"https:\\/\\/www.quantamagazine.org\\/computers-and-humans-see-differently-does-it-matter-20190917\\/\",\"title\":\"Computers and Humans \\u2018See\\u2019 Differently. Does It Matter?\"},{\"type\":\"internal\",\"link\":\"https:\\/\\/www.quantamagazine.org\\/been-kim-is-building-a-translator-for-artificial-intelligence-20190110\\/\",\"title\":\"A New Approach to Understanding How Machines Think\"},{\"type\":\"internal\",\"link\":\"https:\\/\\/www.quantamagazine.org\\/foundations-built-for-a-general-theory-of-neural-networks-20190131\\/\",\"title\":\"Foundations Built for a General Theory of Neural Networks\"},{\"type\":\"internal\",\"link\":\"https:\\/\\/www.quantamagazine.org\\/why-alphazeros-artificial-intelligence-has-trouble-with-the-real-world-20180221\\/\",\"title\":\"Why Artificial Intelligence Like AlphaZero Has Trouble With the Real World\"}]}}\u003c\/script>\u003c/div>\n\u003cp>Bowman points out that it’s hard to know how we would ever be fully convinced that a neural network achieves anything like real understanding. Standardized tests, after all, are supposed to reveal something intrinsic and generalizable about the test-taker’s knowledge. But as anyone who has taken an SAT prep course knows, tests can be gamed. “We have a hard time making tests that are hard enough and trick-proof enough that solving [them] really convinces us that we’ve fully solved some aspect of AI or language technology,” he said.\u003c/p>\n\u003cp>Indeed, Bowman and his collaborators recently introduced a test called \u003ca href=\"https://super.gluebenchmark.com/leaderboard\">SuperGLUE\u003c/a> that’s specifically designed to be hard for BERT-based systems. So far, no neural network can beat human performance on it. But even if (or when) it happens, does it mean that machines can really understand language any better than before? Or does just it mean that science has gotten better at teaching machines to the test?\u003c/p>\n\u003cp>“That’s a good analogy,” Bowman said. “We figured out how to solve the LSAT and the MCAT, and we might not actually be qualified to be doctors and lawyers.” Still, he added, this seems to be the way that artificial intelligence research moves forward. “Chess felt like a serious test of intelligence until we figured out how to write a chess program,” he said. “We’re definitely in an era where the goal is to keep coming up with harder problems that represent language understanding, and keep figuring out how to solve those problems.”\u003c/p>\n\u003cp>\u003cem>Clarification: On October 17, this article was updated to clarify the point made by Anna Rogers.\u003c/em>\u003c/p>\n\u003cp class=\"p1\">\u003cspan class=\"s1\">\u003ci>This article was reprinted on \u003c/i>\u003ca href=\"https://www.wired.com/story/computers-are-learning-to-read-but-theyre-still-not-so-smart/\">\u003ci>Wired.com\u003c/i>\u003c/a>\u003ci>.\u003c/i>\u003c/span>\u003c/p>\n","fadein":false,"__typename":"ACFContent"},"$Post:77108.acf.series":{"name":null,"link":null,"__typename":"Term"},"$Post:77108.attachments":{"pdf":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017.pdf","__typename":"Attachments"},"$Post:77108.next.data.0":{"title":"Inherited Learning? It Happens, but How Is Uncertain","link":"https://www.quantamagazine.org/inherited-learning-it-happens-but-how-is-uncertain-20191016/","categories":[{"type":"id","generated":true,"id":"$Post:77108.next.data.0.categories.0","typename":"Term"}],"featured_media_image":null,"acf":{"type":"id","generated":true,"id":"$Post:77108.next.data.0.acf","typename":"ACFFields"},"__typename":"Post"},"$Post:77108.next.data.0.categories.0":{"slug":"biology","__typename":"Term"},"$Post:77108.next.data.0.acf":{"template":"article","featured_block_title":"","featured_image_gif":false,"featured_image_default":{"type":"id","generated":true,"id":"$Post:77108.next.data.0.acf.featured_image_default","typename":"Image"},"featured_image_full_width":{"type":"id","generated":true,"id":"$Post:77108.next.data.0.acf.featured_image_full_width","typename":"Image"},"__typename":"ACFFields"},"$Post:77108.next.data.0.acf.featured_image_default":{"alt":"Illustration of two strips of movie film coiled around each other in a double helix.","caption":"Biologists have observed examples of learned behaviors and acquired responses being passed down through several generations, contrary to rules of Mendelian inheritance.","url":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_520x292.jpg","width":520,"height":292,"sizes":{"type":"id","generated":true,"id":"$Post:77108.next.data.0.acf.featured_image_default.sizes","typename":"ImageSizes"},"__typename":"Image"},"$Post:77108.next.data.0.acf.featured_image_default.sizes":{"thumbnail":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_520x292-520x292.jpg","square_small":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_520x292-160x160.jpg","square_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_520x292-520x292.jpg","medium":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_520x292.jpg","medium_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_520x292.jpg","large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_520x292.jpg","__typename":"ImageSizes"},"$Post:77108.next.data.0.acf.featured_image_full_width":{"alt":"Illustration of two strips of movie film coiled around each other in a double helix.","caption":"Biologists have observed examples of learned behaviors and acquired responses being passed down through several generations, contrary to rules of Mendelian inheritance.","url":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_2880x1220Lede.jpg","width":2880,"height":1220,"sizes":{"type":"id","generated":true,"id":"$Post:77108.next.data.0.acf.featured_image_full_width.sizes","typename":"ImageSizes"},"__typename":"Image"},"$Post:77108.next.data.0.acf.featured_image_full_width.sizes":{"thumbnail":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_2880x1220Lede-520x220.jpg","square_small":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_2880x1220Lede-160x160.jpg","square_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_2880x1220Lede-520x520.jpg","medium":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_2880x1220Lede-1720x729.jpg","medium_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_2880x1220Lede-768x325.jpg","large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/FILM_2880x1220Lede-2880x1220.jpg","__typename":"ImageSizes"},"$Post:77108.next":{"data":[{"type":"id","generated":true,"id":"$Post:77108.next.data.0","typename":"Post"}],"__typename":"PostPageArchive"}}</script><script type="text/javascript" data-reactid="7">window.__app__ = {
            state: {"navigation":{"megaMenuIsOpen":false,"navIsOpen":null,"localNavIsOpen":null,"interactiveNavIsOpen":null,"bookmarksIsOpen":null,"headerType":"default"},"globals":{"meta":"\n<\!-- All in One SEO Pack 2.3.11.4 by Michael Torbert of Semper Fi Web Designob_start_detected [-1,-1] -->\n<meta name=\"description\"  content=\"A tool known as BERT can now beat humans on advanced reading-comprehension tests. But it's also revealed how far AI has to go.\" />\n\n<meta name=\"keywords\"  content=\"computer science,artificial intelligence,neural networks,machine learning,natural language processing,bert,nlp\" />\n\n<link rel=\"canonical\" href=\"https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/\" />\n<meta property=\"og:title\" content=\"Machines Beat Humans on a Reading Test. But Do They Understand? | Quanta Magazine\" />\n<meta property=\"og:type\" content=\"article\" />\n<meta property=\"og:url\" content=\"https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/\" />\n<meta property=\"og:image\" content=\"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_1200_Social.jpg\" />\n<meta property=\"og:image:width\" content=\"1200\" />\n<meta property=\"og:image:height\" content=\"630\" />\n<meta property=\"og:site_name\" content=\"Quanta Magazine\" />\n<meta property=\"fb:app_id\" content=\"533309373681765\" />\n<meta name=\"twitter:card\" content=\"summary_large_image\" />\n<meta name=\"twitter:site\" content=\"@QuantaMagazine\" />\n<meta name=\"twitter:domain\" content=\"quantamagazine.org\" />\n<meta name=\"twitter:title\" content=\"Machines Beat Humans on a Reading Test. But Do They Understand? | Quanta Magazine\" />\n<meta name=\"twitter:image\" content=\"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_1200_Social.jpg\" />\n<meta itemprop=\"image\" content=\"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/10/Testing-AI_1200_Social.jpg\" />\n\t\t\t<script>\n\t\t\t(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t\t\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\t\t\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n\t\t\t})(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n\n\t\t\tga('create', 'UA-8526335-13', 'auto');\n\t\t\tga('require', 'displayfeatures');\n\t\t\tga('send', 'pageview');\n\t\t\t<\/script>\n<\!-- /all in one seo pack -->\n<meta name=\"twitter:description\" content=\"A tool known as BERT can now beat humans on advanced reading-comprehension tests. But it&#039;s also revealed how far AI has to go.\" />","settings":{"socialLinks":[{"type":"facebook","label":"Facebook","url":"https://www.facebook.com/QuantaNews","__typename":"SocialMediaLink"},{"type":"twitter","label":"Twitter","url":"https://twitter.com/QuantaMagazine","__typename":"SocialMediaLink"},{"type":"youtube","label":"YouTube","url":"http://youtube.com/c/QuantamagazineOrgNews","__typename":"SocialMediaLink"},{"type":"rss","label":"RSS","url":"https://api.quantamagazine.org/feed/","__typename":"SocialMediaLink"},{"type":"instagram","label":"Instagram","url":"https://instagram.com/quantamag","__typename":"SocialMediaLink"}],"newsletterAction":"https://quantamagazine.us1.list-manage.com/subscribe/post?u=0d6ddf7dc1a0b7297c8e06618&id=f0cb61321c","newsletterUrl":"http://us1.campaign-archive2.com/home/?u=0d6ddf7dc1a0b7297c8e06618&id=f0cb61321c","commentsHeader":"<p class=\"byline\"><small><em>Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. </em></small></p>\n","itunesSubscribe":"https://itunes.apple.com/us/podcast/quanta-science-podcast/id1021340531?mt=2&ls=1","androidSubscribe":"https://subscribeonandroid.com/www.quantamagazine.org/feed/podcast/","trackingScripts":"<\!-- Facebook Pixel Code -->\r\n<script>\r\n!function(f,b,e,v,n,t,s)\r\n{if(f.fbq)return;n=f.fbq=function()\r\n{n.callMethod? n.callMethod.apply(n,arguments):n.queue.push(arguments)}\r\n;\r\nif(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';\r\nn.queue=[];t=b.createElement(e);t.async=!0;\r\nt.src=v;s=b.getElementsByTagName(e)[0];\r\ns.parentNode.insertBefore(t,s)}(window,document,'script',\r\n'https://connect.facebook.net/en_US/fbevents.js');\r\nfbq('init', '190747804793608'); \r\nfbq('track', 'PageView');\r\n<\/script>\r\n<noscript>\r\n<img height=\"1\" width=\"1\" \r\nsrc=\"https://www.facebook.com/tr?id=190747804793608&ev=PageView\r\n&noscript=1\"/>\r\n</noscript>\r\n<\!-- End Facebook Pixel Code -->\r\n\r\n<\!-- Chartbeat --><script type=\"text/javascript\">var _sf_async_config = { uid: 65564, domain: 'quantamagazine.org', useCanonical: true };(function() {function loadChartbeat(){ window._sf_endpt = (new Date()).getTime(); var e = document.createElement('script'); e.setAttribute('language', 'javascript'); e.setAttribute('type', 'text/javascript'); e.setAttribute('src','//static.chartbeat.com/js/chartbeat.js'); document.body.appendChild(e); };var oldonload = window.onload;window.onload = (typeof window.onload != 'function') ?loadChartbeat : function(){ oldonload(); loadChartbeat(); };})();<\/script><\!-- End Chartbeat -->\r\n\r\n<\!--Parsely--><script id=\"parsely-cfg\" src=\"//cdn.parsely.com/keys/quantamagazine.org/p.js\"><\/script>","popularSearches":[{"term":"math","label":"Mathematics","__typename":"PopularSearch"},{"term":"physics","label":"Physics","__typename":"PopularSearch"},{"term":"black holes","label":"Black Holes","__typename":"PopularSearch"},{"term":"evolution","label":"Evolution","__typename":"PopularSearch"}],"searchTopics":[{"type":"Tag","label":"Podcasts","tag":{"name":"podcast","slug":"podcast","term_id":"552","__typename":"Term"},"category":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"__typename":"SearchTopic"},{"type":"Tag","label":"Columns","tag":{"name":"Quantized Columns","slug":"quantized","term_id":"551","__typename":"Term"},"category":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"__typename":"SearchTopic"},{"type":"Series","label":"Series","tag":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"category":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"__typename":"SearchTopic"},{"type":"Category","label":"Interviews","tag":{"name":"Q&amp;A","slug":"qa","term_id":"567","__typename":"Term"},"category":{"name":"Q&amp;A","slug":"qa","term_id":"176","__typename":"Term"},"__typename":"SearchTopic"},{"type":"Category","label":"Multimedia","tag":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"category":{"name":"Multimedia","slug":"multimedia","term_id":"43","__typename":"Term"},"__typename":"SearchTopic"},{"type":"Category","label":"Puzzles","tag":{"name":"puzzles","slug":"puzzles","term_id":"542","__typename":"Term"},"category":{"name":"Puzzles","slug":"puzzles","term_id":"546","__typename":"Term"},"__typename":"SearchTopic"},{"type":"Category","label":"Blog Posts","tag":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"category":{"name":"Abstractions blog","slug":"abstractions","term_id":"619","__typename":"Term"},"__typename":"SearchTopic"},{"type":"news","label":"News Articles","tag":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"category":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"__typename":"SearchTopic"},{"type":"videos","label":"Videos","tag":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"category":{"name":null,"slug":null,"term_id":null,"__typename":"Term"},"__typename":"SearchTopic"}],"searchSections":[{"name":"Mathematics","slug":"mathematics","term_id":"188","__typename":"Term"},{"name":"Physics","slug":"physics","term_id":"189","__typename":"Term"},{"name":"Biology","slug":"biology","term_id":"191","__typename":"Term"},{"name":"Computer Science","slug":"computer-science","term_id":"190","__typename":"Term"}],"adBehavior":"everywhere","adUrl":"https://www.quantamagazine.org/gift-store","adAlt":"Alice and Bob Meet the Wall of Fire - The Biggest Ideas in Science from Quanta – Available now!","adImageHome":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Default_250x342_2x_Science.jpg","adImageArticle":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Article_320x600_Science.jpg","adImageTablet":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Tablet_890x250_2x_Science.jpg","adImageMobile":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/Ad_Mobile_250x200_2x_Science.jpg"},"theme":{"page":{"accent":"#ff8600","text":"#1a1a1a","background":"white"},"header":{"type":"default","gradient":{"color":"white"},"solid":{"primary":"#1a1a1a","secondary":"#999999","hover":"#ff8600"},"transparent":{"primary":"white","secondary":"white","hover":"#ff8600"}}},"redirect":null,"fallbackImage":{"alt":"","caption":"","url":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default.gif","width":1200,"height":600,"sizes":{"thumbnail":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default-520x260.gif","square_small":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default-160x160.gif","square_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default-520x520.gif","medium":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default.gif","medium_large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default-768x384.gif","large":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/04/default.gif","__typename":"ImageSizes"},"__typename":"Image"}},"modals":{"loginModal":false,"signUpModal":false,"forgotPasswordModal":false,"resetPasswordModal":false,"lightboxModal":false,"callback":null,"props":null},"podcast":{"id":null,"playing":false,"duration":0,"currentTime":0},"user":{"loggedIn":false,"savedArticleIDs":[],"userEmail":null,"editor":null,"__typename":"CurrentUser"},"comments":{"open":false}},
            env: {
              APP_URL: 'https://www.quantamagazine.org',
              NODE_ENV: 'production',
              WP_URL: 'https://api.quantamagazine.org',
              HAS_GOOGLE_ID: true,
              HAS_FACEBOOK_ID: true,
            },
          }</script><script type="text/javascript" data-reactid="8">
          var initResourceScripts = 0;
          function resourceScripts() {
            window.clearTimeout(initResourceScripts);
            var d = document, mathjax = d.createElement('script'), disqus = d.createElement('script');

            mathjax.src = '/mathjax/MathJax.js?config=default';
            (d.head || d.body).appendChild(mathjax);

            disqus.src = 'https://quanta-mag.disqus.com/count.js';
            disqus.id = 'dsq-count-scr';
            (d.head || d.body).appendChild(disqus);
          }

          document.onreadystatechange = function () {
            if (document.readyState === "complete") {
              resourceScripts();
            }
          };

          initResourceScripts = window.setTimeout(function() {
            resourceScripts();
          }, 6000);
          </script><script src="/index.js?ver=2.7.6" data-reactid="9"></script></body></html>